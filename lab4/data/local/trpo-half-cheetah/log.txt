[2019-11-19 11:28:17.569504 UTC] Starting env pool
[2019-11-19 11:28:17.622202 UTC] Starting iteration 0
[2019-11-19 11:28:17.622886 UTC] Start collecting samples
[2019-11-19 11:28:22.152747 UTC] Computing input variables for policy optimization
[2019-11-19 11:28:22.320665 UTC] Performing policy update
[2019-11-19 11:28:22.322378 UTC] Computing gradient in Euclidean space
[2019-11-19 11:28:22.459031 UTC] Computing approximate natural gradient using conjugate gradient algorithm
[2019-11-19 11:28:23.036445 UTC] Performing line search
[2019-11-19 11:28:23.120469 UTC] Updating baseline
[2019-11-19 11:28:23.891659 UTC] Computing logging information
-------------------------------------
| Iteration            | 0          |
| ExpectedImprovement  | 0.035926   |
| ActualImprovement    | 0.03405    |
| ImprovementRatio     | 0.94779    |
| MeanKL               | 0.0065261  |
| Entropy              | 8.5136     |
| Perplexity           | 4982.2     |
| AveragePolicyStd     | 1          |
| AveragePolicyStd[0]  | 1          |
| AveragePolicyStd[1]  | 1          |
| AveragePolicyStd[2]  | 1          |
| AveragePolicyStd[3]  | 1          |
| AveragePolicyStd[4]  | 1          |
| AveragePolicyStd[5]  | 1          |
| AverageReturn        | -11.579    |
| MinReturn            | -56.593    |
| MaxReturn            | -2.3802    |
| StdReturn            | 6.5968     |
| AverageEpisodeLength | 18.02      |
| MinEpisodeLength     | 13         |
| MaxEpisodeLength     | 42         |
| StdEpisodeLength     | 5.0714     |
| TotalNEpisodes       | 268        |
| TotalNSamples        | 4869       |
| ExplainedVariance    | -0.0083012 |
-------------------------------------
[2019-11-19 11:28:24.785065 UTC] Saving snapshot
[2019-11-19 11:28:24.802775 UTC] Starting iteration 1
[2019-11-19 11:28:24.803548 UTC] Start collecting samples
[2019-11-19 11:28:29.430151 UTC] Computing input variables for policy optimization
[2019-11-19 11:28:29.606286 UTC] Performing policy update
[2019-11-19 11:28:29.607667 UTC] Computing gradient in Euclidean space
[2019-11-19 11:28:29.663553 UTC] Computing approximate natural gradient using conjugate gradient algorithm
[2019-11-19 11:28:30.270477 UTC] Performing line search
[2019-11-19 11:28:30.354935 UTC] Updating baseline
[2019-11-19 11:28:31.158663 UTC] Computing logging information
------------------------------------
| Iteration            | 1         |
| ExpectedImprovement  | 0.035098  |
| ActualImprovement    | 0.034176  |
| ImprovementRatio     | 0.97371   |
| MeanKL               | 0.0065551 |
| Entropy              | 8.48      |
| Perplexity           | 4817.5    |
| AveragePolicyStd     | 0.99442   |
| AveragePolicyStd[0]  | 1         |
| AveragePolicyStd[1]  | 0.99488   |
| AveragePolicyStd[2]  | 0.99169   |
| AveragePolicyStd[3]  | 0.99448   |
| AveragePolicyStd[4]  | 0.99555   |
| AveragePolicyStd[5]  | 0.98987   |
| AverageReturn        | -10.887   |
| MinReturn            | -35.43    |
| MaxReturn            | 2.3735    |
| StdReturn            | 5.638     |
| AverageEpisodeLength | 17.76     |
| MinEpisodeLength     | 13        |
| MaxEpisodeLength     | 45        |
| StdEpisodeLength     | 5.4335    |
| TotalNEpisodes       | 561       |
| TotalNSamples        | 9918      |
| ExplainedVariance    | 0.26472   |
------------------------------------
[2019-11-19 11:28:31.971199 UTC] Saving snapshot
[2019-11-19 11:28:31.971881 UTC] Starting iteration 2
[2019-11-19 11:28:31.972567 UTC] Start collecting samples
[2019-11-19 11:28:36.551824 UTC] Computing input variables for policy optimization
[2019-11-19 11:28:36.727376 UTC] Performing policy update
[2019-11-19 11:28:36.728571 UTC] Computing gradient in Euclidean space
[2019-11-19 11:28:36.787062 UTC] Computing approximate natural gradient using conjugate gradient algorithm
[2019-11-19 11:28:37.389372 UTC] Performing line search
[2019-11-19 11:28:37.472655 UTC] Updating baseline
[2019-11-19 11:28:38.413472 UTC] Computing logging information
------------------------------------
| Iteration            | 2         |
| ExpectedImprovement  | 0.03733   |
| ActualImprovement    | 0.036092  |
| ImprovementRatio     | 0.96685   |
| MeanKL               | 0.0065206 |
| Entropy              | 8.4113    |
| Perplexity           | 4497.6    |
| AveragePolicyStd     | 0.98311   |
| AveragePolicyStd[0]  | 0.99343   |
| AveragePolicyStd[1]  | 0.98684   |
| AveragePolicyStd[2]  | 0.97897   |
| AveragePolicyStd[3]  | 0.9821    |
| AveragePolicyStd[4]  | 0.9818    |
| AveragePolicyStd[5]  | 0.9755    |
| AverageReturn        | -10.334   |
| MinReturn            | -41.044   |
| MaxReturn            | 2.0807    |
| StdReturn            | 5.1304    |
| AverageEpisodeLength | 17.2      |
| MinEpisodeLength     | 12        |
| MaxEpisodeLength     | 38        |
| StdEpisodeLength     | 3.5128    |
| TotalNEpisodes       | 846       |
| TotalNSamples        | 14886     |
| ExplainedVariance    | 0.34391   |
------------------------------------
[2019-11-19 11:28:39.406635 UTC] Saving snapshot
[2019-11-19 11:28:39.407238 UTC] Starting iteration 3
[2019-11-19 11:28:39.407863 UTC] Start collecting samples
[2019-11-19 11:28:44.181847 UTC] Computing input variables for policy optimization
[2019-11-19 11:28:44.356699 UTC] Performing policy update
[2019-11-19 11:28:44.358086 UTC] Computing gradient in Euclidean space
[2019-11-19 11:28:44.426200 UTC] Computing approximate natural gradient using conjugate gradient algorithm
[2019-11-19 11:28:45.028673 UTC] Performing line search
[2019-11-19 11:28:45.113333 UTC] Updating baseline
[2019-11-19 11:28:45.902634 UTC] Computing logging information
------------------------------------
| Iteration            | 3         |
| ExpectedImprovement  | 0.035795  |
| ActualImprovement    | 0.034341  |
| ImprovementRatio     | 0.95938   |
| MeanKL               | 0.0065754 |
| Entropy              | 8.3451    |
| Perplexity           | 4209.4    |
| AveragePolicyStd     | 0.97233   |
| AveragePolicyStd[0]  | 0.98708   |
| AveragePolicyStd[1]  | 0.98042   |
| AveragePolicyStd[2]  | 0.96618   |
| AveragePolicyStd[3]  | 0.96579   |
| AveragePolicyStd[4]  | 0.96863   |
| AveragePolicyStd[5]  | 0.9659    |
| AverageReturn        | -8.3594   |
| MinReturn            | -36.629   |
| MaxReturn            | 1.9216    |
| StdReturn            | 4.7821    |
| AverageEpisodeLength | 17.59     |
| MinEpisodeLength     | 12        |
| MaxEpisodeLength     | 33        |
| StdEpisodeLength     | 2.9158    |
| TotalNEpisodes       | 1128      |
| TotalNSamples        | 19857     |
| ExplainedVariance    | 0.25556   |
------------------------------------
[2019-11-19 11:28:46.655880 UTC] Saving snapshot
[2019-11-19 11:28:46.656354 UTC] Starting iteration 4
[2019-11-19 11:28:46.656812 UTC] Start collecting samples
[2019-11-19 11:28:51.188008 UTC] Computing input variables for policy optimization
[2019-11-19 11:28:51.364157 UTC] Performing policy update
[2019-11-19 11:28:51.365465 UTC] Computing gradient in Euclidean space
[2019-11-19 11:28:51.428882 UTC] Computing approximate natural gradient using conjugate gradient algorithm
[2019-11-19 11:28:52.015926 UTC] Performing line search
[2019-11-19 11:28:52.099352 UTC] Updating baseline
[2019-11-19 11:28:52.919477 UTC] Computing logging information
------------------------------------
| Iteration            | 4         |
| ExpectedImprovement  | 0.034644  |
| ActualImprovement    | 0.033847  |
| ImprovementRatio     | 0.97699   |
| MeanKL               | 0.0065859 |
| Entropy              | 8.2809    |
| Perplexity           | 3947.7    |
| AveragePolicyStd     | 0.96201   |
| AveragePolicyStd[0]  | 0.98265   |
| AveragePolicyStd[1]  | 0.96936   |
| AveragePolicyStd[2]  | 0.95859   |
| AveragePolicyStd[3]  | 0.95107   |
| AveragePolicyStd[4]  | 0.95741   |
| AveragePolicyStd[5]  | 0.95299   |
| AverageReturn        | -8.324    |
| MinReturn            | -22.427   |
| MaxReturn            | 0.79657   |
| StdReturn            | 4.5278    |
| AverageEpisodeLength | 17.71     |
| MinEpisodeLength     | 13        |
| MaxEpisodeLength     | 31        |
| StdEpisodeLength     | 2.8785    |
| TotalNEpisodes       | 1413      |
| TotalNSamples        | 24933     |
| ExplainedVariance    | 0.23561   |
------------------------------------
[2019-11-19 11:28:53.891831 UTC] Saving snapshot
[2019-11-19 11:28:53.892627 UTC] Starting iteration 5
[2019-11-19 11:28:53.893399 UTC] Start collecting samples
[2019-11-19 11:28:58.355477 UTC] Computing input variables for policy optimization
[2019-11-19 11:28:58.549789 UTC] Performing policy update
[2019-11-19 11:28:58.550984 UTC] Computing gradient in Euclidean space
[2019-11-19 11:28:58.610552 UTC] Computing approximate natural gradient using conjugate gradient algorithm
[2019-11-19 11:28:59.204583 UTC] Performing line search
[2019-11-19 11:28:59.291085 UTC] Updating baseline
[2019-11-19 11:29:00.082905 UTC] Computing logging information
-----------------------------------
| Iteration            | 5        |
| ExpectedImprovement  | 0.034015 |
| ActualImprovement    | 0.033287 |
| ImprovementRatio     | 0.9786   |
| MeanKL               | 0.006579 |
| Entropy              | 8.1812   |
| Perplexity           | 3573.1   |
| AveragePolicyStd     | 0.94615  |
| AveragePolicyStd[0]  | 0.96438  |
| AveragePolicyStd[1]  | 0.95278  |
| AveragePolicyStd[2]  | 0.94309  |
| AveragePolicyStd[3]  | 0.93599  |
| AveragePolicyStd[4]  | 0.94334  |
| AveragePolicyStd[5]  | 0.93733  |
| AverageReturn        | -7.3133  |
| MinReturn            | -19.475  |
| MaxReturn            | 4.2143   |
| StdReturn            | 3.9152   |
| AverageEpisodeLength | 17.41    |
| MinEpisodeLength     | 12       |
| MaxEpisodeLength     | 31       |
| StdEpisodeLength     | 2.5341   |
| TotalNEpisodes       | 1695     |
| TotalNSamples        | 29908    |
| ExplainedVariance    | 0.29356  |
-----------------------------------
[2019-11-19 11:29:01.196826 UTC] Saving snapshot
[2019-11-19 11:29:01.197805 UTC] Starting iteration 6
[2019-11-19 11:29:01.198431 UTC] Start collecting samples
[2019-11-19 11:29:05.890468 UTC] Computing input variables for policy optimization
[2019-11-19 11:29:06.063096 UTC] Performing policy update
[2019-11-19 11:29:06.064336 UTC] Computing gradient in Euclidean space
[2019-11-19 11:29:06.119921 UTC] Computing approximate natural gradient using conjugate gradient algorithm
[2019-11-19 11:29:06.708030 UTC] Performing line search
[2019-11-19 11:29:06.789824 UTC] Updating baseline
[2019-11-19 11:29:07.598722 UTC] Computing logging information
------------------------------------
| Iteration            | 6         |
| ExpectedImprovement  | 0.033134  |
| ActualImprovement    | 0.032141  |
| ImprovementRatio     | 0.97003   |
| MeanKL               | 0.0065968 |
| Entropy              | 8.0836    |
| Perplexity           | 3241      |
| AveragePolicyStd     | 0.93091   |
| AveragePolicyStd[0]  | 0.94807   |
| AveragePolicyStd[1]  | 0.94306   |
| AveragePolicyStd[2]  | 0.92236   |
| AveragePolicyStd[3]  | 0.91726   |
| AveragePolicyStd[4]  | 0.93232   |
| AveragePolicyStd[5]  | 0.92239   |
| AverageReturn        | -6.2536   |
| MinReturn            | -18.429   |
| MaxReturn            | 1.7596    |
| StdReturn            | 3.702     |
| AverageEpisodeLength | 17.87     |
| MinEpisodeLength     | 13        |
| MaxEpisodeLength     | 35        |
| StdEpisodeLength     | 3.4078    |
| TotalNEpisodes       | 1980      |
| TotalNSamples        | 34963     |
| ExplainedVariance    | 0.30935   |
------------------------------------
[2019-11-19 11:29:08.283313 UTC] Saving snapshot
[2019-11-19 11:29:08.283748 UTC] Starting iteration 7
[2019-11-19 11:29:08.284130 UTC] Start collecting samples
[2019-11-19 11:29:12.441409 UTC] Computing input variables for policy optimization
[2019-11-19 11:29:12.614496 UTC] Performing policy update
[2019-11-19 11:29:12.615575 UTC] Computing gradient in Euclidean space
[2019-11-19 11:29:12.673137 UTC] Computing approximate natural gradient using conjugate gradient algorithm
[2019-11-19 11:29:13.268044 UTC] Performing line search
[2019-11-19 11:29:13.350890 UTC] Updating baseline
[2019-11-19 11:29:14.116991 UTC] Computing logging information
------------------------------------
| Iteration            | 7         |
| ExpectedImprovement  | 0.031868  |
| ActualImprovement    | 0.031259  |
| ImprovementRatio     | 0.9809    |
| MeanKL               | 0.0066882 |
| Entropy              | 7.9607    |
| Perplexity           | 2866.1    |
| AveragePolicyStd     | 0.91209   |
| AveragePolicyStd[0]  | 0.92506   |
| AveragePolicyStd[1]  | 0.93389   |
| AveragePolicyStd[2]  | 0.90429   |
| AveragePolicyStd[3]  | 0.89183   |
| AveragePolicyStd[4]  | 0.91988   |
| AveragePolicyStd[5]  | 0.8976    |
| AverageReturn        | -5.1835   |
| MinReturn            | -13.641   |
| MaxReturn            | 7.4398    |
| StdReturn            | 3.5575    |
| AverageEpisodeLength | 17.92     |
| MinEpisodeLength     | 14        |
| MaxEpisodeLength     | 26        |
| StdEpisodeLength     | 2.0134    |
| TotalNEpisodes       | 2255      |
| TotalNSamples        | 39933     |
| ExplainedVariance    | 0.22713   |
------------------------------------
[2019-11-19 11:29:15.019894 UTC] Saving snapshot
[2019-11-19 11:29:15.020485 UTC] Starting iteration 8
[2019-11-19 11:29:15.021294 UTC] Start collecting samples
[2019-11-19 11:29:19.576010 UTC] Computing input variables for policy optimization
[2019-11-19 11:29:19.748673 UTC] Performing policy update
[2019-11-19 11:29:19.749779 UTC] Computing gradient in Euclidean space
[2019-11-19 11:29:19.807905 UTC] Computing approximate natural gradient using conjugate gradient algorithm
[2019-11-19 11:29:20.408862 UTC] Performing line search
[2019-11-19 11:29:20.494573 UTC] Updating baseline
[2019-11-19 11:29:21.287052 UTC] Computing logging information
------------------------------------
| Iteration            | 8         |
| ExpectedImprovement  | 0.031767  |
| ActualImprovement    | 0.030912  |
| ImprovementRatio     | 0.97309   |
| MeanKL               | 0.0067074 |
| Entropy              | 7.8513    |
| Perplexity           | 2569.2    |
| AveragePolicyStd     | 0.89574   |
| AveragePolicyStd[0]  | 0.90668   |
| AveragePolicyStd[1]  | 0.92332   |
| AveragePolicyStd[2]  | 0.88981   |
| AveragePolicyStd[3]  | 0.87373   |
| AveragePolicyStd[4]  | 0.91452   |
| AveragePolicyStd[5]  | 0.86635   |
| AverageReturn        | -4.3332   |
| MinReturn            | -15.159   |
| MaxReturn            | 7.2266    |
| StdReturn            | 3.3059    |
| AverageEpisodeLength | 18.07     |
| MinEpisodeLength     | 13        |
| MaxEpisodeLength     | 41        |
| StdEpisodeLength     | 3.2226    |
| TotalNEpisodes       | 2533      |
| TotalNSamples        | 44929     |
| ExplainedVariance    | 0.1994    |
------------------------------------
[2019-11-19 11:29:22.211787 UTC] Saving snapshot
[2019-11-19 11:29:22.212470 UTC] Starting iteration 9
[2019-11-19 11:29:22.213025 UTC] Start collecting samples
[2019-11-19 11:29:26.688546 UTC] Computing input variables for policy optimization
[2019-11-19 11:29:26.873923 UTC] Performing policy update
[2019-11-19 11:29:26.875026 UTC] Computing gradient in Euclidean space
[2019-11-19 11:29:26.932948 UTC] Computing approximate natural gradient using conjugate gradient algorithm
[2019-11-19 11:29:27.517274 UTC] Performing line search
[2019-11-19 11:29:27.603906 UTC] Updating baseline
[2019-11-19 11:29:28.461345 UTC] Computing logging information
------------------------------------
| Iteration            | 9         |
| ExpectedImprovement  | 0.031694  |
| ActualImprovement    | 0.031446  |
| ImprovementRatio     | 0.99216   |
| MeanKL               | 0.0066874 |
| Entropy              | 7.7251    |
| Perplexity           | 2264.4    |
| AveragePolicyStd     | 0.87708   |
| AveragePolicyStd[0]  | 0.88939   |
| AveragePolicyStd[1]  | 0.90659   |
| AveragePolicyStd[2]  | 0.8728    |
| AveragePolicyStd[3]  | 0.85761   |
| AveragePolicyStd[4]  | 0.88907   |
| AveragePolicyStd[5]  | 0.84702   |
| AverageReturn        | -3.9885   |
| MinReturn            | -17.283   |
| MaxReturn            | 3.0187    |
| StdReturn            | 3.1338    |
| AverageEpisodeLength | 18.08     |
| MinEpisodeLength     | 14        |
| MaxEpisodeLength     | 32        |
| StdEpisodeLength     | 2.3095    |
| TotalNEpisodes       | 2812      |
| TotalNSamples        | 49985     |
| ExplainedVariance    | 0.21865   |
------------------------------------
[2019-11-19 11:29:29.364449 UTC] Saving snapshot
[2019-11-19 11:29:29.365355 UTC] Starting iteration 10
[2019-11-19 11:29:29.365967 UTC] Start collecting samples
[2019-11-19 11:29:33.765837 UTC] Computing input variables for policy optimization
[2019-11-19 11:29:33.945193 UTC] Performing policy update
[2019-11-19 11:29:33.946205 UTC] Computing gradient in Euclidean space
[2019-11-19 11:29:34.002323 UTC] Computing approximate natural gradient using conjugate gradient algorithm
[2019-11-19 11:29:34.586363 UTC] Performing line search
[2019-11-19 11:29:34.669045 UTC] Updating baseline
[2019-11-19 11:29:35.433767 UTC] Computing logging information
------------------------------------
| Iteration            | 10        |
| ExpectedImprovement  | 0.031087  |
| ActualImprovement    | 0.03032   |
| ImprovementRatio     | 0.9753    |
| MeanKL               | 0.0065242 |
| Entropy              | 7.6189    |
| Perplexity           | 2036.4    |
| AveragePolicyStd     | 0.86171   |
| AveragePolicyStd[0]  | 0.8807    |
| AveragePolicyStd[1]  | 0.89319   |
| AveragePolicyStd[2]  | 0.8508    |
| AveragePolicyStd[3]  | 0.84675   |
| AveragePolicyStd[4]  | 0.86613   |
| AveragePolicyStd[5]  | 0.83272   |
| AverageReturn        | -3.4358   |
| MinReturn            | -19.245   |
| MaxReturn            | 3.6251    |
| StdReturn            | 3.5419    |
| AverageEpisodeLength | 18.24     |
| MinEpisodeLength     | 14        |
| MaxEpisodeLength     | 31        |
| StdEpisodeLength     | 2.5224    |
| TotalNEpisodes       | 3086      |
| TotalNSamples        | 54975     |
| ExplainedVariance    | 0.20509   |
------------------------------------
[2019-11-19 11:29:36.390784 UTC] Saving snapshot
[2019-11-19 11:29:36.416925 UTC] Starting iteration 11
[2019-11-19 11:29:36.420059 UTC] Start collecting samples
[2019-11-19 11:29:40.762130 UTC] Computing input variables for policy optimization
[2019-11-19 11:29:40.935137 UTC] Performing policy update
[2019-11-19 11:29:40.936321 UTC] Computing gradient in Euclidean space
[2019-11-19 11:29:40.992233 UTC] Computing approximate natural gradient using conjugate gradient algorithm
[2019-11-19 11:29:41.580225 UTC] Performing line search
[2019-11-19 11:29:41.664700 UTC] Updating baseline
[2019-11-19 11:29:42.419748 UTC] Computing logging information
------------------------------------
| Iteration            | 11        |
| ExpectedImprovement  | 0.03062   |
| ActualImprovement    | 0.030079  |
| ImprovementRatio     | 0.98234   |
| MeanKL               | 0.0065076 |
| Entropy              | 7.4998    |
| Perplexity           | 1807.7    |
| AveragePolicyStd     | 0.84484   |
| AveragePolicyStd[0]  | 0.86692   |
| AveragePolicyStd[1]  | 0.87488   |
| AveragePolicyStd[2]  | 0.8378    |
| AveragePolicyStd[3]  | 0.82535   |
| AveragePolicyStd[4]  | 0.85366   |
| AveragePolicyStd[5]  | 0.81044   |
| AverageReturn        | -1.5853   |
| MinReturn            | -18.272   |
| MaxReturn            | 9.2384    |
| StdReturn            | 3.763     |
| AverageEpisodeLength | 19.34     |
| MinEpisodeLength     | 14        |
| MaxEpisodeLength     | 39        |
| StdEpisodeLength     | 4.5546    |
| TotalNEpisodes       | 3354      |
| TotalNSamples        | 59994     |
| ExplainedVariance    | 0.16693   |
------------------------------------
[2019-11-19 11:29:43.178408 UTC] Saving snapshot
[2019-11-19 11:29:43.179040 UTC] Starting iteration 12
[2019-11-19 11:29:43.179528 UTC] Start collecting samples
[2019-11-19 11:29:47.465776 UTC] Computing input variables for policy optimization
[2019-11-19 11:29:47.636922 UTC] Performing policy update
[2019-11-19 11:29:47.638273 UTC] Computing gradient in Euclidean space
[2019-11-19 11:29:47.701462 UTC] Computing approximate natural gradient using conjugate gradient algorithm
[2019-11-19 11:29:48.292325 UTC] Performing line search
[2019-11-19 11:29:48.379822 UTC] Updating baseline
[2019-11-19 11:29:49.159520 UTC] Computing logging information
------------------------------------
| Iteration            | 12        |
| ExpectedImprovement  | 0.026591  |
| ActualImprovement    | 0.026241  |
| ImprovementRatio     | 0.98684   |
| MeanKL               | 0.0066572 |
| Entropy              | 7.3778    |
| Perplexity           | 1600.1    |
| AveragePolicyStd     | 0.82784   |
| AveragePolicyStd[0]  | 0.85061   |
| AveragePolicyStd[1]  | 0.86033   |
| AveragePolicyStd[2]  | 0.81925   |
| AveragePolicyStd[3]  | 0.80984   |
| AveragePolicyStd[4]  | 0.83118   |
| AveragePolicyStd[5]  | 0.79584   |
| AverageReturn        | -1.5592   |
| MinReturn            | -14.69    |
| MaxReturn            | 14.594    |
| StdReturn            | 3.8949    |
| AverageEpisodeLength | 18.56     |
| MinEpisodeLength     | 13        |
| MaxEpisodeLength     | 32        |
| StdEpisodeLength     | 3.3146    |
| TotalNEpisodes       | 3623      |
| TotalNSamples        | 64965     |
| ExplainedVariance    | 0.15261   |
------------------------------------
[2019-11-19 11:29:50.099569 UTC] Saving snapshot
[2019-11-19 11:29:50.100132 UTC] Starting iteration 13
[2019-11-19 11:29:50.100678 UTC] Start collecting samples
[2019-11-19 11:29:54.672207 UTC] Computing input variables for policy optimization
[2019-11-19 11:29:54.849918 UTC] Performing policy update
[2019-11-19 11:29:54.851086 UTC] Computing gradient in Euclidean space
[2019-11-19 11:29:54.909534 UTC] Computing approximate natural gradient using conjugate gradient algorithm
[2019-11-19 11:29:55.499050 UTC] Performing line search
[2019-11-19 11:29:55.586044 UTC] Updating baseline
[2019-11-19 11:29:56.432364 UTC] Computing logging information
------------------------------------
| Iteration            | 13        |
| ExpectedImprovement  | 0.027437  |
| ActualImprovement    | 0.026875  |
| ImprovementRatio     | 0.97952   |
| MeanKL               | 0.0066518 |
| Entropy              | 7.2423    |
| Perplexity           | 1397.3    |
| AveragePolicyStd     | 0.80933   |
| AveragePolicyStd[0]  | 0.82857   |
| AveragePolicyStd[1]  | 0.84325   |
| AveragePolicyStd[2]  | 0.79775   |
| AveragePolicyStd[3]  | 0.7939    |
| AveragePolicyStd[4]  | 0.81144   |
| AveragePolicyStd[5]  | 0.78106   |
| AverageReturn        | -0.32119  |
| MinReturn            | -8.3009   |
| MaxReturn            | 6.4494    |
| StdReturn            | 3.0081    |
| AverageEpisodeLength | 18.19     |
| MinEpisodeLength     | 14        |
| MaxEpisodeLength     | 30        |
| StdEpisodeLength     | 2.1152    |
| TotalNEpisodes       | 3894      |
| TotalNSamples        | 69964     |
| ExplainedVariance    | 0.21736   |
------------------------------------
[2019-11-19 11:29:57.227233 UTC] Saving snapshot
[2019-11-19 11:29:57.227701 UTC] Starting iteration 14
[2019-11-19 11:29:57.228221 UTC] Start collecting samples
[2019-11-19 11:30:01.494861 UTC] Computing input variables for policy optimization
[2019-11-19 11:30:01.663124 UTC] Performing policy update
[2019-11-19 11:30:01.664047 UTC] Computing gradient in Euclidean space
[2019-11-19 11:30:01.720382 UTC] Computing approximate natural gradient using conjugate gradient algorithm
[2019-11-19 11:30:02.304919 UTC] Performing line search
[2019-11-19 11:30:02.394367 UTC] Updating baseline
[2019-11-19 11:30:03.199246 UTC] Computing logging information
------------------------------------
| Iteration            | 14        |
| ExpectedImprovement  | 0.02449   |
| ActualImprovement    | 0.023687  |
| ImprovementRatio     | 0.96721   |
| MeanKL               | 0.0067784 |
| Entropy              | 7.1222    |
| Perplexity           | 1239.2    |
| AveragePolicyStd     | 0.79328   |
| AveragePolicyStd[0]  | 0.81005   |
| AveragePolicyStd[1]  | 0.8255    |
| AveragePolicyStd[2]  | 0.78455   |
| AveragePolicyStd[3]  | 0.773     |
| AveragePolicyStd[4]  | 0.79914   |
| AveragePolicyStd[5]  | 0.76745   |
| AverageReturn        | 0.18749   |
| MinReturn            | -9.2506   |
| MaxReturn            | 11.638    |
| StdReturn            | 3.5296    |
| AverageEpisodeLength | 18.64     |
| MinEpisodeLength     | 15        |
| MaxEpisodeLength     | 34        |
| StdEpisodeLength     | 2.9783    |
| TotalNEpisodes       | 4162      |
| TotalNSamples        | 74983     |
| ExplainedVariance    | 0.21366   |
------------------------------------
[2019-11-19 11:30:04.000306 UTC] Saving snapshot
[2019-11-19 11:30:04.000736 UTC] Starting iteration 15
[2019-11-19 11:30:04.001140 UTC] Start collecting samples
[2019-11-19 11:30:08.640421 UTC] Computing input variables for policy optimization
[2019-11-19 11:30:08.816402 UTC] Performing policy update
[2019-11-19 11:30:08.817395 UTC] Computing gradient in Euclidean space
[2019-11-19 11:30:08.873544 UTC] Computing approximate natural gradient using conjugate gradient algorithm
[2019-11-19 11:30:09.453989 UTC] Performing line search
[2019-11-19 11:30:09.535548 UTC] Updating baseline
[2019-11-19 11:30:10.347653 UTC] Computing logging information
------------------------------------
| Iteration            | 15        |
| ExpectedImprovement  | 0.025934  |
| ActualImprovement    | 0.025129  |
| ImprovementRatio     | 0.96897   |
| MeanKL               | 0.0064908 |
| Entropy              | 6.9927    |
| Perplexity           | 1088.7    |
| AveragePolicyStd     | 0.77636   |
| AveragePolicyStd[0]  | 0.7883    |
| AveragePolicyStd[1]  | 0.81311   |
| AveragePolicyStd[2]  | 0.76977   |
| AveragePolicyStd[3]  | 0.75773   |
| AveragePolicyStd[4]  | 0.77787   |
| AveragePolicyStd[5]  | 0.75138   |
| AverageReturn        | 0.42488   |
| MinReturn            | -8.4063   |
| MaxReturn            | 10.108    |
| StdReturn            | 2.9468    |
| AverageEpisodeLength | 18.5      |
| MinEpisodeLength     | 15        |
| MaxEpisodeLength     | 29        |
| StdEpisodeLength     | 2.2956    |
| TotalNEpisodes       | 4430      |
| TotalNSamples        | 79995     |
| ExplainedVariance    | 0.28448   |
------------------------------------
[2019-11-19 11:30:11.221427 UTC] Saving snapshot
[2019-11-19 11:30:11.221991 UTC] Starting iteration 16
[2019-11-19 11:30:11.222501 UTC] Start collecting samples
[2019-11-19 11:30:16.151213 UTC] Computing input variables for policy optimization
[2019-11-19 11:30:16.318335 UTC] Performing policy update
[2019-11-19 11:30:16.319293 UTC] Computing gradient in Euclidean space
[2019-11-19 11:30:16.374794 UTC] Computing approximate natural gradient using conjugate gradient algorithm
[2019-11-19 11:30:16.959294 UTC] Performing line search
[2019-11-19 11:30:17.047083 UTC] Updating baseline
[2019-11-19 11:30:17.820536 UTC] Computing logging information
------------------------------------
| Iteration            | 16        |
| ExpectedImprovement  | 0.028916  |
| ActualImprovement    | 0.028513  |
| ImprovementRatio     | 0.98606   |
| MeanKL               | 0.0066753 |
| Entropy              | 6.8634    |
| Perplexity           | 956.63    |
| AveragePolicyStd     | 0.75989   |
| AveragePolicyStd[0]  | 0.77498   |
| AveragePolicyStd[1]  | 0.80073   |
| AveragePolicyStd[2]  | 0.75256   |
| AveragePolicyStd[3]  | 0.7382    |
| AveragePolicyStd[4]  | 0.76115   |
| AveragePolicyStd[5]  | 0.73173   |
| AverageReturn        | 1.5262    |
| MinReturn            | -4.7124   |
| MaxReturn            | 9.2235    |
| StdReturn            | 2.8298    |
| AverageEpisodeLength | 18.33     |
| MinEpisodeLength     | 14        |
| MaxEpisodeLength     | 30        |
| StdEpisodeLength     | 1.855     |
| TotalNEpisodes       | 4703      |
| TotalNSamples        | 85006     |
| ExplainedVariance    | 0.2773    |
------------------------------------
[2019-11-19 11:30:19.042924 UTC] Saving snapshot
[2019-11-19 11:30:19.043617 UTC] Starting iteration 17
[2019-11-19 11:30:19.044405 UTC] Start collecting samples
[2019-11-19 11:30:23.755150 UTC] Computing input variables for policy optimization
[2019-11-19 11:30:23.923947 UTC] Performing policy update
[2019-11-19 11:30:23.925210 UTC] Computing gradient in Euclidean space
[2019-11-19 11:30:23.983634 UTC] Computing approximate natural gradient using conjugate gradient algorithm
[2019-11-19 11:30:24.566980 UTC] Performing line search
[2019-11-19 11:30:24.655126 UTC] Updating baseline
[2019-11-19 11:30:25.430150 UTC] Computing logging information
------------------------------------
| Iteration            | 17        |
| ExpectedImprovement  | 0.02566   |
| ActualImprovement    | 0.025261  |
| ImprovementRatio     | 0.98445   |
| MeanKL               | 0.0066407 |
| Entropy              | 6.7288    |
| Perplexity           | 836.15    |
| AveragePolicyStd     | 0.7431    |
| AveragePolicyStd[0]  | 0.75772   |
| AveragePolicyStd[1]  | 0.78614   |
| AveragePolicyStd[2]  | 0.74091   |
| AveragePolicyStd[3]  | 0.71559   |
| AveragePolicyStd[4]  | 0.74396   |
| AveragePolicyStd[5]  | 0.71428   |
| AverageReturn        | 2.0908    |
| MinReturn            | -5.3451   |
| MaxReturn            | 9.9509    |
| StdReturn            | 2.9531    |
| AverageEpisodeLength | 19.03     |
| MinEpisodeLength     | 16        |
| MaxEpisodeLength     | 31        |
| StdEpisodeLength     | 2.563     |
| TotalNEpisodes       | 4970      |
| TotalNSamples        | 89994     |
| ExplainedVariance    | 0.30685   |
------------------------------------
[2019-11-19 11:30:26.334271 UTC] Saving snapshot
[2019-11-19 11:30:26.335251 UTC] Starting iteration 18
[2019-11-19 11:30:26.336023 UTC] Start collecting samples
[2019-11-19 11:30:31.142860 UTC] Computing input variables for policy optimization
[2019-11-19 11:30:31.315539 UTC] Performing policy update
[2019-11-19 11:30:31.316894 UTC] Computing gradient in Euclidean space
[2019-11-19 11:30:31.407546 UTC] Computing approximate natural gradient using conjugate gradient algorithm
[2019-11-19 11:30:32.014200 UTC] Performing line search
[2019-11-19 11:30:32.114149 UTC] Updating baseline
[2019-11-19 11:30:33.052484 UTC] Computing logging information
-----------------------------------
| Iteration            | 18       |
| ExpectedImprovement  | 0.02532  |
| ActualImprovement    | 0.024944 |
| ImprovementRatio     | 0.98512  |
| MeanKL               | 0.00673  |
| Entropy              | 6.6016   |
| Perplexity           | 736.29   |
| AveragePolicyStd     | 0.72754  |
| AveragePolicyStd[0]  | 0.74314  |
| AveragePolicyStd[1]  | 0.76805  |
| AveragePolicyStd[2]  | 0.72388  |
| AveragePolicyStd[3]  | 0.69619  |
| AveragePolicyStd[4]  | 0.7346   |
| AveragePolicyStd[5]  | 0.69938  |
| AverageReturn        | 1.7614   |
| MinReturn            | -4.9727  |
| MaxReturn            | 11.687   |
| StdReturn            | 2.8646   |
| AverageEpisodeLength | 18.63    |
| MinEpisodeLength     | 16       |
| MaxEpisodeLength     | 34       |
| StdEpisodeLength     | 2.2345   |
| TotalNEpisodes       | 5235     |
| TotalNSamples        | 94986    |
| ExplainedVariance    | 0.35103  |
-----------------------------------
[2019-11-19 11:30:34.051614 UTC] Saving snapshot
[2019-11-19 11:30:34.052352 UTC] Starting iteration 19
[2019-11-19 11:30:34.053015 UTC] Start collecting samples
[2019-11-19 11:30:39.604652 UTC] Computing input variables for policy optimization
[2019-11-19 11:30:39.782473 UTC] Performing policy update
[2019-11-19 11:30:39.783851 UTC] Computing gradient in Euclidean space
[2019-11-19 11:30:39.841892 UTC] Computing approximate natural gradient using conjugate gradient algorithm
[2019-11-19 11:30:40.486085 UTC] Performing line search
[2019-11-19 11:30:40.573985 UTC] Updating baseline
[2019-11-19 11:30:41.401631 UTC] Computing logging information
------------------------------------
| Iteration            | 19        |
| ExpectedImprovement  | 0.026616  |
| ActualImprovement    | 0.026139  |
| ImprovementRatio     | 0.98209   |
| MeanKL               | 0.0067466 |
| Entropy              | 6.4746    |
| Perplexity           | 648.47    |
| AveragePolicyStd     | 0.71239   |
| AveragePolicyStd[0]  | 0.72788   |
| AveragePolicyStd[1]  | 0.75316   |
| AveragePolicyStd[2]  | 0.7023    |
| AveragePolicyStd[3]  | 0.67678   |
| AveragePolicyStd[4]  | 0.72878   |
| AveragePolicyStd[5]  | 0.68541   |
| AverageReturn        | 2.7439    |
| MinReturn            | -5.5965   |
| MaxReturn            | 8.4007    |
| StdReturn            | 2.895     |
| AverageEpisodeLength | 19.15     |
| MinEpisodeLength     | 16        |
| MaxEpisodeLength     | 32        |
| StdEpisodeLength     | 2.6434    |
| TotalNEpisodes       | 5497      |
| TotalNSamples        | 99983     |
| ExplainedVariance    | 0.34917   |
------------------------------------
[2019-11-19 11:30:42.759403 UTC] Saving snapshot
[2019-11-19 11:30:42.760213 UTC] Starting iteration 20
[2019-11-19 11:30:42.761192 UTC] Start collecting samples
[2019-11-19 11:30:48.169257 UTC] Computing input variables for policy optimization
[2019-11-19 11:30:48.352278 UTC] Performing policy update
[2019-11-19 11:30:48.353585 UTC] Computing gradient in Euclidean space
[2019-11-19 11:30:48.410315 UTC] Computing approximate natural gradient using conjugate gradient algorithm
[2019-11-19 11:30:49.019150 UTC] Performing line search
[2019-11-19 11:30:49.104381 UTC] Updating baseline
[2019-11-19 11:30:49.911548 UTC] Computing logging information
-------------------------------------
| Iteration            | 20         |
| ExpectedImprovement  | 0.025759   |
| ActualImprovement    | 0.025474   |
| ImprovementRatio     | 0.98891    |
| MeanKL               | 0.0065753  |
| Entropy              | 6.3482     |
| Perplexity           | 571.44     |
| AveragePolicyStd     | 0.69754    |
| AveragePolicyStd[0]  | 0.71013    |
| AveragePolicyStd[1]  | 0.73838    |
| AveragePolicyStd[2]  | 0.69195    |
| AveragePolicyStd[3]  | 0.6646     |
| AveragePolicyStd[4]  | 0.71382    |
| AveragePolicyStd[5]  | 0.66636    |
| AverageReturn        | 3.2805     |
| MinReturn            | -6.4914    |
| MaxReturn            | 13.649     |
| StdReturn            | 3.1404     |
| AverageEpisodeLength | 18.96      |
| MinEpisodeLength     | 16         |
| MaxEpisodeLength     | 33         |
| StdEpisodeLength     | 2.6755     |
| TotalNEpisodes       | 5763       |
| TotalNSamples        | 1.0501e+05 |
| ExplainedVariance    | 0.43725    |
-------------------------------------
[2019-11-19 11:30:50.913403 UTC] Saving snapshot
[2019-11-19 11:30:50.929304 UTC] Starting iteration 21
[2019-11-19 11:30:50.929879 UTC] Start collecting samples
[2019-11-19 11:30:56.027105 UTC] Computing input variables for policy optimization
[2019-11-19 11:30:56.203836 UTC] Performing policy update
[2019-11-19 11:30:56.205078 UTC] Computing gradient in Euclidean space
[2019-11-19 11:30:56.262156 UTC] Computing approximate natural gradient using conjugate gradient algorithm
[2019-11-19 11:30:56.856139 UTC] Performing line search
[2019-11-19 11:30:56.938315 UTC] Updating baseline
[2019-11-19 11:30:57.723322 UTC] Computing logging information
-------------------------------------
| Iteration            | 21         |
| ExpectedImprovement  | 0.023931   |
| ActualImprovement    | 0.023452   |
| ImprovementRatio     | 0.98       |
| MeanKL               | 0.0066447  |
| Entropy              | 6.2403     |
| Perplexity           | 513        |
| AveragePolicyStd     | 0.68525    |
| AveragePolicyStd[0]  | 0.68894    |
| AveragePolicyStd[1]  | 0.73517    |
| AveragePolicyStd[2]  | 0.67668    |
| AveragePolicyStd[3]  | 0.65035    |
| AveragePolicyStd[4]  | 0.70652    |
| AveragePolicyStd[5]  | 0.65385    |
| AverageReturn        | 4.1192     |
| MinReturn            | -6.8761    |
| MaxReturn            | 15.763     |
| StdReturn            | 3.4383     |
| AverageEpisodeLength | 19.81      |
| MinEpisodeLength     | 14         |
| MaxEpisodeLength     | 38         |
| StdEpisodeLength     | 3.714      |
| TotalNEpisodes       | 6022       |
| TotalNSamples        | 1.1001e+05 |
| ExplainedVariance    | 0.42018    |
-------------------------------------
[2019-11-19 11:30:58.926989 UTC] Saving snapshot
[2019-11-19 11:30:58.928158 UTC] Starting iteration 22
[2019-11-19 11:30:58.929048 UTC] Start collecting samples
[2019-11-19 11:31:03.987386 UTC] Computing input variables for policy optimization
[2019-11-19 11:31:04.149764 UTC] Performing policy update
[2019-11-19 11:31:04.151064 UTC] Computing gradient in Euclidean space
[2019-11-19 11:31:04.206726 UTC] Computing approximate natural gradient using conjugate gradient algorithm
[2019-11-19 11:31:04.796495 UTC] Performing line search
[2019-11-19 11:31:04.881149 UTC] Updating baseline
[2019-11-19 11:31:05.698047 UTC] Computing logging information
-------------------------------------
| Iteration            | 22         |
| ExpectedImprovement  | 0.022968   |
| ActualImprovement    | 0.022823   |
| ImprovementRatio     | 0.99369    |
| MeanKL               | 0.0066713  |
| Entropy              | 6.109      |
| Perplexity           | 449.89     |
| AveragePolicyStd     | 0.67049    |
| AveragePolicyStd[0]  | 0.67052    |
| AveragePolicyStd[1]  | 0.72205    |
| AveragePolicyStd[2]  | 0.65836    |
| AveragePolicyStd[3]  | 0.63802    |
| AveragePolicyStd[4]  | 0.69645    |
| AveragePolicyStd[5]  | 0.63755    |
| AverageReturn        | 4.1784     |
| MinReturn            | -3.8859    |
| MaxReturn            | 13.032     |
| StdReturn            | 2.8903     |
| AverageEpisodeLength | 19.2       |
| MinEpisodeLength     | 16         |
| MaxEpisodeLength     | 31         |
| StdEpisodeLength     | 2.5259     |
| TotalNEpisodes       | 6281       |
| TotalNSamples        | 1.1502e+05 |
| ExplainedVariance    | 0.47592    |
-------------------------------------
[2019-11-19 11:31:07.285069 UTC] Saving snapshot
[2019-11-19 11:31:07.286306 UTC] Starting iteration 23
[2019-11-19 11:31:07.286989 UTC] Start collecting samples
[2019-11-19 11:31:12.148250 UTC] Computing input variables for policy optimization
[2019-11-19 11:31:12.315050 UTC] Performing policy update
[2019-11-19 11:31:12.316272 UTC] Computing gradient in Euclidean space
[2019-11-19 11:31:12.374213 UTC] Computing approximate natural gradient using conjugate gradient algorithm
[2019-11-19 11:31:12.969906 UTC] Performing line search
[2019-11-19 11:31:13.054590 UTC] Updating baseline
[2019-11-19 11:31:13.846857 UTC] Computing logging information
-------------------------------------
| Iteration            | 23         |
| ExpectedImprovement  | 0.024226   |
| ActualImprovement    | 0.023716   |
| ImprovementRatio     | 0.97895    |
| MeanKL               | 0.006838   |
| Entropy              | 5.9789     |
| Perplexity           | 395.01     |
| AveragePolicyStd     | 0.65622    |
| AveragePolicyStd[0]  | 0.6636     |
| AveragePolicyStd[1]  | 0.7098     |
| AveragePolicyStd[2]  | 0.64107    |
| AveragePolicyStd[3]  | 0.61527    |
| AveragePolicyStd[4]  | 0.6802     |
| AveragePolicyStd[5]  | 0.62739    |
| AverageReturn        | 4.2613     |
| MinReturn            | -2.0888    |
| MaxReturn            | 11.259     |
| StdReturn            | 2.5085     |
| AverageEpisodeLength | 19.01      |
| MinEpisodeLength     | 15         |
| MaxEpisodeLength     | 27         |
| StdEpisodeLength     | 1.8193     |
| TotalNEpisodes       | 6545       |
| TotalNSamples        | 1.2008e+05 |
| ExplainedVariance    | 0.51083    |
-------------------------------------
[2019-11-19 11:31:14.847029 UTC] Saving snapshot
[2019-11-19 11:31:14.848057 UTC] Starting iteration 24
[2019-11-19 11:31:14.848686 UTC] Start collecting samples
[2019-11-19 11:31:20.260344 UTC] Computing input variables for policy optimization
[2019-11-19 11:31:20.429790 UTC] Performing policy update
[2019-11-19 11:31:20.431126 UTC] Computing gradient in Euclidean space
[2019-11-19 11:31:20.485375 UTC] Computing approximate natural gradient using conjugate gradient algorithm
[2019-11-19 11:31:21.065888 UTC] Performing line search
[2019-11-19 11:31:21.149724 UTC] Updating baseline
[2019-11-19 11:31:21.924162 UTC] Computing logging information
-------------------------------------
| Iteration            | 24         |
| ExpectedImprovement  | 0.025412   |
| ActualImprovement    | 0.024472   |
| ImprovementRatio     | 0.96301    |
| MeanKL               | 0.0066667  |
| Entropy              | 5.8567     |
| Perplexity           | 349.55     |
| AveragePolicyStd     | 0.64307    |
| AveragePolicyStd[0]  | 0.64903    |
| AveragePolicyStd[1]  | 0.69866    |
| AveragePolicyStd[2]  | 0.63826    |
| AveragePolicyStd[3]  | 0.59625    |
| AveragePolicyStd[4]  | 0.66298    |
| AveragePolicyStd[5]  | 0.61323    |
| AverageReturn        | 5.1507     |
| MinReturn            | -3.305     |
| MaxReturn            | 13.66      |
| StdReturn            | 2.9287     |
| AverageEpisodeLength | 19.31      |
| MinEpisodeLength     | 15         |
| MaxEpisodeLength     | 41         |
| StdEpisodeLength     | 3.3547     |
| TotalNEpisodes       | 6804       |
| TotalNSamples        | 1.2507e+05 |
| ExplainedVariance    | 0.51689    |
-------------------------------------
[2019-11-19 11:31:22.865289 UTC] Saving snapshot
[2019-11-19 11:31:22.865787 UTC] Starting iteration 25
[2019-11-19 11:31:22.866230 UTC] Start collecting samples
[2019-11-19 11:31:28.079721 UTC] Computing input variables for policy optimization
[2019-11-19 11:31:28.268060 UTC] Performing policy update
[2019-11-19 11:31:28.269487 UTC] Computing gradient in Euclidean space
[2019-11-19 11:31:28.332750 UTC] Computing approximate natural gradient using conjugate gradient algorithm
[2019-11-19 11:31:28.973543 UTC] Performing line search
[2019-11-19 11:31:29.055555 UTC] Updating baseline
[2019-11-19 11:31:29.805382 UTC] Computing logging information
-------------------------------------
| Iteration            | 25         |
| ExpectedImprovement  | 0.021465   |
| ActualImprovement    | 0.021225   |
| ImprovementRatio     | 0.98883    |
| MeanKL               | 0.0065472  |
| Entropy              | 5.7201     |
| Perplexity           | 304.93     |
| AveragePolicyStd     | 0.62855    |
| AveragePolicyStd[0]  | 0.63024    |
| AveragePolicyStd[1]  | 0.67621    |
| AveragePolicyStd[2]  | 0.62338    |
| AveragePolicyStd[3]  | 0.58383    |
| AveragePolicyStd[4]  | 0.65757    |
| AveragePolicyStd[5]  | 0.60008    |
| AverageReturn        | 5.6398     |
| MinReturn            | -3.3984    |
| MaxReturn            | 12.088     |
| StdReturn            | 2.6991     |
| AverageEpisodeLength | 19.32      |
| MinEpisodeLength     | 17         |
| MaxEpisodeLength     | 30         |
| StdEpisodeLength     | 2.2311     |
| TotalNEpisodes       | 7061       |
| TotalNSamples        | 1.3006e+05 |
| ExplainedVariance    | 0.5556     |
-------------------------------------
[2019-11-19 11:31:30.988253 UTC] Saving snapshot
[2019-11-19 11:31:30.989039 UTC] Starting iteration 26
[2019-11-19 11:31:30.989941 UTC] Start collecting samples
[2019-11-19 11:31:36.814879 UTC] Computing input variables for policy optimization
[2019-11-19 11:31:37.027795 UTC] Performing policy update
[2019-11-19 11:31:37.034380 UTC] Computing gradient in Euclidean space
[2019-11-19 11:31:37.117351 UTC] Computing approximate natural gradient using conjugate gradient algorithm
[2019-11-19 11:31:38.003485 UTC] Performing line search
[2019-11-19 11:31:38.135698 UTC] Updating baseline
[2019-11-19 11:31:39.420180 UTC] Computing logging information
-------------------------------------
| Iteration            | 26         |
| ExpectedImprovement  | 0.022967   |
| ActualImprovement    | 0.022605   |
| ImprovementRatio     | 0.98421    |
| MeanKL               | 0.0065747  |
| Entropy              | 5.6166     |
| Perplexity           | 274.96     |
| AveragePolicyStd     | 0.61776    |
| AveragePolicyStd[0]  | 0.62048    |
| AveragePolicyStd[1]  | 0.66824    |
| AveragePolicyStd[2]  | 0.60608    |
| AveragePolicyStd[3]  | 0.57659    |
| AveragePolicyStd[4]  | 0.64097    |
| AveragePolicyStd[5]  | 0.59422    |
| AverageReturn        | 6.277      |
| MinReturn            | -1.1136    |
| MaxReturn            | 17.095     |
| StdReturn            | 3.4293     |
| AverageEpisodeLength | 20.17      |
| MinEpisodeLength     | 16         |
| MaxEpisodeLength     | 39         |
| StdEpisodeLength     | 3.6825     |
| TotalNEpisodes       | 7313       |
| TotalNSamples        | 1.3508e+05 |
| ExplainedVariance    | 0.51418    |
-------------------------------------
[2019-11-19 11:31:41.441768 UTC] Saving snapshot
[2019-11-19 11:31:41.442550 UTC] Starting iteration 27
[2019-11-19 11:31:41.443278 UTC] Start collecting samples
[2019-11-19 11:31:46.629591 UTC] Computing input variables for policy optimization
[2019-11-19 11:31:46.786163 UTC] Performing policy update
[2019-11-19 11:31:46.787355 UTC] Computing gradient in Euclidean space
[2019-11-19 11:31:46.842511 UTC] Computing approximate natural gradient using conjugate gradient algorithm
[2019-11-19 11:31:47.435275 UTC] Performing line search
[2019-11-19 11:31:47.515647 UTC] Updating baseline
[2019-11-19 11:31:48.514115 UTC] Computing logging information
-------------------------------------
| Iteration            | 27         |
| ExpectedImprovement  | 0.024216   |
| ActualImprovement    | 0.024018   |
| ImprovementRatio     | 0.99182    |
| MeanKL               | 0.0065386  |
| Entropy              | 5.4859     |
| Perplexity           | 241.27     |
| AveragePolicyStd     | 0.60457    |
| AveragePolicyStd[0]  | 0.60736    |
| AveragePolicyStd[1]  | 0.65769    |
| AveragePolicyStd[2]  | 0.59091    |
| AveragePolicyStd[3]  | 0.55911    |
| AveragePolicyStd[4]  | 0.62886    |
| AveragePolicyStd[5]  | 0.5835     |
| AverageReturn        | 6.7955     |
| MinReturn            | -0.91762   |
| MaxReturn            | 16.583     |
| StdReturn            | 3.0603     |
| AverageEpisodeLength | 19.82      |
| MinEpisodeLength     | 14         |
| MaxEpisodeLength     | 30         |
| StdEpisodeLength     | 2.707      |
| TotalNEpisodes       | 7564       |
| TotalNSamples        | 1.4008e+05 |
| ExplainedVariance    | 0.60729    |
-------------------------------------
[2019-11-19 11:31:51.115011 UTC] Saving snapshot
[2019-11-19 11:31:51.115590 UTC] Starting iteration 28
[2019-11-19 11:31:51.116264 UTC] Start collecting samples
[2019-11-19 11:31:56.658994 UTC] Computing input variables for policy optimization
[2019-11-19 11:31:56.813456 UTC] Performing policy update
[2019-11-19 11:31:56.814936 UTC] Computing gradient in Euclidean space
[2019-11-19 11:31:56.869627 UTC] Computing approximate natural gradient using conjugate gradient algorithm
[2019-11-19 11:31:57.466659 UTC] Performing line search
[2019-11-19 11:31:57.548955 UTC] Updating baseline
[2019-11-19 11:31:58.379743 UTC] Computing logging information
-------------------------------------
| Iteration            | 28         |
| ExpectedImprovement  | 0.022764   |
| ActualImprovement    | 0.022588   |
| ImprovementRatio     | 0.99225    |
| MeanKL               | 0.0066018  |
| Entropy              | 5.377      |
| Perplexity           | 216.37     |
| AveragePolicyStd     | 0.59364    |
| AveragePolicyStd[0]  | 0.60196    |
| AveragePolicyStd[1]  | 0.64375    |
| AveragePolicyStd[2]  | 0.57629    |
| AveragePolicyStd[3]  | 0.55136    |
| AveragePolicyStd[4]  | 0.61472    |
| AveragePolicyStd[5]  | 0.57377    |
| AverageReturn        | 7.3466     |
| MinReturn            | 0.7886     |
| MaxReturn            | 18.985     |
| StdReturn            | 3.1536     |
| AverageEpisodeLength | 20.11      |
| MinEpisodeLength     | 18         |
| MaxEpisodeLength     | 31         |
| StdEpisodeLength     | 2.9254     |
| TotalNEpisodes       | 7813       |
| TotalNSamples        | 1.4507e+05 |
| ExplainedVariance    | 0.53534    |
-------------------------------------
[2019-11-19 11:31:59.350434 UTC] Saving snapshot
[2019-11-19 11:31:59.351081 UTC] Starting iteration 29
[2019-11-19 11:31:59.351831 UTC] Start collecting samples
[2019-11-19 11:32:04.260781 UTC] Computing input variables for policy optimization
[2019-11-19 11:32:04.441828 UTC] Performing policy update
[2019-11-19 11:32:04.442992 UTC] Computing gradient in Euclidean space
[2019-11-19 11:32:04.508766 UTC] Computing approximate natural gradient using conjugate gradient algorithm
[2019-11-19 11:32:05.182067 UTC] Performing line search
[2019-11-19 11:32:05.281855 UTC] Updating baseline
[2019-11-19 11:32:06.080143 UTC] Computing logging information
-------------------------------------
| Iteration            | 29         |
| ExpectedImprovement  | 0.023158   |
| ActualImprovement    | 0.022726   |
| ImprovementRatio     | 0.98133    |
| MeanKL               | 0.006627   |
| Entropy              | 5.2779     |
| Perplexity           | 195.96     |
| AveragePolicyStd     | 0.58408    |
| AveragePolicyStd[0]  | 0.58697    |
| AveragePolicyStd[1]  | 0.64053    |
| AveragePolicyStd[2]  | 0.55809    |
| AveragePolicyStd[3]  | 0.5431     |
| AveragePolicyStd[4]  | 0.60919    |
| AveragePolicyStd[5]  | 0.56658    |
| AverageReturn        | 7.6079     |
| MinReturn            | -2.4384    |
| MaxReturn            | 15.461     |
| StdReturn            | 3.0202     |
| AverageEpisodeLength | 19.86      |
| MinEpisodeLength     | 15         |
| MaxEpisodeLength     | 36         |
| StdEpisodeLength     | 2.7677     |
| TotalNEpisodes       | 8064       |
| TotalNSamples        | 1.5009e+05 |
| ExplainedVariance    | 0.53802    |
-------------------------------------
[2019-11-19 11:32:06.988429 UTC] Saving snapshot
[2019-11-19 11:32:06.989141 UTC] Starting iteration 30
[2019-11-19 11:32:06.989894 UTC] Start collecting samples
[2019-11-19 11:32:11.776826 UTC] Computing input variables for policy optimization
[2019-11-19 11:32:11.939911 UTC] Performing policy update
[2019-11-19 11:32:11.940972 UTC] Computing gradient in Euclidean space
[2019-11-19 11:32:11.997282 UTC] Computing approximate natural gradient using conjugate gradient algorithm
[2019-11-19 11:32:12.578098 UTC] Performing line search
[2019-11-19 11:32:12.660409 UTC] Updating baseline
[2019-11-19 11:32:13.410170 UTC] Computing logging information
------------------------------------
| Iteration            | 30        |
| ExpectedImprovement  | 0.021469  |
| ActualImprovement    | 0.021394  |
| ImprovementRatio     | 0.99649   |
| MeanKL               | 0.0068751 |
| Entropy              | 5.1624    |
| Perplexity           | 174.58    |
| AveragePolicyStd     | 0.57297   |
| AveragePolicyStd[0]  | 0.57349   |
| AveragePolicyStd[1]  | 0.63149   |
| AveragePolicyStd[2]  | 0.55089   |
| AveragePolicyStd[3]  | 0.53078   |
| AveragePolicyStd[4]  | 0.59531   |
| AveragePolicyStd[5]  | 0.55587   |
| AverageReturn        | 8.3019    |
| MinReturn            | 1.9917    |
| MaxReturn            | 20.608    |
| StdReturn            | 3.4542    |
| AverageEpisodeLength | 20.34     |
| MinEpisodeLength     | 17        |
| MaxEpisodeLength     | 35        |
| StdEpisodeLength     | 3.5106    |
| TotalNEpisodes       | 8313      |
| TotalNSamples        | 1.551e+05 |
| ExplainedVariance    | 0.59127   |
------------------------------------
[2019-11-19 11:32:14.542581 UTC] Saving snapshot
[2019-11-19 11:32:14.562750 UTC] Starting iteration 31
[2019-11-19 11:32:14.563409 UTC] Start collecting samples
[2019-11-19 11:32:19.409873 UTC] Computing input variables for policy optimization
[2019-11-19 11:32:19.567849 UTC] Performing policy update
[2019-11-19 11:32:19.569376 UTC] Computing gradient in Euclidean space
[2019-11-19 11:32:19.627564 UTC] Computing approximate natural gradient using conjugate gradient algorithm
[2019-11-19 11:32:20.215126 UTC] Performing line search
[2019-11-19 11:32:20.298965 UTC] Updating baseline
[2019-11-19 11:32:21.073104 UTC] Computing logging information
-------------------------------------
| Iteration            | 31         |
| ExpectedImprovement  | 0.024467   |
| ActualImprovement    | 0.024386   |
| ImprovementRatio     | 0.9967     |
| MeanKL               | 0.0066075  |
| Entropy              | 5.0432     |
| Perplexity           | 154.96     |
| AveragePolicyStd     | 0.56176    |
| AveragePolicyStd[0]  | 0.55667    |
| AveragePolicyStd[1]  | 0.62506    |
| AveragePolicyStd[2]  | 0.54045    |
| AveragePolicyStd[3]  | 0.52171    |
| AveragePolicyStd[4]  | 0.58123    |
| AveragePolicyStd[5]  | 0.54543    |
| AverageReturn        | 8.5086     |
| MinReturn            | 2.846      |
| MaxReturn            | 20.711     |
| StdReturn            | 3.0904     |
| AverageEpisodeLength | 19.93      |
| MinEpisodeLength     | 17         |
| MaxEpisodeLength     | 37         |
| StdEpisodeLength     | 2.7614     |
| TotalNEpisodes       | 8563       |
| TotalNSamples        | 1.6011e+05 |
| ExplainedVariance    | 0.60865    |
-------------------------------------
[2019-11-19 11:32:22.016557 UTC] Saving snapshot
[2019-11-19 11:32:22.017679 UTC] Starting iteration 32
[2019-11-19 11:32:22.018628 UTC] Start collecting samples
[2019-11-19 11:32:27.240713 UTC] Computing input variables for policy optimization
[2019-11-19 11:32:27.404212 UTC] Performing policy update
[2019-11-19 11:32:27.405679 UTC] Computing gradient in Euclidean space
[2019-11-19 11:32:27.466813 UTC] Computing approximate natural gradient using conjugate gradient algorithm
[2019-11-19 11:32:28.055311 UTC] Performing line search
[2019-11-19 11:32:28.138503 UTC] Updating baseline
[2019-11-19 11:32:28.898647 UTC] Computing logging information
-------------------------------------
| Iteration            | 32         |
| ExpectedImprovement  | 0.023438   |
| ActualImprovement    | 0.023364   |
| ImprovementRatio     | 0.99683    |
| MeanKL               | 0.0065833  |
| Entropy              | 4.9465     |
| Perplexity           | 140.68     |
| AveragePolicyStd     | 0.5527     |
| AveragePolicyStd[0]  | 0.54344    |
| AveragePolicyStd[1]  | 0.61282    |
| AveragePolicyStd[2]  | 0.53737    |
| AveragePolicyStd[3]  | 0.51483    |
| AveragePolicyStd[4]  | 0.57173    |
| AveragePolicyStd[5]  | 0.53603    |
| AverageReturn        | 8.4878     |
| MinReturn            | 0.14101    |
| MaxReturn            | 19.997     |
| StdReturn            | 2.9995     |
| AverageEpisodeLength | 19.77      |
| MinEpisodeLength     | 15         |
| MaxEpisodeLength     | 40         |
| StdEpisodeLength     | 3.085      |
| TotalNEpisodes       | 8809       |
| TotalNSamples        | 1.6508e+05 |
| ExplainedVariance    | 0.6061     |
-------------------------------------
[2019-11-19 11:32:30.232656 UTC] Saving snapshot
[2019-11-19 11:32:30.233757 UTC] Starting iteration 33
[2019-11-19 11:32:30.234701 UTC] Start collecting samples
[2019-11-19 11:32:35.555140 UTC] Computing input variables for policy optimization
[2019-11-19 11:32:35.715223 UTC] Performing policy update
[2019-11-19 11:32:35.716761 UTC] Computing gradient in Euclidean space
[2019-11-19 11:32:35.777767 UTC] Computing approximate natural gradient using conjugate gradient algorithm
[2019-11-19 11:32:36.362514 UTC] Performing line search
[2019-11-19 11:32:36.445741 UTC] Updating baseline
[2019-11-19 11:32:37.218650 UTC] Computing logging information
-------------------------------------
| Iteration            | 33         |
| ExpectedImprovement  | 0.023443   |
| ActualImprovement    | 0.023321   |
| ImprovementRatio     | 0.99479    |
| MeanKL               | 0.0067247  |
| Entropy              | 4.8583     |
| Perplexity           | 128.81     |
| AveragePolicyStd     | 0.54473    |
| AveragePolicyStd[0]  | 0.53349    |
| AveragePolicyStd[1]  | 0.60785    |
| AveragePolicyStd[2]  | 0.52667    |
| AveragePolicyStd[3]  | 0.50754    |
| AveragePolicyStd[4]  | 0.56442    |
| AveragePolicyStd[5]  | 0.52842    |
| AverageReturn        | 8.9399     |
| MinReturn            | 2.1725     |
| MaxReturn            | 30.002     |
| StdReturn            | 3.6025     |
| AverageEpisodeLength | 20.34      |
| MinEpisodeLength     | 17         |
| MaxEpisodeLength     | 35         |
| StdEpisodeLength     | 3.1913     |
| TotalNEpisodes       | 9057       |
| TotalNSamples        | 1.7011e+05 |
| ExplainedVariance    | 0.66075    |
-------------------------------------
[2019-11-19 11:32:38.575596 UTC] Saving snapshot
[2019-11-19 11:32:38.576526 UTC] Starting iteration 34
[2019-11-19 11:32:38.577249 UTC] Start collecting samples
[2019-11-19 11:32:43.462383 UTC] Computing input variables for policy optimization
[2019-11-19 11:32:43.632220 UTC] Performing policy update
[2019-11-19 11:32:43.633174 UTC] Computing gradient in Euclidean space
[2019-11-19 11:32:43.691868 UTC] Computing approximate natural gradient using conjugate gradient algorithm
[2019-11-19 11:32:44.324472 UTC] Performing line search
[2019-11-19 11:32:44.411668 UTC] Updating baseline
[2019-11-19 11:32:45.178463 UTC] Computing logging information
-------------------------------------
| Iteration            | 34         |
| ExpectedImprovement  | 0.020923   |
| ActualImprovement    | 0.020909   |
| ImprovementRatio     | 0.99935    |
| MeanKL               | 0.0066766  |
| Entropy              | 4.7555     |
| Perplexity           | 116.22     |
| AveragePolicyStd     | 0.53565    |
| AveragePolicyStd[0]  | 0.52114    |
| AveragePolicyStd[1]  | 0.6031     |
| AveragePolicyStd[2]  | 0.523      |
| AveragePolicyStd[3]  | 0.49524    |
| AveragePolicyStd[4]  | 0.55684    |
| AveragePolicyStd[5]  | 0.51461    |
| AverageReturn        | 9.42       |
| MinReturn            | 2.2796     |
| MaxReturn            | 19.939     |
| StdReturn            | 2.9906     |
| AverageEpisodeLength | 20.25      |
| MinEpisodeLength     | 17         |
| MaxEpisodeLength     | 34         |
| StdEpisodeLength     | 2.7798     |
| TotalNEpisodes       | 9304       |
| TotalNSamples        | 1.7515e+05 |
| ExplainedVariance    | 0.60872    |
-------------------------------------
[2019-11-19 11:32:46.709620 UTC] Saving snapshot
[2019-11-19 11:32:46.710403 UTC] Starting iteration 35
[2019-11-19 11:32:46.711130 UTC] Start collecting samples
[2019-11-19 11:32:51.714763 UTC] Computing input variables for policy optimization
[2019-11-19 11:32:51.872232 UTC] Performing policy update
[2019-11-19 11:32:51.873215 UTC] Computing gradient in Euclidean space
[2019-11-19 11:32:51.925111 UTC] Computing approximate natural gradient using conjugate gradient algorithm
[2019-11-19 11:32:52.508876 UTC] Performing line search
[2019-11-19 11:32:52.589402 UTC] Updating baseline
[2019-11-19 11:32:53.360520 UTC] Computing logging information
------------------------------------
| Iteration            | 35        |
| ExpectedImprovement  | 0.023735  |
| ActualImprovement    | 0.023651  |
| ImprovementRatio     | 0.99649   |
| MeanKL               | 0.006668  |
| Entropy              | 4.6868    |
| Perplexity           | 108.51    |
| AveragePolicyStd     | 0.5296    |
| AveragePolicyStd[0]  | 0.51709   |
| AveragePolicyStd[1]  | 0.59981   |
| AveragePolicyStd[2]  | 0.5171    |
| AveragePolicyStd[3]  | 0.48831   |
| AveragePolicyStd[4]  | 0.54576   |
| AveragePolicyStd[5]  | 0.50954   |
| AverageReturn        | 10.503    |
| MinReturn            | 4.9458    |
| MaxReturn            | 30.609    |
| StdReturn            | 3.4355    |
| AverageEpisodeLength | 20.83     |
| MinEpisodeLength     | 16        |
| MaxEpisodeLength     | 41        |
| StdEpisodeLength     | 3.3913    |
| TotalNEpisodes       | 9546      |
| TotalNSamples        | 1.801e+05 |
| ExplainedVariance    | 0.6612    |
------------------------------------
[2019-11-19 11:32:54.240795 UTC] Saving snapshot
[2019-11-19 11:32:54.241690 UTC] Starting iteration 36
[2019-11-19 11:32:54.242457 UTC] Start collecting samples
[2019-11-19 11:32:59.719537 UTC] Computing input variables for policy optimization
[2019-11-19 11:32:59.871847 UTC] Performing policy update
[2019-11-19 11:32:59.873047 UTC] Computing gradient in Euclidean space
[2019-11-19 11:32:59.925001 UTC] Computing approximate natural gradient using conjugate gradient algorithm
[2019-11-19 11:33:00.674253 UTC] Performing line search
[2019-11-19 11:33:00.793066 UTC] Updating baseline
[2019-11-19 11:33:01.998123 UTC] Computing logging information
-------------------------------------
| Iteration            | 36         |
| ExpectedImprovement  | 0.021419   |
| ActualImprovement    | 0.021334   |
| ImprovementRatio     | 0.99603    |
| MeanKL               | 0.0068218  |
| Entropy              | 4.6068     |
| Perplexity           | 100.17     |
| AveragePolicyStd     | 0.52265    |
| AveragePolicyStd[0]  | 0.50872    |
| AveragePolicyStd[1]  | 0.59319    |
| AveragePolicyStd[2]  | 0.5129     |
| AveragePolicyStd[3]  | 0.4831     |
| AveragePolicyStd[4]  | 0.54042    |
| AveragePolicyStd[5]  | 0.49754    |
| AverageReturn        | 11.168     |
| MinReturn            | 5.0682     |
| MaxReturn            | 25.809     |
| StdReturn            | 3.4592     |
| AverageEpisodeLength | 20.9       |
| MinEpisodeLength     | 16         |
| MaxEpisodeLength     | 44         |
| StdEpisodeLength     | 3.7323     |
| TotalNEpisodes       | 9787       |
| TotalNSamples        | 1.8510e+05 |
| ExplainedVariance    | 0.59454    |
-------------------------------------
[2019-11-19 11:33:03.455434 UTC] Saving snapshot
[2019-11-19 11:33:03.456180 UTC] Starting iteration 37
[2019-11-19 11:33:03.456741 UTC] Start collecting samples
[2019-11-19 11:33:08.969644 UTC] Computing input variables for policy optimization
[2019-11-19 11:33:09.147145 UTC] Performing policy update
[2019-11-19 11:33:09.148430 UTC] Computing gradient in Euclidean space
[2019-11-19 11:33:09.206840 UTC] Computing approximate natural gradient using conjugate gradient algorithm
[2019-11-19 11:33:09.854715 UTC] Performing line search
[2019-11-19 11:33:09.938127 UTC] Updating baseline
[2019-11-19 11:33:10.710880 UTC] Computing logging information
-------------------------------------
| Iteration            | 37         |
| ExpectedImprovement  | 0.022737   |
| ActualImprovement    | 0.022455   |
| ImprovementRatio     | 0.98758    |
| MeanKL               | 0.0066447  |
| Entropy              | 4.524      |
| Perplexity           | 92.202     |
| AveragePolicyStd     | 0.51572    |
| AveragePolicyStd[0]  | 0.50379    |
| AveragePolicyStd[1]  | 0.5937     |
| AveragePolicyStd[2]  | 0.50768    |
| AveragePolicyStd[3]  | 0.47427    |
| AveragePolicyStd[4]  | 0.53043    |
| AveragePolicyStd[5]  | 0.48446    |
| AverageReturn        | 10.646     |
| MinReturn            | 2.7972     |
| MaxReturn            | 20.755     |
| StdReturn            | 3.5722     |
| AverageEpisodeLength | 21.33      |
| MinEpisodeLength     | 16         |
| MaxEpisodeLength     | 40         |
| StdEpisodeLength     | 3.8472     |
| TotalNEpisodes       | 10028      |
| TotalNSamples        | 1.9016e+05 |
| ExplainedVariance    | 0.67545    |
-------------------------------------
[2019-11-19 11:33:11.766997 UTC] Saving snapshot
[2019-11-19 11:33:11.767995 UTC] Starting iteration 38
[2019-11-19 11:33:11.768732 UTC] Start collecting samples
[2019-11-19 11:33:16.943165 UTC] Computing input variables for policy optimization
[2019-11-19 11:33:17.090614 UTC] Performing policy update
[2019-11-19 11:33:17.091969 UTC] Computing gradient in Euclidean space
[2019-11-19 11:33:17.146049 UTC] Computing approximate natural gradient using conjugate gradient algorithm
[2019-11-19 11:33:17.740335 UTC] Performing line search
[2019-11-19 11:33:17.824142 UTC] Updating baseline
[2019-11-19 11:33:18.592459 UTC] Computing logging information
-------------------------------------
| Iteration            | 38         |
| ExpectedImprovement  | 0.020967   |
| ActualImprovement    | 0.020827   |
| ImprovementRatio     | 0.99332    |
| MeanKL               | 0.0066462  |
| Entropy              | 4.4312     |
| Perplexity           | 84.035     |
| AveragePolicyStd     | 0.50803    |
| AveragePolicyStd[0]  | 0.49914    |
| AveragePolicyStd[1]  | 0.59096    |
| AveragePolicyStd[2]  | 0.49943    |
| AveragePolicyStd[3]  | 0.46643    |
| AveragePolicyStd[4]  | 0.52185    |
| AveragePolicyStd[5]  | 0.47038    |
| AverageReturn        | 11.609     |
| MinReturn            | 4.7424     |
| MaxReturn            | 24.071     |
| StdReturn            | 3.9161     |
| AverageEpisodeLength | 22.02      |
| MinEpisodeLength     | 17         |
| MaxEpisodeLength     | 33         |
| StdEpisodeLength     | 3.9344     |
| TotalNEpisodes       | 10256      |
| TotalNSamples        | 1.9509e+05 |
| ExplainedVariance    | 0.63642    |
-------------------------------------
[2019-11-19 11:33:19.800822 UTC] Saving snapshot
[2019-11-19 11:33:19.801768 UTC] Starting iteration 39
[2019-11-19 11:33:19.802859 UTC] Start collecting samples
[2019-11-19 11:33:25.190053 UTC] Computing input variables for policy optimization
[2019-11-19 11:33:25.344029 UTC] Performing policy update
[2019-11-19 11:33:25.345407 UTC] Computing gradient in Euclidean space
[2019-11-19 11:33:25.401704 UTC] Computing approximate natural gradient using conjugate gradient algorithm
[2019-11-19 11:33:26.004341 UTC] Performing line search
[2019-11-19 11:33:26.085842 UTC] Updating baseline
[2019-11-19 11:33:26.877377 UTC] Computing logging information
-------------------------------------
| Iteration            | 39         |
| ExpectedImprovement  | 0.022373   |
| ActualImprovement    | 0.022186   |
| ImprovementRatio     | 0.99166    |
| MeanKL               | 0.0067564  |
| Entropy              | 4.3649     |
| Perplexity           | 78.641     |
| AveragePolicyStd     | 0.50241    |
| AveragePolicyStd[0]  | 0.49049    |
| AveragePolicyStd[1]  | 0.58287    |
| AveragePolicyStd[2]  | 0.4933     |
| AveragePolicyStd[3]  | 0.46467    |
| AveragePolicyStd[4]  | 0.51921    |
| AveragePolicyStd[5]  | 0.4639     |
| AverageReturn        | 12.692     |
| MinReturn            | -0.27305   |
| MaxReturn            | 24.183     |
| StdReturn            | 4.6023     |
| AverageEpisodeLength | 22.43      |
| MinEpisodeLength     | 16         |
| MaxEpisodeLength     | 38         |
| StdEpisodeLength     | 3.9529     |
| TotalNEpisodes       | 10482      |
| TotalNSamples        | 2.0013e+05 |
| ExplainedVariance    | 0.68127    |
-------------------------------------
[2019-11-19 11:33:28.319268 UTC] Saving snapshot
[2019-11-19 11:33:28.320445 UTC] Starting iteration 40
[2019-11-19 11:33:28.321197 UTC] Start collecting samples
[2019-11-19 11:33:33.743189 UTC] Computing input variables for policy optimization
[2019-11-19 11:33:33.896203 UTC] Performing policy update
[2019-11-19 11:33:33.897334 UTC] Computing gradient in Euclidean space
[2019-11-19 11:33:33.955739 UTC] Computing approximate natural gradient using conjugate gradient algorithm
[2019-11-19 11:33:34.537498 UTC] Performing line search
[2019-11-19 11:33:34.619674 UTC] Updating baseline
[2019-11-19 11:33:35.402000 UTC] Computing logging information
-------------------------------------
| Iteration            | 40         |
| ExpectedImprovement  | 0.024807   |
| ActualImprovement    | 0.024445   |
| ImprovementRatio     | 0.98541    |
| MeanKL               | 0.0066203  |
| Entropy              | 4.3075     |
| Perplexity           | 74.254     |
| AveragePolicyStd     | 0.49758    |
| AveragePolicyStd[0]  | 0.48948    |
| AveragePolicyStd[1]  | 0.57757    |
| AveragePolicyStd[2]  | 0.48954    |
| AveragePolicyStd[3]  | 0.45775    |
| AveragePolicyStd[4]  | 0.50838    |
| AveragePolicyStd[5]  | 0.46275    |
| AverageReturn        | 12.933     |
| MinReturn            | 4.2674     |
| MaxReturn            | 25.208     |
| StdReturn            | 4.4242     |
| AverageEpisodeLength | 22.76      |
| MinEpisodeLength     | 16         |
| MaxEpisodeLength     | 37         |
| StdEpisodeLength     | 5.0142     |
| TotalNEpisodes       | 10702      |
| TotalNSamples        | 2.0514e+05 |
| ExplainedVariance    | 0.70035    |
-------------------------------------
[2019-11-19 11:33:36.906792 UTC] Saving snapshot
[2019-11-19 11:33:36.930910 UTC] Starting iteration 41
[2019-11-19 11:33:36.931712 UTC] Start collecting samples
[2019-11-19 11:33:41.930458 UTC] Computing input variables for policy optimization
[2019-11-19 11:33:42.080984 UTC] Performing policy update
[2019-11-19 11:33:42.082421 UTC] Computing gradient in Euclidean space
[2019-11-19 11:33:42.141908 UTC] Computing approximate natural gradient using conjugate gradient algorithm
[2019-11-19 11:33:42.731878 UTC] Performing line search
[2019-11-19 11:33:42.818603 UTC] Updating baseline
[2019-11-19 11:33:43.574279 UTC] Computing logging information
-------------------------------------
| Iteration            | 41         |
| ExpectedImprovement  | 0.023398   |
| ActualImprovement    | 0.023005   |
| ImprovementRatio     | 0.98319    |
| MeanKL               | 0.0066955  |
| Entropy              | 4.2342     |
| Perplexity           | 69.008     |
| AveragePolicyStd     | 0.4917     |
| AveragePolicyStd[0]  | 0.48889    |
| AveragePolicyStd[1]  | 0.57684    |
| AveragePolicyStd[2]  | 0.48385    |
| AveragePolicyStd[3]  | 0.44971    |
| AveragePolicyStd[4]  | 0.49419    |
| AveragePolicyStd[5]  | 0.45674    |
| AverageReturn        | 13.405     |
| MinReturn            | 3.9335     |
| MaxReturn            | 35.012     |
| StdReturn            | 4.9105     |
| AverageEpisodeLength | 23.81      |
| MinEpisodeLength     | 17         |
| MaxEpisodeLength     | 38         |
| StdEpisodeLength     | 4.595      |
| TotalNEpisodes       | 10918      |
| TotalNSamples        | 2.1019e+05 |
| ExplainedVariance    | 0.67182    |
-------------------------------------
[2019-11-19 11:33:44.771753 UTC] Saving snapshot
[2019-11-19 11:33:44.772509 UTC] Starting iteration 42
[2019-11-19 11:33:44.774548 UTC] Start collecting samples
[2019-11-19 11:33:49.718762 UTC] Computing input variables for policy optimization
[2019-11-19 11:33:49.866555 UTC] Performing policy update
[2019-11-19 11:33:49.867694 UTC] Computing gradient in Euclidean space
[2019-11-19 11:33:49.923172 UTC] Computing approximate natural gradient using conjugate gradient algorithm
[2019-11-19 11:33:50.513849 UTC] Performing line search
[2019-11-19 11:33:50.598927 UTC] Updating baseline
[2019-11-19 11:33:51.356985 UTC] Computing logging information
-------------------------------------
| Iteration            | 42         |
| ExpectedImprovement  | 0.024455   |
| ActualImprovement    | 0.024293   |
| ImprovementRatio     | 0.99338    |
| MeanKL               | 0.0066707  |
| Entropy              | 4.1687     |
| Perplexity           | 64.63      |
| AveragePolicyStd     | 0.48656    |
| AveragePolicyStd[0]  | 0.4858     |
| AveragePolicyStd[1]  | 0.57709    |
| AveragePolicyStd[2]  | 0.48083    |
| AveragePolicyStd[3]  | 0.44466    |
| AveragePolicyStd[4]  | 0.48157    |
| AveragePolicyStd[5]  | 0.44939    |
| AverageReturn        | 13.455     |
| MinReturn            | 3.0464     |
| MaxReturn            | 23.529     |
| StdReturn            | 4.3339     |
| AverageEpisodeLength | 22.84      |
| MinEpisodeLength     | 16         |
| MaxEpisodeLength     | 33         |
| StdEpisodeLength     | 3.7596     |
| TotalNEpisodes       | 11131      |
| TotalNSamples        | 2.1516e+05 |
| ExplainedVariance    | 0.75101    |
-------------------------------------
[2019-11-19 11:33:52.676745 UTC] Saving snapshot
[2019-11-19 11:33:52.677564 UTC] Starting iteration 43
[2019-11-19 11:33:52.678312 UTC] Start collecting samples
[2019-11-19 11:33:57.785634 UTC] Computing input variables for policy optimization
[2019-11-19 11:33:57.935840 UTC] Performing policy update
[2019-11-19 11:33:57.937101 UTC] Computing gradient in Euclidean space
[2019-11-19 11:33:57.992390 UTC] Computing approximate natural gradient using conjugate gradient algorithm
[2019-11-19 11:33:58.629518 UTC] Performing line search
[2019-11-19 11:33:58.718316 UTC] Updating baseline
[2019-11-19 11:33:59.549751 UTC] Computing logging information
-------------------------------------
| Iteration            | 43         |
| ExpectedImprovement  | 0.023682   |
| ActualImprovement    | 0.023367   |
| ImprovementRatio     | 0.98668    |
| MeanKL               | 0.0065403  |
| Entropy              | 4.0958     |
| Perplexity           | 60.087     |
| AveragePolicyStd     | 0.48072    |
| AveragePolicyStd[0]  | 0.48272    |
| AveragePolicyStd[1]  | 0.57094    |
| AveragePolicyStd[2]  | 0.47593    |
| AveragePolicyStd[3]  | 0.43811    |
| AveragePolicyStd[4]  | 0.47123    |
| AveragePolicyStd[5]  | 0.44535    |
| AverageReturn        | 14.998     |
| MinReturn            | 7.6163     |
| MaxReturn            | 28.993     |
| StdReturn            | 4.1058     |
| AverageEpisodeLength | 24.71      |
| MinEpisodeLength     | 17         |
| MaxEpisodeLength     | 39         |
| StdEpisodeLength     | 4.2504     |
| TotalNEpisodes       | 11335      |
| TotalNSamples        | 2.2018e+05 |
| ExplainedVariance    | 0.75738    |
-------------------------------------
[2019-11-19 11:34:00.543527 UTC] Saving snapshot
[2019-11-19 11:34:00.544301 UTC] Starting iteration 44
[2019-11-19 11:34:00.545051 UTC] Start collecting samples
[2019-11-19 11:34:05.184893 UTC] Computing input variables for policy optimization
[2019-11-19 11:34:05.325278 UTC] Performing policy update
[2019-11-19 11:34:05.326413 UTC] Computing gradient in Euclidean space
[2019-11-19 11:34:05.378660 UTC] Computing approximate natural gradient using conjugate gradient algorithm
[2019-11-19 11:34:05.962369 UTC] Performing line search
[2019-11-19 11:34:06.042250 UTC] Updating baseline
[2019-11-19 11:34:06.813301 UTC] Computing logging information
-------------------------------------
| Iteration            | 44         |
| ExpectedImprovement  | 0.023065   |
| ActualImprovement    | 0.022672   |
| ImprovementRatio     | 0.98295    |
| MeanKL               | 0.0066056  |
| Entropy              | 4.038      |
| Perplexity           | 56.711     |
| AveragePolicyStd     | 0.47626    |
| AveragePolicyStd[0]  | 0.47987    |
| AveragePolicyStd[1]  | 0.5689     |
| AveragePolicyStd[2]  | 0.4748     |
| AveragePolicyStd[3]  | 0.43172    |
| AveragePolicyStd[4]  | 0.4622     |
| AveragePolicyStd[5]  | 0.44009    |
| AverageReturn        | 15.307     |
| MinReturn            | 7.4848     |
| MaxReturn            | 27.632     |
| StdReturn            | 3.935      |
| AverageEpisodeLength | 24.89      |
| MinEpisodeLength     | 18         |
| MaxEpisodeLength     | 35         |
| StdEpisodeLength     | 3.8933     |
| TotalNEpisodes       | 11533      |
| TotalNSamples        | 2.2516e+05 |
| ExplainedVariance    | 0.78183    |
-------------------------------------
[2019-11-19 11:34:07.965751 UTC] Saving snapshot
[2019-11-19 11:34:07.966821 UTC] Starting iteration 45
[2019-11-19 11:34:07.967537 UTC] Start collecting samples
[2019-11-19 11:34:12.884854 UTC] Computing input variables for policy optimization
[2019-11-19 11:34:13.021081 UTC] Performing policy update
[2019-11-19 11:34:13.022204 UTC] Computing gradient in Euclidean space
[2019-11-19 11:34:13.078012 UTC] Computing approximate natural gradient using conjugate gradient algorithm
[2019-11-19 11:34:13.662450 UTC] Performing line search
[2019-11-19 11:34:13.744298 UTC] Updating baseline
[2019-11-19 11:34:14.507732 UTC] Computing logging information
-------------------------------------
| Iteration            | 45         |
| ExpectedImprovement  | 0.024949   |
| ActualImprovement    | 0.024583   |
| ImprovementRatio     | 0.98534    |
| MeanKL               | 0.0066123  |
| Entropy              | 3.9644     |
| Perplexity           | 52.689     |
| AveragePolicyStd     | 0.47057    |
| AveragePolicyStd[0]  | 0.47366    |
| AveragePolicyStd[1]  | 0.56382    |
| AveragePolicyStd[2]  | 0.47513    |
| AveragePolicyStd[3]  | 0.42506    |
| AveragePolicyStd[4]  | 0.45126    |
| AveragePolicyStd[5]  | 0.43452    |
| AverageReturn        | 16.564     |
| MinReturn            | 7.2342     |
| MaxReturn            | 34.326     |
| StdReturn            | 4.6543     |
| AverageEpisodeLength | 26.03      |
| MinEpisodeLength     | 18         |
| MaxEpisodeLength     | 38         |
| StdEpisodeLength     | 4.158      |
| TotalNEpisodes       | 11730      |
| TotalNSamples        | 2.3017e+05 |
| ExplainedVariance    | 0.7563     |
-------------------------------------
[2019-11-19 11:34:15.433504 UTC] Saving snapshot
[2019-11-19 11:34:15.434327 UTC] Starting iteration 46
[2019-11-19 11:34:15.434997 UTC] Start collecting samples
[2019-11-19 11:34:20.169305 UTC] Computing input variables for policy optimization
[2019-11-19 11:34:20.303313 UTC] Performing policy update
[2019-11-19 11:34:20.304578 UTC] Computing gradient in Euclidean space
[2019-11-19 11:34:20.363817 UTC] Computing approximate natural gradient using conjugate gradient algorithm
[2019-11-19 11:34:20.950198 UTC] Performing line search
[2019-11-19 11:34:21.032619 UTC] Updating baseline
[2019-11-19 11:34:21.794071 UTC] Computing logging information
-------------------------------------
| Iteration            | 46         |
| ExpectedImprovement  | 0.02494    |
| ActualImprovement    | 0.024972   |
| ImprovementRatio     | 1.0013     |
| MeanKL               | 0.0066772  |
| Entropy              | 3.8703     |
| Perplexity           | 47.955     |
| AveragePolicyStd     | 0.46329    |
| AveragePolicyStd[0]  | 0.46511    |
| AveragePolicyStd[1]  | 0.55643    |
| AveragePolicyStd[2]  | 0.46835    |
| AveragePolicyStd[3]  | 0.42172    |
| AveragePolicyStd[4]  | 0.44435    |
| AveragePolicyStd[5]  | 0.42377    |
| AverageReturn        | 17.104     |
| MinReturn            | 3.4806     |
| MaxReturn            | 39.722     |
| StdReturn            | 5.4994     |
| AverageEpisodeLength | 25.85      |
| MinEpisodeLength     | 17         |
| MaxEpisodeLength     | 40         |
| StdEpisodeLength     | 4.2033     |
| TotalNEpisodes       | 11922      |
| TotalNSamples        | 2.3522e+05 |
| ExplainedVariance    | 0.78399    |
-------------------------------------
[2019-11-19 11:34:22.827049 UTC] Saving snapshot
[2019-11-19 11:34:22.827985 UTC] Starting iteration 47
[2019-11-19 11:34:22.828618 UTC] Start collecting samples
[2019-11-19 11:34:27.461834 UTC] Computing input variables for policy optimization
[2019-11-19 11:34:27.592337 UTC] Performing policy update
[2019-11-19 11:34:27.593451 UTC] Computing gradient in Euclidean space
[2019-11-19 11:34:27.647647 UTC] Computing approximate natural gradient using conjugate gradient algorithm
[2019-11-19 11:34:28.237112 UTC] Performing line search
[2019-11-19 11:34:28.327241 UTC] Updating baseline
[2019-11-19 11:34:29.165543 UTC] Computing logging information
-------------------------------------
| Iteration            | 47         |
| ExpectedImprovement  | 0.027818   |
| ActualImprovement    | 0.028159   |
| ImprovementRatio     | 1.0123     |
| MeanKL               | 0.0066159  |
| Entropy              | 3.8113     |
| Perplexity           | 45.208     |
| AveragePolicyStd     | 0.45881    |
| AveragePolicyStd[0]  | 0.46199    |
| AveragePolicyStd[1]  | 0.55363    |
| AveragePolicyStd[2]  | 0.46088    |
| AveragePolicyStd[3]  | 0.42009    |
| AveragePolicyStd[4]  | 0.43656    |
| AveragePolicyStd[5]  | 0.41973    |
| AverageReturn        | 18.72      |
| MinReturn            | 6.9659     |
| MaxReturn            | 32.894     |
| StdReturn            | 4.2916     |
| AverageEpisodeLength | 28.04      |
| MinEpisodeLength     | 18         |
| MaxEpisodeLength     | 41         |
| StdEpisodeLength     | 4.2893     |
| TotalNEpisodes       | 12099      |
| TotalNSamples        | 2.4017e+05 |
| ExplainedVariance    | 0.82574    |
-------------------------------------
[2019-11-19 11:34:30.458143 UTC] Saving snapshot
[2019-11-19 11:34:30.459865 UTC] Starting iteration 48
[2019-11-19 11:34:30.461064 UTC] Start collecting samples
[2019-11-19 11:34:34.921745 UTC] Computing input variables for policy optimization
[2019-11-19 11:34:35.045497 UTC] Performing policy update
[2019-11-19 11:34:35.046496 UTC] Computing gradient in Euclidean space
[2019-11-19 11:34:35.101965 UTC] Computing approximate natural gradient using conjugate gradient algorithm
[2019-11-19 11:34:35.696637 UTC] Performing line search
[2019-11-19 11:34:35.782066 UTC] Updating baseline
[2019-11-19 11:34:36.581211 UTC] Computing logging information
-------------------------------------
| Iteration            | 48         |
| ExpectedImprovement  | 0.027615   |
| ActualImprovement    | 0.027419   |
| ImprovementRatio     | 0.99289    |
| MeanKL               | 0.0065507  |
| Entropy              | 3.77       |
| Perplexity           | 43.381     |
| AveragePolicyStd     | 0.45577    |
| AveragePolicyStd[0]  | 0.46027    |
| AveragePolicyStd[1]  | 0.55027    |
| AveragePolicyStd[2]  | 0.46104    |
| AveragePolicyStd[3]  | 0.41409    |
| AveragePolicyStd[4]  | 0.43427    |
| AveragePolicyStd[5]  | 0.41466    |
| AverageReturn        | 19.392     |
| MinReturn            | 6.148      |
| MaxReturn            | 39.541     |
| StdReturn            | 5.0861     |
| AverageEpisodeLength | 29.03      |
| MinEpisodeLength     | 20         |
| MaxEpisodeLength     | 43         |
| StdEpisodeLength     | 4.4417     |
| TotalNEpisodes       | 12272      |
| TotalNSamples        | 2.4514e+05 |
| ExplainedVariance    | 0.8294     |
-------------------------------------
[2019-11-19 11:34:37.509264 UTC] Saving snapshot
[2019-11-19 11:34:37.510611 UTC] Starting iteration 49
[2019-11-19 11:34:37.511574 UTC] Start collecting samples
[2019-11-19 11:34:42.230461 UTC] Computing input variables for policy optimization
[2019-11-19 11:34:42.369513 UTC] Performing policy update
[2019-11-19 11:34:42.370834 UTC] Computing gradient in Euclidean space
[2019-11-19 11:34:42.425627 UTC] Computing approximate natural gradient using conjugate gradient algorithm
[2019-11-19 11:34:43.007604 UTC] Performing line search
[2019-11-19 11:34:43.091214 UTC] Updating baseline
[2019-11-19 11:34:43.862400 UTC] Computing logging information
-------------------------------------
| Iteration            | 49         |
| ExpectedImprovement  | 0.026229   |
| ActualImprovement    | 0.026186   |
| ImprovementRatio     | 0.99836    |
| MeanKL               | 0.0065762  |
| Entropy              | 3.7146     |
| Perplexity           | 41.043     |
| AveragePolicyStd     | 0.45181    |
| AveragePolicyStd[0]  | 0.45474    |
| AveragePolicyStd[1]  | 0.55155    |
| AveragePolicyStd[2]  | 0.45837    |
| AveragePolicyStd[3]  | 0.41297    |
| AveragePolicyStd[4]  | 0.42445    |
| AveragePolicyStd[5]  | 0.4088     |
| AverageReturn        | 21.542     |
| MinReturn            | 6.7153     |
| MaxReturn            | 48.202     |
| StdReturn            | 7.2353     |
| AverageEpisodeLength | 31.2       |
| MinEpisodeLength     | 18         |
| MaxEpisodeLength     | 53         |
| StdEpisodeLength     | 6.6828     |
| TotalNEpisodes       | 12432      |
| TotalNSamples        | 2.5015e+05 |
| ExplainedVariance    | 0.77691    |
-------------------------------------
[2019-11-19 11:34:44.947562 UTC] Saving snapshot
[2019-11-19 11:34:44.948558 UTC] Starting iteration 50
[2019-11-19 11:34:44.949405 UTC] Start collecting samples
[2019-11-19 11:34:48.948399 UTC] Computing input variables for policy optimization
[2019-11-19 11:34:49.070004 UTC] Performing policy update
[2019-11-19 11:34:49.071023 UTC] Computing gradient in Euclidean space
[2019-11-19 11:34:49.127215 UTC] Computing approximate natural gradient using conjugate gradient algorithm
[2019-11-19 11:34:49.711277 UTC] Performing line search
[2019-11-19 11:34:49.791598 UTC] Updating baseline
[2019-11-19 11:34:50.547809 UTC] Computing logging information
-------------------------------------
| Iteration            | 50         |
| ExpectedImprovement  | 0.029742   |
| ActualImprovement    | 0.029391   |
| ImprovementRatio     | 0.9882     |
| MeanKL               | 0.0064491  |
| Entropy              | 3.6823     |
| Perplexity           | 39.736     |
| AveragePolicyStd     | 0.44945    |
| AveragePolicyStd[0]  | 0.45104    |
| AveragePolicyStd[1]  | 0.55026    |
| AveragePolicyStd[2]  | 0.45648    |
| AveragePolicyStd[3]  | 0.40969    |
| AveragePolicyStd[4]  | 0.42348    |
| AveragePolicyStd[5]  | 0.40576    |
| AverageReturn        | 22.898     |
| MinReturn            | 9.5337     |
| MaxReturn            | 50.425     |
| StdReturn            | 7.7328     |
| AverageEpisodeLength | 32.65      |
| MinEpisodeLength     | 21         |
| MaxEpisodeLength     | 60         |
| StdEpisodeLength     | 7.0162     |
| TotalNEpisodes       | 12583      |
| TotalNSamples        | 2.5508e+05 |
| ExplainedVariance    | 0.80801    |
-------------------------------------
[2019-11-19 11:34:51.460273 UTC] Saving snapshot
[2019-11-19 11:34:51.478996 UTC] Starting iteration 51
[2019-11-19 11:34:51.479631 UTC] Start collecting samples
[2019-11-19 11:34:55.200322 UTC] Computing input variables for policy optimization
[2019-11-19 11:34:55.309625 UTC] Performing policy update
[2019-11-19 11:34:55.310813 UTC] Computing gradient in Euclidean space
[2019-11-19 11:34:55.365137 UTC] Computing approximate natural gradient using conjugate gradient algorithm
[2019-11-19 11:34:55.949701 UTC] Performing line search
[2019-11-19 11:34:56.029728 UTC] Updating baseline
[2019-11-19 11:34:56.783863 UTC] Computing logging information
-------------------------------------
| Iteration            | 51         |
| ExpectedImprovement  | 0.02926    |
| ActualImprovement    | 0.029603   |
| ImprovementRatio     | 1.0117     |
| MeanKL               | 0.0065709  |
| Entropy              | 3.6593     |
| Perplexity           | 38.834     |
| AveragePolicyStd     | 0.44794    |
| AveragePolicyStd[0]  | 0.44949    |
| AveragePolicyStd[1]  | 0.55213    |
| AveragePolicyStd[2]  | 0.45641    |
| AveragePolicyStd[3]  | 0.40723    |
| AveragePolicyStd[4]  | 0.42078    |
| AveragePolicyStd[5]  | 0.40159    |
| AverageReturn        | 28.835     |
| MinReturn            | 8.7401     |
| MaxReturn            | 63.3       |
| StdReturn            | 11.896     |
| AverageEpisodeLength | 40.23      |
| MinEpisodeLength     | 22         |
| MaxEpisodeLength     | 79         |
| StdEpisodeLength     | 12.601     |
| TotalNEpisodes       | 12711      |
| TotalNSamples        | 2.6007e+05 |
| ExplainedVariance    | 0.72013    |
-------------------------------------
[2019-11-19 11:34:57.851879 UTC] Saving snapshot
[2019-11-19 11:34:57.852878 UTC] Starting iteration 52
[2019-11-19 11:34:57.853543 UTC] Start collecting samples
[2019-11-19 11:35:01.806214 UTC] Computing input variables for policy optimization
[2019-11-19 11:35:01.923611 UTC] Performing policy update
[2019-11-19 11:35:01.924637 UTC] Computing gradient in Euclidean space
[2019-11-19 11:35:01.976732 UTC] Computing approximate natural gradient using conjugate gradient algorithm
[2019-11-19 11:35:02.562521 UTC] Performing line search
[2019-11-19 11:35:02.643735 UTC] Updating baseline
[2019-11-19 11:35:03.390510 UTC] Computing logging information
-------------------------------------
| Iteration            | 52         |
| ExpectedImprovement  | 0.026465   |
| ActualImprovement    | 0.026634   |
| ImprovementRatio     | 1.0064     |
| MeanKL               | 0.0067724  |
| Entropy              | 3.6489     |
| Perplexity           | 38.434     |
| AveragePolicyStd     | 0.4473     |
| AveragePolicyStd[0]  | 0.44845    |
| AveragePolicyStd[1]  | 0.5532     |
| AveragePolicyStd[2]  | 0.4578     |
| AveragePolicyStd[3]  | 0.40597    |
| AveragePolicyStd[4]  | 0.41991    |
| AveragePolicyStd[5]  | 0.39843    |
| AverageReturn        | 29.921     |
| MinReturn            | 10.618     |
| MaxReturn            | 64.619     |
| StdReturn            | 11.665     |
| AverageEpisodeLength | 40.48      |
| MinEpisodeLength     | 20         |
| MaxEpisodeLength     | 75         |
| StdEpisodeLength     | 11.417     |
| TotalNEpisodes       | 12836      |
| TotalNSamples        | 2.6516e+05 |
| ExplainedVariance    | 0.74811    |
-------------------------------------
[2019-11-19 11:35:04.546836 UTC] Saving snapshot
[2019-11-19 11:35:04.547909 UTC] Starting iteration 53
[2019-11-19 11:35:04.548488 UTC] Start collecting samples
[2019-11-19 11:35:07.797311 UTC] Computing input variables for policy optimization
[2019-11-19 11:35:07.894618 UTC] Performing policy update
[2019-11-19 11:35:07.895830 UTC] Computing gradient in Euclidean space
[2019-11-19 11:35:07.952263 UTC] Computing approximate natural gradient using conjugate gradient algorithm
[2019-11-19 11:35:08.532773 UTC] Performing line search
[2019-11-19 11:35:08.614871 UTC] Updating baseline
[2019-11-19 11:35:09.369242 UTC] Computing logging information
-------------------------------------
| Iteration            | 53         |
| ExpectedImprovement  | 0.024151   |
| ActualImprovement    | 0.023908   |
| ImprovementRatio     | 0.98995    |
| MeanKL               | 0.0067255  |
| Entropy              | 3.6275     |
| Perplexity           | 37.62      |
| AveragePolicyStd     | 0.44571    |
| AveragePolicyStd[0]  | 0.4455     |
| AveragePolicyStd[1]  | 0.55058    |
| AveragePolicyStd[2]  | 0.45968    |
| AveragePolicyStd[3]  | 0.4044     |
| AveragePolicyStd[4]  | 0.41676    |
| AveragePolicyStd[5]  | 0.39735    |
| AverageReturn        | 34.839     |
| MinReturn            | 0.93592    |
| MaxReturn            | 75.084     |
| StdReturn            | 14.315     |
| AverageEpisodeLength | 47.44      |
| MinEpisodeLength     | 24         |
| MaxEpisodeLength     | 149        |
| StdEpisodeLength     | 17.325     |
| TotalNEpisodes       | 12938      |
| TotalNSamples        | 2.6997e+05 |
| ExplainedVariance    | 0.7        |
-------------------------------------
[2019-11-19 11:35:10.365158 UTC] Saving snapshot
[2019-11-19 11:35:10.366147 UTC] Starting iteration 54
[2019-11-19 11:35:10.366917 UTC] Start collecting samples
[2019-11-19 11:35:13.643741 UTC] Computing input variables for policy optimization
[2019-11-19 11:35:13.740704 UTC] Performing policy update
[2019-11-19 11:35:13.742025 UTC] Computing gradient in Euclidean space
[2019-11-19 11:35:13.796594 UTC] Computing approximate natural gradient using conjugate gradient algorithm
[2019-11-19 11:35:14.377751 UTC] Performing line search
[2019-11-19 11:35:14.457027 UTC] Updating baseline
[2019-11-19 11:35:15.212935 UTC] Computing logging information
-------------------------------------
| Iteration            | 54         |
| ExpectedImprovement  | 0.025223   |
| ActualImprovement    | 0.025331   |
| ImprovementRatio     | 1.0043     |
| MeanKL               | 0.0067491  |
| Entropy              | 3.5905     |
| Perplexity           | 36.253     |
| AveragePolicyStd     | 0.44295    |
| AveragePolicyStd[0]  | 0.44645    |
| AveragePolicyStd[1]  | 0.5457     |
| AveragePolicyStd[2]  | 0.4561     |
| AveragePolicyStd[3]  | 0.40165    |
| AveragePolicyStd[4]  | 0.4131     |
| AveragePolicyStd[5]  | 0.39467    |
| AverageReturn        | 40.319     |
| MinReturn            | 16.296     |
| MaxReturn            | 82.519     |
| StdReturn            | 14.623     |
| AverageEpisodeLength | 53.29      |
| MinEpisodeLength     | 30         |
| MaxEpisodeLength     | 171        |
| StdEpisodeLength     | 21.024     |
| TotalNEpisodes       | 13032      |
| TotalNSamples        | 2.7505e+05 |
| ExplainedVariance    | 0.75016    |
-------------------------------------
[2019-11-19 11:35:16.308902 UTC] Saving snapshot
[2019-11-19 11:35:16.310107 UTC] Starting iteration 55
[2019-11-19 11:35:16.310967 UTC] Start collecting samples
[2019-11-19 11:35:19.349904 UTC] Computing input variables for policy optimization
[2019-11-19 11:35:19.437779 UTC] Performing policy update
[2019-11-19 11:35:19.439001 UTC] Computing gradient in Euclidean space
[2019-11-19 11:35:19.495012 UTC] Computing approximate natural gradient using conjugate gradient algorithm
[2019-11-19 11:35:20.071551 UTC] Performing line search
[2019-11-19 11:35:20.150917 UTC] Updating baseline
[2019-11-19 11:35:20.897467 UTC] Computing logging information
-------------------------------------
| Iteration            | 55         |
| ExpectedImprovement  | 0.022523   |
| ActualImprovement    | 0.0218     |
| ImprovementRatio     | 0.9679     |
| MeanKL               | 0.0067891  |
| Entropy              | 3.5621     |
| Perplexity           | 35.236     |
| AveragePolicyStd     | 0.44122    |
| AveragePolicyStd[0]  | 0.44671    |
| AveragePolicyStd[1]  | 0.5493     |
| AveragePolicyStd[2]  | 0.45709    |
| AveragePolicyStd[3]  | 0.39425    |
| AveragePolicyStd[4]  | 0.40682    |
| AveragePolicyStd[5]  | 0.39314    |
| AverageReturn        | 45.319     |
| MinReturn            | 19.713     |
| MaxReturn            | 98.156     |
| StdReturn            | 16.105     |
| AverageEpisodeLength | 59.37      |
| MinEpisodeLength     | 28         |
| MaxEpisodeLength     | 174        |
| StdEpisodeLength     | 23.222     |
| TotalNEpisodes       | 13118      |
| TotalNSamples        | 2.8005e+05 |
| ExplainedVariance    | 0.74364    |
-------------------------------------
[2019-11-19 11:35:22.247840 UTC] Saving snapshot
[2019-11-19 11:35:22.248742 UTC] Starting iteration 56
[2019-11-19 11:35:22.249703 UTC] Start collecting samples
[2019-11-19 11:35:25.251719 UTC] Computing input variables for policy optimization
[2019-11-19 11:35:25.340166 UTC] Performing policy update
[2019-11-19 11:35:25.341380 UTC] Computing gradient in Euclidean space
[2019-11-19 11:35:25.395538 UTC] Computing approximate natural gradient using conjugate gradient algorithm
[2019-11-19 11:35:25.972079 UTC] Performing line search
[2019-11-19 11:35:26.052828 UTC] Updating baseline
[2019-11-19 11:35:26.841928 UTC] Computing logging information
-------------------------------------
| Iteration            | 56         |
| ExpectedImprovement  | 0.019664   |
| ActualImprovement    | 0.019461   |
| ImprovementRatio     | 0.9897     |
| MeanKL               | 0.0067563  |
| Entropy              | 3.5178     |
| Perplexity           | 33.71      |
| AveragePolicyStd     | 0.43807    |
| AveragePolicyStd[0]  | 0.45139    |
| AveragePolicyStd[1]  | 0.5432     |
| AveragePolicyStd[2]  | 0.45451    |
| AveragePolicyStd[3]  | 0.38608    |
| AveragePolicyStd[4]  | 0.4038     |
| AveragePolicyStd[5]  | 0.38943    |
| AverageReturn        | 46.823     |
| MinReturn            | 14.458     |
| MaxReturn            | 98.156     |
| StdReturn            | 13.373     |
| AverageEpisodeLength | 62.16      |
| MinEpisodeLength     | 28         |
| MaxEpisodeLength     | 174        |
| StdEpisodeLength     | 21.297     |
| TotalNEpisodes       | 13198      |
| TotalNSamples        | 2.8499e+05 |
| ExplainedVariance    | 0.79327    |
-------------------------------------
[2019-11-19 11:35:28.129650 UTC] Saving snapshot
[2019-11-19 11:35:28.130734 UTC] Starting iteration 57
[2019-11-19 11:35:28.131704 UTC] Start collecting samples
[2019-11-19 11:35:31.154158 UTC] Computing input variables for policy optimization
[2019-11-19 11:35:31.249036 UTC] Performing policy update
[2019-11-19 11:35:31.250224 UTC] Computing gradient in Euclidean space
[2019-11-19 11:35:31.305071 UTC] Computing approximate natural gradient using conjugate gradient algorithm
[2019-11-19 11:35:31.882331 UTC] Performing line search
[2019-11-19 11:35:31.962811 UTC] Updating baseline
[2019-11-19 11:35:32.701184 UTC] Computing logging information
-------------------------------------
| Iteration            | 57         |
| ExpectedImprovement  | 0.021102   |
| ActualImprovement    | 0.020713   |
| ImprovementRatio     | 0.98156    |
| MeanKL               | 0.0065966  |
| Entropy              | 3.4563     |
| Perplexity           | 31.701     |
| AveragePolicyStd     | 0.43376    |
| AveragePolicyStd[0]  | 0.44828    |
| AveragePolicyStd[1]  | 0.54004    |
| AveragePolicyStd[2]  | 0.4515     |
| AveragePolicyStd[3]  | 0.38443    |
| AveragePolicyStd[4]  | 0.39379    |
| AveragePolicyStd[5]  | 0.38454    |
| AverageReturn        | 48.491     |
| MinReturn            | 14.933     |
| MaxReturn            | 80.751     |
| StdReturn            | 12.808     |
| AverageEpisodeLength | 61.73      |
| MinEpisodeLength     | 36         |
| MaxEpisodeLength     | 162        |
| StdEpisodeLength     | 22.073     |
| TotalNEpisodes       | 13281      |
| TotalNSamples        | 2.9010e+05 |
| ExplainedVariance    | 0.78995    |
-------------------------------------
[2019-11-19 11:35:33.700588 UTC] Saving snapshot
[2019-11-19 11:35:33.701422 UTC] Starting iteration 58
[2019-11-19 11:35:33.702225 UTC] Start collecting samples
[2019-11-19 11:35:36.577557 UTC] Computing input variables for policy optimization
[2019-11-19 11:35:36.659384 UTC] Performing policy update
[2019-11-19 11:35:36.660805 UTC] Computing gradient in Euclidean space
[2019-11-19 11:35:36.717252 UTC] Computing approximate natural gradient using conjugate gradient algorithm
[2019-11-19 11:35:37.296714 UTC] Performing line search
[2019-11-19 11:35:37.378240 UTC] Updating baseline
[2019-11-19 11:35:38.291436 UTC] Computing logging information
------------------------------------
| Iteration            | 58        |
| ExpectedImprovement  | 0.018839  |
| ActualImprovement    | 0.018713  |
| ImprovementRatio     | 0.9933    |
| MeanKL               | 0.0068328 |
| Entropy              | 3.408     |
| Perplexity           | 30.205    |
| AveragePolicyStd     | 0.43026   |
| AveragePolicyStd[0]  | 0.44677   |
| AveragePolicyStd[1]  | 0.5323    |
| AveragePolicyStd[2]  | 0.45121   |
| AveragePolicyStd[3]  | 0.37553   |
| AveragePolicyStd[4]  | 0.39037   |
| AveragePolicyStd[5]  | 0.3854    |
| AverageReturn        | 51.969    |
| MinReturn            | 16.763    |
| MaxReturn            | 80.722    |
| StdReturn            | 12.303    |
| AverageEpisodeLength | 65.24     |
| MinEpisodeLength     | 36        |
| MaxEpisodeLength     | 162       |
| StdEpisodeLength     | 19.544    |
| TotalNEpisodes       | 13356     |
| TotalNSamples        | 2.95e+05  |
| ExplainedVariance    | 0.82896   |
------------------------------------
[2019-11-19 11:35:39.423657 UTC] Saving snapshot
[2019-11-19 11:35:39.424743 UTC] Starting iteration 59
[2019-11-19 11:35:39.425583 UTC] Start collecting samples
[2019-11-19 11:35:42.158344 UTC] Computing input variables for policy optimization
[2019-11-19 11:35:42.237391 UTC] Performing policy update
[2019-11-19 11:35:42.238309 UTC] Computing gradient in Euclidean space
[2019-11-19 11:35:42.290985 UTC] Computing approximate natural gradient using conjugate gradient algorithm
[2019-11-19 11:35:42.870659 UTC] Performing line search
[2019-11-19 11:35:42.951823 UTC] Updating baseline
[2019-11-19 11:35:43.681299 UTC] Computing logging information
-------------------------------------
| Iteration            | 59         |
| ExpectedImprovement  | 0.022224   |
| ActualImprovement    | 0.021722   |
| ImprovementRatio     | 0.97742    |
| MeanKL               | 0.0067163  |
| Entropy              | 3.3784     |
| Perplexity           | 29.324     |
| AveragePolicyStd     | 0.42835    |
| AveragePolicyStd[0]  | 0.4454     |
| AveragePolicyStd[1]  | 0.53204    |
| AveragePolicyStd[2]  | 0.45083    |
| AveragePolicyStd[3]  | 0.36852    |
| AveragePolicyStd[4]  | 0.38609    |
| AveragePolicyStd[5]  | 0.38722    |
| AverageReturn        | 53.047     |
| MinReturn            | 20.754     |
| MaxReturn            | 78.277     |
| StdReturn            | 11.783     |
| AverageEpisodeLength | 68.32      |
| MinEpisodeLength     | 36         |
| MaxEpisodeLength     | 151        |
| StdEpisodeLength     | 22.08      |
| TotalNEpisodes       | 13426      |
| TotalNSamples        | 2.9986e+05 |
| ExplainedVariance    | 0.841      |
-------------------------------------
[2019-11-19 11:35:44.747088 UTC] Saving snapshot
[2019-11-19 11:35:44.748151 UTC] Starting iteration 60
[2019-11-19 11:35:44.748993 UTC] Start collecting samples
[2019-11-19 11:35:47.505552 UTC] Computing input variables for policy optimization
[2019-11-19 11:35:47.590595 UTC] Performing policy update
[2019-11-19 11:35:47.591682 UTC] Computing gradient in Euclidean space
[2019-11-19 11:35:47.645205 UTC] Computing approximate natural gradient using conjugate gradient algorithm
[2019-11-19 11:35:48.217237 UTC] Performing line search
[2019-11-19 11:35:48.295617 UTC] Updating baseline
[2019-11-19 11:35:49.185591 UTC] Computing logging information
-------------------------------------
| Iteration            | 60         |
| ExpectedImprovement  | 0.020172   |
| ActualImprovement    | 0.019494   |
| ImprovementRatio     | 0.96639    |
| MeanKL               | 0.0066181  |
| Entropy              | 3.3549     |
| Perplexity           | 28.642     |
| AveragePolicyStd     | 0.42646    |
| AveragePolicyStd[0]  | 0.44217    |
| AveragePolicyStd[1]  | 0.52512    |
| AveragePolicyStd[2]  | 0.4521     |
| AveragePolicyStd[3]  | 0.37153    |
| AveragePolicyStd[4]  | 0.38353    |
| AveragePolicyStd[5]  | 0.38433    |
| AverageReturn        | 55.495     |
| MinReturn            | 12.399     |
| MaxReturn            | 94.95      |
| StdReturn            | 13.491     |
| AverageEpisodeLength | 74.02      |
| MinEpisodeLength     | 37         |
| MaxEpisodeLength     | 175        |
| StdEpisodeLength     | 26.359     |
| TotalNEpisodes       | 13495      |
| TotalNSamples        | 3.0494e+05 |
| ExplainedVariance    | 0.83706    |
-------------------------------------
[2019-11-19 11:35:50.272820 UTC] Saving snapshot
[2019-11-19 11:35:50.296570 UTC] Starting iteration 61
[2019-11-19 11:35:50.297996 UTC] Start collecting samples
[2019-11-19 11:35:53.103045 UTC] Computing input variables for policy optimization
[2019-11-19 11:35:53.186676 UTC] Performing policy update
[2019-11-19 11:35:53.188048 UTC] Computing gradient in Euclidean space
[2019-11-19 11:35:53.241080 UTC] Computing approximate natural gradient using conjugate gradient algorithm
[2019-11-19 11:35:53.815806 UTC] Performing line search
[2019-11-19 11:35:53.895031 UTC] Updating baseline
[2019-11-19 11:35:54.724590 UTC] Computing logging information
-------------------------------------
| Iteration            | 61         |
| ExpectedImprovement  | 0.017982   |
| ActualImprovement    | 0.017364   |
| ImprovementRatio     | 0.96565    |
| MeanKL               | 0.0068241  |
| Entropy              | 3.3218     |
| Perplexity           | 27.71      |
| AveragePolicyStd     | 0.42419    |
| AveragePolicyStd[0]  | 0.4455     |
| AveragePolicyStd[1]  | 0.52104    |
| AveragePolicyStd[2]  | 0.44913    |
| AveragePolicyStd[3]  | 0.3684     |
| AveragePolicyStd[4]  | 0.37997    |
| AveragePolicyStd[5]  | 0.38111    |
| AverageReturn        | 56.886     |
| MinReturn            | 32.259     |
| MaxReturn            | 94.95      |
| StdReturn            | 11.76      |
| AverageEpisodeLength | 72.64      |
| MinEpisodeLength     | 44         |
| MaxEpisodeLength     | 175        |
| StdEpisodeLength     | 23.646     |
| TotalNEpisodes       | 13565      |
| TotalNSamples        | 3.0996e+05 |
| ExplainedVariance    | 0.86735    |
-------------------------------------
[2019-11-19 11:35:56.030529 UTC] Saving snapshot
[2019-11-19 11:35:56.031725 UTC] Starting iteration 62
[2019-11-19 11:35:56.032613 UTC] Start collecting samples
[2019-11-19 11:35:58.817315 UTC] Computing input variables for policy optimization
[2019-11-19 11:35:58.895155 UTC] Performing policy update
[2019-11-19 11:35:58.896868 UTC] Computing gradient in Euclidean space
[2019-11-19 11:35:58.953106 UTC] Computing approximate natural gradient using conjugate gradient algorithm
[2019-11-19 11:35:59.527216 UTC] Performing line search
[2019-11-19 11:35:59.606009 UTC] Updating baseline
[2019-11-19 11:36:00.347460 UTC] Computing logging information
-------------------------------------
| Iteration            | 62         |
| ExpectedImprovement  | 0.019524   |
| ActualImprovement    | 0.019409   |
| ImprovementRatio     | 0.99408    |
| MeanKL               | 0.0066867  |
| Entropy              | 3.2881     |
| Perplexity           | 26.791     |
| AveragePolicyStd     | 0.42204    |
| AveragePolicyStd[0]  | 0.44483    |
| AveragePolicyStd[1]  | 0.52164    |
| AveragePolicyStd[2]  | 0.44654    |
| AveragePolicyStd[3]  | 0.36298    |
| AveragePolicyStd[4]  | 0.37882    |
| AveragePolicyStd[5]  | 0.37743    |
| AverageReturn        | 56.036     |
| MinReturn            | 30.87      |
| MaxReturn            | 87.799     |
| StdReturn            | 10.831     |
| AverageEpisodeLength | 71.15      |
| MinEpisodeLength     | 42         |
| MaxEpisodeLength     | 149        |
| StdEpisodeLength     | 21.071     |
| TotalNEpisodes       | 13632      |
| TotalNSamples        | 3.1473e+05 |
| ExplainedVariance    | 0.8502     |
-------------------------------------
[2019-11-19 11:36:01.473200 UTC] Saving snapshot
[2019-11-19 11:36:01.474196 UTC] Starting iteration 63
[2019-11-19 11:36:01.475024 UTC] Start collecting samples
[2019-11-19 11:36:04.173836 UTC] Computing input variables for policy optimization
[2019-11-19 11:36:04.254400 UTC] Performing policy update
[2019-11-19 11:36:04.255518 UTC] Computing gradient in Euclidean space
[2019-11-19 11:36:04.309739 UTC] Computing approximate natural gradient using conjugate gradient algorithm
[2019-11-19 11:36:04.884399 UTC] Performing line search
[2019-11-19 11:36:04.962093 UTC] Updating baseline
[2019-11-19 11:36:05.709476 UTC] Computing logging information
-------------------------------------
| Iteration            | 63         |
| ExpectedImprovement  | 0.021111   |
| ActualImprovement    | 0.020481   |
| ImprovementRatio     | 0.97016    |
| MeanKL               | 0.0066199  |
| Entropy              | 3.2568     |
| Perplexity           | 25.966     |
| AveragePolicyStd     | 0.41986    |
| AveragePolicyStd[0]  | 0.44513    |
| AveragePolicyStd[1]  | 0.51858    |
| AveragePolicyStd[2]  | 0.44285    |
| AveragePolicyStd[3]  | 0.36182    |
| AveragePolicyStd[4]  | 0.37674    |
| AveragePolicyStd[5]  | 0.37402    |
| AverageReturn        | 60.176     |
| MinReturn            | 29.636     |
| MaxReturn            | 103.35     |
| StdReturn            | 14.251     |
| AverageEpisodeLength | 80.67      |
| MinEpisodeLength     | 42         |
| MaxEpisodeLength     | 208        |
| StdEpisodeLength     | 29.892     |
| TotalNEpisodes       | 13693      |
| TotalNSamples        | 3.1989e+05 |
| ExplainedVariance    | 0.84069    |
-------------------------------------
[2019-11-19 11:36:06.992271 UTC] Saving snapshot
[2019-11-19 11:36:06.993216 UTC] Starting iteration 64
[2019-11-19 11:36:06.993972 UTC] Start collecting samples
[2019-11-19 11:36:09.376749 UTC] Computing input variables for policy optimization
[2019-11-19 11:36:09.455881 UTC] Performing policy update
[2019-11-19 11:36:09.456951 UTC] Computing gradient in Euclidean space
[2019-11-19 11:36:09.510889 UTC] Computing approximate natural gradient using conjugate gradient algorithm
[2019-11-19 11:36:10.081363 UTC] Performing line search
[2019-11-19 11:36:10.162621 UTC] Updating baseline
[2019-11-19 11:36:11.006065 UTC] Computing logging information
-------------------------------------
| Iteration            | 64         |
| ExpectedImprovement  | 0.020596   |
| ActualImprovement    | 0.020065   |
| ImprovementRatio     | 0.97424    |
| MeanKL               | 0.0065967  |
| Entropy              | 3.2242     |
| Perplexity           | 25.134     |
| AveragePolicyStd     | 0.41751    |
| AveragePolicyStd[0]  | 0.44527    |
| AveragePolicyStd[1]  | 0.51204    |
| AveragePolicyStd[2]  | 0.44055    |
| AveragePolicyStd[3]  | 0.35648    |
| AveragePolicyStd[4]  | 0.37612    |
| AveragePolicyStd[5]  | 0.37459    |
| AverageReturn        | 62.662     |
| MinReturn            | 29.636     |
| MaxReturn            | 107.28     |
| StdReturn            | 16.262     |
| AverageEpisodeLength | 86.85      |
| MinEpisodeLength     | 41         |
| MaxEpisodeLength     | 208        |
| StdEpisodeLength     | 34.745     |
| TotalNEpisodes       | 13749      |
| TotalNSamples        | 3.2496e+05 |
| ExplainedVariance    | 0.81262    |
-------------------------------------
[2019-11-19 11:36:12.024318 UTC] Saving snapshot
[2019-11-19 11:36:12.025306 UTC] Starting iteration 65
[2019-11-19 11:36:12.026113 UTC] Start collecting samples
[2019-11-19 11:36:14.592228 UTC] Computing input variables for policy optimization
[2019-11-19 11:36:14.676563 UTC] Performing policy update
[2019-11-19 11:36:14.678001 UTC] Computing gradient in Euclidean space
[2019-11-19 11:36:14.737013 UTC] Computing approximate natural gradient using conjugate gradient algorithm
[2019-11-19 11:36:15.312495 UTC] Performing line search
[2019-11-19 11:36:15.395833 UTC] Updating baseline
[2019-11-19 11:36:16.154649 UTC] Computing logging information
-------------------------------------
| Iteration            | 65         |
| ExpectedImprovement  | 0.01993    |
| ActualImprovement    | 0.01952    |
| ImprovementRatio     | 0.97943    |
| MeanKL               | 0.0067246  |
| Entropy              | 3.1996     |
| Perplexity           | 24.524     |
| AveragePolicyStd     | 0.4157     |
| AveragePolicyStd[0]  | 0.44773    |
| AveragePolicyStd[1]  | 0.50527    |
| AveragePolicyStd[2]  | 0.43832    |
| AveragePolicyStd[3]  | 0.35499    |
| AveragePolicyStd[4]  | 0.37501    |
| AveragePolicyStd[5]  | 0.37288    |
| AverageReturn        | 61.536     |
| MinReturn            | 26.736     |
| MaxReturn            | 107.28     |
| StdReturn            | 14.749     |
| AverageEpisodeLength | 82.59      |
| MinEpisodeLength     | 45         |
| MaxEpisodeLength     | 165        |
| StdEpisodeLength     | 29.854     |
| TotalNEpisodes       | 13810      |
| TotalNSamples        | 3.2955e+05 |
| ExplainedVariance    | 0.84293    |
-------------------------------------
[2019-11-19 11:36:17.132173 UTC] Saving snapshot
[2019-11-19 11:36:17.133099 UTC] Starting iteration 66
[2019-11-19 11:36:17.133982 UTC] Start collecting samples
[2019-11-19 11:36:19.762099 UTC] Computing input variables for policy optimization
[2019-11-19 11:36:19.846092 UTC] Performing policy update
[2019-11-19 11:36:19.847160 UTC] Computing gradient in Euclidean space
[2019-11-19 11:36:19.902097 UTC] Computing approximate natural gradient using conjugate gradient algorithm
[2019-11-19 11:36:20.473685 UTC] Performing line search
[2019-11-19 11:36:20.554606 UTC] Updating baseline
[2019-11-19 11:36:21.366168 UTC] Computing logging information
-------------------------------------
| Iteration            | 66         |
| ExpectedImprovement  | 0.020962   |
| ActualImprovement    | 0.020445   |
| ImprovementRatio     | 0.97535    |
| MeanKL               | 0.0064902  |
| Entropy              | 3.1643     |
| Perplexity           | 23.671     |
| AveragePolicyStd     | 0.41329    |
| AveragePolicyStd[0]  | 0.44611    |
| AveragePolicyStd[1]  | 0.50313    |
| AveragePolicyStd[2]  | 0.43377    |
| AveragePolicyStd[3]  | 0.35099    |
| AveragePolicyStd[4]  | 0.37388    |
| AveragePolicyStd[5]  | 0.37188    |
| AverageReturn        | 62.954     |
| MinReturn            | 26.736     |
| MaxReturn            | 99.768     |
| StdReturn            | 13.587     |
| AverageEpisodeLength | 82.58      |
| MinEpisodeLength     | 45         |
| MaxEpisodeLength     | 168        |
| StdEpisodeLength     | 26.874     |
| TotalNEpisodes       | 13870      |
| TotalNSamples        | 3.3482e+05 |
| ExplainedVariance    | 0.85859    |
-------------------------------------
[2019-11-19 11:36:22.553211 UTC] Saving snapshot
[2019-11-19 11:36:22.554345 UTC] Starting iteration 67
[2019-11-19 11:36:22.555281 UTC] Start collecting samples
[2019-11-19 11:36:24.987272 UTC] Computing input variables for policy optimization
[2019-11-19 11:36:25.065765 UTC] Performing policy update
[2019-11-19 11:36:25.067020 UTC] Computing gradient in Euclidean space
[2019-11-19 11:36:25.120194 UTC] Computing approximate natural gradient using conjugate gradient algorithm
[2019-11-19 11:36:25.695575 UTC] Performing line search
[2019-11-19 11:36:25.776003 UTC] Updating baseline
[2019-11-19 11:36:26.531893 UTC] Computing logging information
-------------------------------------
| Iteration            | 67         |
| ExpectedImprovement  | 0.02159    |
| ActualImprovement    | 0.021219   |
| ImprovementRatio     | 0.98282    |
| MeanKL               | 0.0065909  |
| Entropy              | 3.1175     |
| Perplexity           | 22.59      |
| AveragePolicyStd     | 0.40983    |
| AveragePolicyStd[0]  | 0.44589    |
| AveragePolicyStd[1]  | 0.49446    |
| AveragePolicyStd[2]  | 0.42551    |
| AveragePolicyStd[3]  | 0.35132    |
| AveragePolicyStd[4]  | 0.37154    |
| AveragePolicyStd[5]  | 0.37027    |
| AverageReturn        | 63.987     |
| MinReturn            | 19.275     |
| MaxReturn            | 99.768     |
| StdReturn            | 15.082     |
| AverageEpisodeLength | 88.25      |
| MinEpisodeLength     | 36         |
| MaxEpisodeLength     | 168        |
| StdEpisodeLength     | 29.145     |
| TotalNEpisodes       | 13925      |
| TotalNSamples        | 3.3972e+05 |
| ExplainedVariance    | 0.77539    |
-------------------------------------
[2019-11-19 11:36:27.527980 UTC] Saving snapshot
[2019-11-19 11:36:27.529062 UTC] Starting iteration 68
[2019-11-19 11:36:27.530067 UTC] Start collecting samples
[2019-11-19 11:36:30.207697 UTC] Computing input variables for policy optimization
[2019-11-19 11:36:30.286317 UTC] Performing policy update
[2019-11-19 11:36:30.287308 UTC] Computing gradient in Euclidean space
[2019-11-19 11:36:30.340595 UTC] Computing approximate natural gradient using conjugate gradient algorithm
[2019-11-19 11:36:30.915251 UTC] Performing line search
[2019-11-19 11:36:30.995438 UTC] Updating baseline
[2019-11-19 11:36:31.771402 UTC] Computing logging information
-------------------------------------
| Iteration            | 68         |
| ExpectedImprovement  | 0.019047   |
| ActualImprovement    | 0.018276   |
| ImprovementRatio     | 0.9595     |
| MeanKL               | 0.0067488  |
| Entropy              | 3.0988     |
| Perplexity           | 22.17      |
| AveragePolicyStd     | 0.40855    |
| AveragePolicyStd[0]  | 0.44819    |
| AveragePolicyStd[1]  | 0.49083    |
| AveragePolicyStd[2]  | 0.42258    |
| AveragePolicyStd[3]  | 0.34926    |
| AveragePolicyStd[4]  | 0.37093    |
| AveragePolicyStd[5]  | 0.36951    |
| AverageReturn        | 63.817     |
| MinReturn            | 19.275     |
| MaxReturn            | 113.82     |
| StdReturn            | 15.086     |
| AverageEpisodeLength | 87.88      |
| MinEpisodeLength     | 36         |
| MaxEpisodeLength     | 173        |
| StdEpisodeLength     | 28.613     |
| TotalNEpisodes       | 13984      |
| TotalNSamples        | 3.4474e+05 |
| ExplainedVariance    | 0.89722    |
-------------------------------------
[2019-11-19 11:36:32.908560 UTC] Saving snapshot
[2019-11-19 11:36:32.909770 UTC] Starting iteration 69
[2019-11-19 11:36:32.910637 UTC] Start collecting samples
[2019-11-19 11:36:35.486508 UTC] Computing input variables for policy optimization
[2019-11-19 11:36:35.566115 UTC] Performing policy update
[2019-11-19 11:36:35.567311 UTC] Computing gradient in Euclidean space
[2019-11-19 11:36:35.621761 UTC] Computing approximate natural gradient using conjugate gradient algorithm
[2019-11-19 11:36:36.199649 UTC] Performing line search
[2019-11-19 11:36:36.277543 UTC] Updating baseline
[2019-11-19 11:36:37.106307 UTC] Computing logging information
-------------------------------------
| Iteration            | 69         |
| ExpectedImprovement  | 0.018635   |
| ActualImprovement    | 0.019028   |
| ImprovementRatio     | 1.0211     |
| MeanKL               | 0.0065684  |
| Entropy              | 3.0588     |
| Perplexity           | 21.302     |
| AveragePolicyStd     | 0.40589    |
| AveragePolicyStd[0]  | 0.45071    |
| AveragePolicyStd[1]  | 0.48479    |
| AveragePolicyStd[2]  | 0.41946    |
| AveragePolicyStd[3]  | 0.34644    |
| AveragePolicyStd[4]  | 0.36959    |
| AveragePolicyStd[5]  | 0.36433    |
| AverageReturn        | 66.889     |
| MinReturn            | 34.35      |
| MaxReturn            | 113.82     |
| StdReturn            | 13.618     |
| AverageEpisodeLength | 86.75      |
| MinEpisodeLength     | 50         |
| MaxEpisodeLength     | 177        |
| StdEpisodeLength     | 29.058     |
| TotalNEpisodes       | 14043      |
| TotalNSamples        | 3.4989e+05 |
| ExplainedVariance    | 0.89978    |
-------------------------------------
[2019-11-19 11:36:38.205874 UTC] Saving snapshot
[2019-11-19 11:36:38.206947 UTC] Starting iteration 70
[2019-11-19 11:36:38.207808 UTC] Start collecting samples
[2019-11-19 11:36:40.710223 UTC] Computing input variables for policy optimization
[2019-11-19 11:36:40.786542 UTC] Performing policy update
[2019-11-19 11:36:40.787566 UTC] Computing gradient in Euclidean space
[2019-11-19 11:36:40.842134 UTC] Computing approximate natural gradient using conjugate gradient algorithm
[2019-11-19 11:36:41.409296 UTC] Performing line search
[2019-11-19 11:36:41.489136 UTC] Updating baseline
[2019-11-19 11:36:42.248607 UTC] Computing logging information
-------------------------------------
| Iteration            | 70         |
| ExpectedImprovement  | 0.02225    |
| ActualImprovement    | 0.022286   |
| ImprovementRatio     | 1.0016     |
| MeanKL               | 0.0065692  |
| Entropy              | 3.0366     |
| Perplexity           | 20.833     |
| AveragePolicyStd     | 0.40435    |
| AveragePolicyStd[0]  | 0.44743    |
| AveragePolicyStd[1]  | 0.48285    |
| AveragePolicyStd[2]  | 0.41786    |
| AveragePolicyStd[3]  | 0.34337    |
| AveragePolicyStd[4]  | 0.37122    |
| AveragePolicyStd[5]  | 0.36339    |
| AverageReturn        | 69.923     |
| MinReturn            | 42.909     |
| MaxReturn            | 118.32     |
| StdReturn            | 13.652     |
| AverageEpisodeLength | 91         |
| MinEpisodeLength     | 46         |
| MaxEpisodeLength     | 177        |
| StdEpisodeLength     | 29.25      |
| TotalNEpisodes       | 14096      |
| TotalNSamples        | 3.5488e+05 |
| ExplainedVariance    | 0.93603    |
-------------------------------------
[2019-11-19 11:36:43.122445 UTC] Saving snapshot
[2019-11-19 11:36:43.141193 UTC] Starting iteration 71
[2019-11-19 11:36:43.141846 UTC] Start collecting samples
[2019-11-19 11:36:45.537992 UTC] Computing input variables for policy optimization
[2019-11-19 11:36:45.614271 UTC] Performing policy update
[2019-11-19 11:36:45.615516 UTC] Computing gradient in Euclidean space
[2019-11-19 11:36:45.670955 UTC] Computing approximate natural gradient using conjugate gradient algorithm
[2019-11-19 11:36:46.245596 UTC] Performing line search
[2019-11-19 11:36:46.328578 UTC] Updating baseline
[2019-11-19 11:36:47.139261 UTC] Computing logging information
-------------------------------------
| Iteration            | 71         |
| ExpectedImprovement  | 0.02023    |
| ActualImprovement    | 0.020042   |
| ImprovementRatio     | 0.99069    |
| MeanKL               | 0.0068023  |
| Entropy              | 3.0293     |
| Perplexity           | 20.683     |
| AveragePolicyStd     | 0.40369    |
| AveragePolicyStd[0]  | 0.44714    |
| AveragePolicyStd[1]  | 0.47972    |
| AveragePolicyStd[2]  | 0.41486    |
| AveragePolicyStd[3]  | 0.34638    |
| AveragePolicyStd[4]  | 0.37209    |
| AveragePolicyStd[5]  | 0.36196    |
| AverageReturn        | 70.526     |
| MinReturn            | 22.532     |
| MaxReturn            | 118.32     |
| StdReturn            | 14.801     |
| AverageEpisodeLength | 92.88      |
| MinEpisodeLength     | 46         |
| MaxEpisodeLength     | 177        |
| StdEpisodeLength     | 30.64      |
| TotalNEpisodes       | 14149      |
| TotalNSamples        | 3.5964e+05 |
| ExplainedVariance    | 0.84048    |
-------------------------------------
[2019-11-19 11:36:48.091974 UTC] Saving snapshot
[2019-11-19 11:36:48.092870 UTC] Starting iteration 72
[2019-11-19 11:36:48.093505 UTC] Start collecting samples
[2019-11-19 11:36:50.607785 UTC] Computing input variables for policy optimization
[2019-11-19 11:36:50.684788 UTC] Performing policy update
[2019-11-19 11:36:50.686239 UTC] Computing gradient in Euclidean space
[2019-11-19 11:36:50.745597 UTC] Computing approximate natural gradient using conjugate gradient algorithm
[2019-11-19 11:36:51.321486 UTC] Performing line search
[2019-11-19 11:36:51.405791 UTC] Updating baseline
[2019-11-19 11:36:52.138909 UTC] Computing logging information
-------------------------------------
| Iteration            | 72         |
| ExpectedImprovement  | 0.02078    |
| ActualImprovement    | 0.019565   |
| ImprovementRatio     | 0.94155    |
| MeanKL               | 0.0066399  |
| Entropy              | 2.9872     |
| Perplexity           | 19.829     |
| AveragePolicyStd     | 0.40094    |
| AveragePolicyStd[0]  | 0.44438    |
| AveragePolicyStd[1]  | 0.4782     |
| AveragePolicyStd[2]  | 0.41246    |
| AveragePolicyStd[3]  | 0.34469    |
| AveragePolicyStd[4]  | 0.36586    |
| AveragePolicyStd[5]  | 0.36008    |
| AverageReturn        | 70.937     |
| MinReturn            | 22.532     |
| MaxReturn            | 119.8      |
| StdReturn            | 15.934     |
| AverageEpisodeLength | 93.14      |
| MinEpisodeLength     | 49         |
| MaxEpisodeLength     | 224        |
| StdEpisodeLength     | 32.377     |
| TotalNEpisodes       | 14204      |
| TotalNSamples        | 3.6482e+05 |
| ExplainedVariance    | 0.8956     |
-------------------------------------
[2019-11-19 11:36:53.590764 UTC] Saving snapshot
[2019-11-19 11:36:53.592321 UTC] Starting iteration 73
[2019-11-19 11:36:53.593239 UTC] Start collecting samples
[2019-11-19 11:36:55.815048 UTC] Computing input variables for policy optimization
[2019-11-19 11:36:55.890618 UTC] Performing policy update
[2019-11-19 11:36:55.891776 UTC] Computing gradient in Euclidean space
[2019-11-19 11:36:55.945808 UTC] Computing approximate natural gradient using conjugate gradient algorithm
[2019-11-19 11:36:56.519623 UTC] Performing line search
[2019-11-19 11:36:56.598871 UTC] Updating baseline
[2019-11-19 11:36:57.358677 UTC] Computing logging information
-------------------------------------
| Iteration            | 73         |
| ExpectedImprovement  | 0.021076   |
| ActualImprovement    | 0.019633   |
| ImprovementRatio     | 0.93156    |
| MeanKL               | 0.0066236  |
| Entropy              | 2.9664     |
| Perplexity           | 19.422     |
| AveragePolicyStd     | 0.39957    |
| AveragePolicyStd[0]  | 0.4431     |
| AveragePolicyStd[1]  | 0.47686    |
| AveragePolicyStd[2]  | 0.40919    |
| AveragePolicyStd[3]  | 0.34056    |
| AveragePolicyStd[4]  | 0.36548    |
| AveragePolicyStd[5]  | 0.36224    |
| AverageReturn        | 73.149     |
| MinReturn            | 34.47      |
| MaxReturn            | 119.8      |
| StdReturn            | 14.175     |
| AverageEpisodeLength | 97.32      |
| MinEpisodeLength     | 53         |
| MaxEpisodeLength     | 224        |
| StdEpisodeLength     | 30.974     |
| TotalNEpisodes       | 14251      |
| TotalNSamples        | 3.6953e+05 |
| ExplainedVariance    | 0.83694    |
-------------------------------------
[2019-11-19 11:36:58.313736 UTC] Saving snapshot
[2019-11-19 11:36:58.314899 UTC] Starting iteration 74
[2019-11-19 11:36:58.315771 UTC] Start collecting samples
[2019-11-19 11:37:00.765113 UTC] Computing input variables for policy optimization
[2019-11-19 11:37:00.847459 UTC] Performing policy update
[2019-11-19 11:37:00.848476 UTC] Computing gradient in Euclidean space
[2019-11-19 11:37:00.904347 UTC] Computing approximate natural gradient using conjugate gradient algorithm
[2019-11-19 11:37:01.482405 UTC] Performing line search
[2019-11-19 11:37:01.563524 UTC] Updating baseline
[2019-11-19 11:37:02.293186 UTC] Computing logging information
-------------------------------------
| Iteration            | 74         |
| ExpectedImprovement  | 0.020706   |
| ActualImprovement    | 0.020038   |
| ImprovementRatio     | 0.96773    |
| MeanKL               | 0.0066057  |
| Entropy              | 2.9549     |
| Perplexity           | 19.2       |
| AveragePolicyStd     | 0.39876    |
| AveragePolicyStd[0]  | 0.44108    |
| AveragePolicyStd[1]  | 0.47349    |
| AveragePolicyStd[2]  | 0.4115     |
| AveragePolicyStd[3]  | 0.33837    |
| AveragePolicyStd[4]  | 0.36629    |
| AveragePolicyStd[5]  | 0.3618     |
| AverageReturn        | 72.826     |
| MinReturn            | 7.2958     |
| MaxReturn            | 168.93     |
| StdReturn            | 19.176     |
| AverageEpisodeLength | 99.06      |
| MinEpisodeLength     | 41         |
| MaxEpisodeLength     | 252        |
| StdEpisodeLength     | 33.674     |
| TotalNEpisodes       | 14303      |
| TotalNSamples        | 3.7459e+05 |
| ExplainedVariance    | 0.73001    |
-------------------------------------
[2019-11-19 11:37:03.453977 UTC] Saving snapshot
[2019-11-19 11:37:03.454733 UTC] Starting iteration 75
[2019-11-19 11:37:03.455538 UTC] Start collecting samples
[2019-11-19 11:37:05.847852 UTC] Computing input variables for policy optimization
[2019-11-19 11:37:05.920948 UTC] Performing policy update
[2019-11-19 11:37:05.922224 UTC] Computing gradient in Euclidean space
[2019-11-19 11:37:05.982618 UTC] Computing approximate natural gradient using conjugate gradient algorithm
[2019-11-19 11:37:06.558709 UTC] Performing line search
[2019-11-19 11:37:06.640248 UTC] Updating baseline
[2019-11-19 11:37:07.379190 UTC] Computing logging information
-------------------------------------
| Iteration            | 75         |
| ExpectedImprovement  | 0.022547   |
| ActualImprovement    | 0.021866   |
| ImprovementRatio     | 0.96981    |
| MeanKL               | 0.0065057  |
| Entropy              | 2.9148     |
| Perplexity           | 18.445     |
| AveragePolicyStd     | 0.39592    |
| AveragePolicyStd[0]  | 0.4329     |
| AveragePolicyStd[1]  | 0.46904    |
| AveragePolicyStd[2]  | 0.41079    |
| AveragePolicyStd[3]  | 0.3374     |
| AveragePolicyStd[4]  | 0.36502    |
| AveragePolicyStd[5]  | 0.36039    |
| AverageReturn        | 75.005     |
| MinReturn            | 7.2958     |
| MaxReturn            | 168.93     |
| StdReturn            | 22.704     |
| AverageEpisodeLength | 101        |
| MinEpisodeLength     | 41         |
| MaxEpisodeLength     | 252        |
| StdEpisodeLength     | 39.124     |
| TotalNEpisodes       | 14353      |
| TotalNSamples        | 3.7994e+05 |
| ExplainedVariance    | 0.86881    |
-------------------------------------
[2019-11-19 11:37:08.558245 UTC] Saving snapshot
[2019-11-19 11:37:08.559340 UTC] Starting iteration 76
[2019-11-19 11:37:08.560298 UTC] Start collecting samples
[2019-11-19 11:37:10.762757 UTC] Computing input variables for policy optimization
[2019-11-19 11:37:10.839618 UTC] Performing policy update
[2019-11-19 11:37:10.840917 UTC] Computing gradient in Euclidean space
[2019-11-19 11:37:10.893065 UTC] Computing approximate natural gradient using conjugate gradient algorithm
[2019-11-19 11:37:11.466506 UTC] Performing line search
[2019-11-19 11:37:11.546026 UTC] Updating baseline
[2019-11-19 11:37:12.253188 UTC] Computing logging information
------------------------------------
| Iteration            | 76        |
| ExpectedImprovement  | 0.019189  |
| ActualImprovement    | 0.018958  |
| ImprovementRatio     | 0.98797   |
| MeanKL               | 0.0066019 |
| Entropy              | 2.8849    |
| Perplexity           | 17.903    |
| AveragePolicyStd     | 0.39389   |
| AveragePolicyStd[0]  | 0.42729   |
| AveragePolicyStd[1]  | 0.46798   |
| AveragePolicyStd[2]  | 0.40736   |
| AveragePolicyStd[3]  | 0.33552   |
| AveragePolicyStd[4]  | 0.36479   |
| AveragePolicyStd[5]  | 0.36041   |
| AverageReturn        | 77.624    |
| MinReturn            | 36.331    |
| MaxReturn            | 142.56    |
| StdReturn            | 17.125    |
| AverageEpisodeLength | 103.14    |
| MinEpisodeLength     | 50        |
| MaxEpisodeLength     | 227       |
| StdEpisodeLength     | 34.647    |
| TotalNEpisodes       | 14400     |
| TotalNSamples        | 3.847e+05 |
| ExplainedVariance    | 0.92055   |
------------------------------------
[2019-11-19 11:37:13.420147 UTC] Saving snapshot
[2019-11-19 11:37:13.420898 UTC] Starting iteration 77
[2019-11-19 11:37:13.421728 UTC] Start collecting samples
[2019-11-19 11:37:15.704577 UTC] Computing input variables for policy optimization
[2019-11-19 11:37:15.775207 UTC] Performing policy update
[2019-11-19 11:37:15.776641 UTC] Computing gradient in Euclidean space
[2019-11-19 11:37:15.834309 UTC] Computing approximate natural gradient using conjugate gradient algorithm
[2019-11-19 11:37:16.401649 UTC] Performing line search
[2019-11-19 11:37:16.482787 UTC] Updating baseline
[2019-11-19 11:37:17.195915 UTC] Computing logging information
-------------------------------------
| Iteration            | 77         |
| ExpectedImprovement  | 0.020751   |
| ActualImprovement    | 0.019526   |
| ImprovementRatio     | 0.94094    |
| MeanKL               | 0.0065981  |
| Entropy              | 2.8629     |
| Perplexity           | 17.513     |
| AveragePolicyStd     | 0.39225    |
| AveragePolicyStd[0]  | 0.42485    |
| AveragePolicyStd[1]  | 0.46272    |
| AveragePolicyStd[2]  | 0.40384    |
| AveragePolicyStd[3]  | 0.33516    |
| AveragePolicyStd[4]  | 0.36549    |
| AveragePolicyStd[5]  | 0.36145    |
| AverageReturn        | 75.899     |
| MinReturn            | 32.077     |
| MaxReturn            | 120.31     |
| StdReturn            | 15.399     |
| AverageEpisodeLength | 98.08      |
| MinEpisodeLength     | 46         |
| MaxEpisodeLength     | 179        |
| StdEpisodeLength     | 29.27      |
| TotalNEpisodes       | 14449      |
| TotalNSamples        | 3.8931e+05 |
| ExplainedVariance    | 0.8845     |
-------------------------------------
[2019-11-19 11:37:18.228452 UTC] Saving snapshot
[2019-11-19 11:37:18.229457 UTC] Starting iteration 78
[2019-11-19 11:37:18.230113 UTC] Start collecting samples
[2019-11-19 11:37:20.680021 UTC] Computing input variables for policy optimization
[2019-11-19 11:37:20.753956 UTC] Performing policy update
[2019-11-19 11:37:20.755868 UTC] Computing gradient in Euclidean space
[2019-11-19 11:37:20.811428 UTC] Computing approximate natural gradient using conjugate gradient algorithm
[2019-11-19 11:37:21.381684 UTC] Performing line search
[2019-11-19 11:37:21.464628 UTC] Updating baseline
[2019-11-19 11:37:22.196509 UTC] Computing logging information
-------------------------------------
| Iteration            | 78         |
| ExpectedImprovement  | 0.025949   |
| ActualImprovement    | 0.023554   |
| ImprovementRatio     | 0.9077     |
| MeanKL               | 0.0064377  |
| Entropy              | 2.8298     |
| Perplexity           | 16.941     |
| AveragePolicyStd     | 0.39012    |
| AveragePolicyStd[0]  | 0.42388    |
| AveragePolicyStd[1]  | 0.45854    |
| AveragePolicyStd[2]  | 0.40432    |
| AveragePolicyStd[3]  | 0.33254    |
| AveragePolicyStd[4]  | 0.36191    |
| AveragePolicyStd[5]  | 0.35953    |
| AverageReturn        | 77.88      |
| MinReturn            | 32.077     |
| MaxReturn            | 154.99     |
| StdReturn            | 18.704     |
| AverageEpisodeLength | 100.96     |
| MinEpisodeLength     | 46         |
| MaxEpisodeLength     | 242        |
| StdEpisodeLength     | 36.865     |
| TotalNEpisodes       | 14500      |
| TotalNSamples        | 3.9479e+05 |
| ExplainedVariance    | 0.87317    |
-------------------------------------
[2019-11-19 11:37:23.374754 UTC] Saving snapshot
[2019-11-19 11:37:23.375603 UTC] Starting iteration 79
[2019-11-19 11:37:23.376458 UTC] Start collecting samples
[2019-11-19 11:37:25.727366 UTC] Computing input variables for policy optimization
[2019-11-19 11:37:25.802047 UTC] Performing policy update
[2019-11-19 11:37:25.803177 UTC] Computing gradient in Euclidean space
[2019-11-19 11:37:25.861436 UTC] Computing approximate natural gradient using conjugate gradient algorithm
[2019-11-19 11:37:26.442938 UTC] Performing line search
[2019-11-19 11:37:26.526126 UTC] Updating baseline
[2019-11-19 11:37:27.270795 UTC] Computing logging information
-------------------------------------
| Iteration            | 79         |
| ExpectedImprovement  | 0.019403   |
| ActualImprovement    | 0.018923   |
| ImprovementRatio     | 0.97525    |
| MeanKL               | 0.0066421  |
| Entropy              | 2.7932     |
| Perplexity           | 16.333     |
| AveragePolicyStd     | 0.38768    |
| AveragePolicyStd[0]  | 0.42375    |
| AveragePolicyStd[1]  | 0.45305    |
| AveragePolicyStd[2]  | 0.40116    |
| AveragePolicyStd[3]  | 0.33217    |
| AveragePolicyStd[4]  | 0.35975    |
| AveragePolicyStd[5]  | 0.35622    |
| AverageReturn        | 79.012     |
| MinReturn            | 30.201     |
| MaxReturn            | 154.99     |
| StdReturn            | 20.512     |
| AverageEpisodeLength | 107.88     |
| MinEpisodeLength     | 46         |
| MaxEpisodeLength     | 242        |
| StdEpisodeLength     | 39.108     |
| TotalNEpisodes       | 14544      |
| TotalNSamples        | 3.9967e+05 |
| ExplainedVariance    | 0.80939    |
-------------------------------------
[2019-11-19 11:37:28.357990 UTC] Saving snapshot
[2019-11-19 11:37:28.359091 UTC] Starting iteration 80
[2019-11-19 11:37:28.360115 UTC] Start collecting samples
[2019-11-19 11:37:30.894333 UTC] Computing input variables for policy optimization
[2019-11-19 11:37:30.968328 UTC] Performing policy update
[2019-11-19 11:37:30.969393 UTC] Computing gradient in Euclidean space
[2019-11-19 11:37:31.024086 UTC] Computing approximate natural gradient using conjugate gradient algorithm
[2019-11-19 11:37:31.595987 UTC] Performing line search
[2019-11-19 11:37:31.677085 UTC] Updating baseline
[2019-11-19 11:37:32.400219 UTC] Computing logging information
-------------------------------------
| Iteration            | 80         |
| ExpectedImprovement  | 0.017512   |
| ActualImprovement    | 0.017597   |
| ImprovementRatio     | 1.0048     |
| MeanKL               | 0.0066717  |
| Entropy              | 2.7669     |
| Perplexity           | 15.91      |
| AveragePolicyStd     | 0.38608    |
| AveragePolicyStd[0]  | 0.42517    |
| AveragePolicyStd[1]  | 0.45124    |
| AveragePolicyStd[2]  | 0.39849    |
| AveragePolicyStd[3]  | 0.32958    |
| AveragePolicyStd[4]  | 0.35768    |
| AveragePolicyStd[5]  | 0.35433    |
| AverageReturn        | 79.663     |
| MinReturn            | 30.201     |
| MaxReturn            | 133.73     |
| StdReturn            | 18.243     |
| AverageEpisodeLength | 106.65     |
| MinEpisodeLength     | 52         |
| MaxEpisodeLength     | 235        |
| StdEpisodeLength     | 34.362     |
| TotalNEpisodes       | 14592      |
| TotalNSamples        | 4.0452e+05 |
| ExplainedVariance    | 0.9221     |
-------------------------------------
[2019-11-19 11:37:33.406672 UTC] Saving snapshot
[2019-11-19 11:37:33.426578 UTC] Starting iteration 81
[2019-11-19 11:37:33.427083 UTC] Start collecting samples
[2019-11-19 11:37:35.752977 UTC] Computing input variables for policy optimization
[2019-11-19 11:37:35.827757 UTC] Performing policy update
[2019-11-19 11:37:35.828853 UTC] Computing gradient in Euclidean space
[2019-11-19 11:37:35.881833 UTC] Computing approximate natural gradient using conjugate gradient algorithm
[2019-11-19 11:37:36.458638 UTC] Performing line search
[2019-11-19 11:37:36.543233 UTC] Updating baseline
[2019-11-19 11:37:37.325337 UTC] Computing logging information
-------------------------------------
| Iteration            | 81         |
| ExpectedImprovement  | 0.020649   |
| ActualImprovement    | 0.020525   |
| ImprovementRatio     | 0.994      |
| MeanKL               | 0.0065283  |
| Entropy              | 2.7539     |
| Perplexity           | 15.704     |
| AveragePolicyStd     | 0.3852     |
| AveragePolicyStd[0]  | 0.42381    |
| AveragePolicyStd[1]  | 0.45031    |
| AveragePolicyStd[2]  | 0.39518    |
| AveragePolicyStd[3]  | 0.3282     |
| AveragePolicyStd[4]  | 0.35817    |
| AveragePolicyStd[5]  | 0.35554    |
| AverageReturn        | 80.383     |
| MinReturn            | 22.121     |
| MaxReturn            | 146.53     |
| StdReturn            | 20.264     |
| AverageEpisodeLength | 104.67     |
| MinEpisodeLength     | 52         |
| MaxEpisodeLength     | 242        |
| StdEpisodeLength     | 38.17      |
| TotalNEpisodes       | 14642      |
| TotalNSamples        | 4.0996e+05 |
| ExplainedVariance    | 0.86473    |
-------------------------------------
[2019-11-19 11:37:38.350498 UTC] Saving snapshot
[2019-11-19 11:37:38.351640 UTC] Starting iteration 82
[2019-11-19 11:37:38.352398 UTC] Start collecting samples
[2019-11-19 11:37:40.631537 UTC] Computing input variables for policy optimization
[2019-11-19 11:37:40.701786 UTC] Performing policy update
[2019-11-19 11:37:40.703238 UTC] Computing gradient in Euclidean space
[2019-11-19 11:37:40.763363 UTC] Computing approximate natural gradient using conjugate gradient algorithm
[2019-11-19 11:37:41.336219 UTC] Performing line search
[2019-11-19 11:37:41.416795 UTC] Updating baseline
[2019-11-19 11:37:42.169916 UTC] Computing logging information
-------------------------------------
| Iteration            | 82         |
| ExpectedImprovement  | 0.022144   |
| ActualImprovement    | 0.020228   |
| ImprovementRatio     | 0.91348    |
| MeanKL               | 0.0066137  |
| Entropy              | 2.7479     |
| Perplexity           | 15.609     |
| AveragePolicyStd     | 0.38479    |
| AveragePolicyStd[0]  | 0.42559    |
| AveragePolicyStd[1]  | 0.44724    |
| AveragePolicyStd[2]  | 0.39597    |
| AveragePolicyStd[3]  | 0.32886    |
| AveragePolicyStd[4]  | 0.35794    |
| AveragePolicyStd[5]  | 0.35313    |
| AverageReturn        | 80.672     |
| MinReturn            | 10.28      |
| MaxReturn            | 162.25     |
| StdReturn            | 24.077     |
| AverageEpisodeLength | 107.32     |
| MinEpisodeLength     | 31         |
| MaxEpisodeLength     | 266        |
| StdEpisodeLength     | 45.348     |
| TotalNEpisodes       | 14684      |
| TotalNSamples        | 4.1448e+05 |
| ExplainedVariance    | 0.85944    |
-------------------------------------
[2019-11-19 11:37:43.355696 UTC] Saving snapshot
[2019-11-19 11:37:43.356571 UTC] Starting iteration 83
[2019-11-19 11:37:43.357832 UTC] Start collecting samples
[2019-11-19 11:37:45.763521 UTC] Computing input variables for policy optimization
[2019-11-19 11:37:45.838147 UTC] Performing policy update
[2019-11-19 11:37:45.839355 UTC] Computing gradient in Euclidean space
[2019-11-19 11:37:45.894085 UTC] Computing approximate natural gradient using conjugate gradient algorithm
[2019-11-19 11:37:46.472195 UTC] Performing line search
[2019-11-19 11:37:46.552032 UTC] Updating baseline
[2019-11-19 11:37:47.291745 UTC] Computing logging information
-------------------------------------
| Iteration            | 83         |
| ExpectedImprovement  | 0.020318   |
| ActualImprovement    | 0.019824   |
| ImprovementRatio     | 0.97572    |
| MeanKL               | 0.0065145  |
| Entropy              | 2.7242     |
| Perplexity           | 15.245     |
| AveragePolicyStd     | 0.38334    |
| AveragePolicyStd[0]  | 0.42523    |
| AveragePolicyStd[1]  | 0.44616    |
| AveragePolicyStd[2]  | 0.39578    |
| AveragePolicyStd[3]  | 0.32915    |
| AveragePolicyStd[4]  | 0.35251    |
| AveragePolicyStd[5]  | 0.3512     |
| AverageReturn        | 82.228     |
| MinReturn            | 10.28      |
| MaxReturn            | 175.78     |
| StdReturn            | 24.127     |
| AverageEpisodeLength | 107.79     |
| MinEpisodeLength     | 31         |
| MaxEpisodeLength     | 271        |
| StdEpisodeLength     | 46.382     |
| TotalNEpisodes       | 14732      |
| TotalNSamples        | 4.1984e+05 |
| ExplainedVariance    | 0.93656    |
-------------------------------------
[2019-11-19 11:37:48.256752 UTC] Saving snapshot
[2019-11-19 11:37:48.257854 UTC] Starting iteration 84
[2019-11-19 11:37:48.258731 UTC] Start collecting samples
[2019-11-19 11:37:50.427144 UTC] Computing input variables for policy optimization
[2019-11-19 11:37:50.502434 UTC] Performing policy update
[2019-11-19 11:37:50.503476 UTC] Computing gradient in Euclidean space
[2019-11-19 11:37:50.556208 UTC] Computing approximate natural gradient using conjugate gradient algorithm
[2019-11-19 11:37:51.124834 UTC] Performing line search
[2019-11-19 11:37:51.203265 UTC] Updating baseline
[2019-11-19 11:37:51.923445 UTC] Computing logging information
-------------------------------------
| Iteration            | 84         |
| ExpectedImprovement  | 0.019984   |
| ActualImprovement    | 0.019769   |
| ImprovementRatio     | 0.98922    |
| MeanKL               | 0.0065194  |
| Entropy              | 2.6774     |
| Perplexity           | 14.547     |
| AveragePolicyStd     | 0.38028    |
| AveragePolicyStd[0]  | 0.42282    |
| AveragePolicyStd[1]  | 0.44122    |
| AveragePolicyStd[2]  | 0.39046    |
| AveragePolicyStd[3]  | 0.32777    |
| AveragePolicyStd[4]  | 0.35008    |
| AveragePolicyStd[5]  | 0.34933    |
| AverageReturn        | 86.07      |
| MinReturn            | 10.28      |
| MaxReturn            | 175.78     |
| StdReturn            | 23.917     |
| AverageEpisodeLength | 114.58     |
| MinEpisodeLength     | 31         |
| MaxEpisodeLength     | 271        |
| StdEpisodeLength     | 45.117     |
| TotalNEpisodes       | 14774      |
| TotalNSamples        | 4.2489e+05 |
| ExplainedVariance    | 0.89198    |
-------------------------------------
[2019-11-19 11:37:52.930338 UTC] Saving snapshot
[2019-11-19 11:37:52.931251 UTC] Starting iteration 85
[2019-11-19 11:37:52.931931 UTC] Start collecting samples
[2019-11-19 11:37:55.208900 UTC] Computing input variables for policy optimization
[2019-11-19 11:37:55.281358 UTC] Performing policy update
[2019-11-19 11:37:55.282611 UTC] Computing gradient in Euclidean space
[2019-11-19 11:37:55.339129 UTC] Computing approximate natural gradient using conjugate gradient algorithm
[2019-11-19 11:37:55.912927 UTC] Performing line search
[2019-11-19 11:37:55.991178 UTC] Updating baseline
[2019-11-19 11:37:56.714723 UTC] Computing logging information
-------------------------------------
| Iteration            | 85         |
| ExpectedImprovement  | 0.02336    |
| ActualImprovement    | 0.022514   |
| ImprovementRatio     | 0.96376    |
| MeanKL               | 0.0066446  |
| Entropy              | 2.6639     |
| Perplexity           | 14.352     |
| AveragePolicyStd     | 0.37951    |
| AveragePolicyStd[0]  | 0.4218     |
| AveragePolicyStd[1]  | 0.44097    |
| AveragePolicyStd[2]  | 0.39076    |
| AveragePolicyStd[3]  | 0.32343    |
| AveragePolicyStd[4]  | 0.34989    |
| AveragePolicyStd[5]  | 0.35024    |
| AverageReturn        | 87.184     |
| MinReturn            | 35.59      |
| MaxReturn            | 175.78     |
| StdReturn            | 22.227     |
| AverageEpisodeLength | 116.05     |
| MinEpisodeLength     | 55         |
| MaxEpisodeLength     | 271        |
| StdEpisodeLength     | 43.512     |
| TotalNEpisodes       | 14813      |
| TotalNSamples        | 4.2948e+05 |
| ExplainedVariance    | 0.90318    |
-------------------------------------
[2019-11-19 11:37:57.754128 UTC] Saving snapshot
[2019-11-19 11:37:57.754991 UTC] Starting iteration 86
[2019-11-19 11:37:57.756030 UTC] Start collecting samples
[2019-11-19 11:37:59.981021 UTC] Computing input variables for policy optimization
[2019-11-19 11:38:00.054171 UTC] Performing policy update
[2019-11-19 11:38:00.055392 UTC] Computing gradient in Euclidean space
[2019-11-19 11:38:00.109947 UTC] Computing approximate natural gradient using conjugate gradient algorithm
[2019-11-19 11:38:00.678554 UTC] Performing line search
[2019-11-19 11:38:00.759513 UTC] Updating baseline
[2019-11-19 11:38:01.466568 UTC] Computing logging information
-------------------------------------
| Iteration            | 86         |
| ExpectedImprovement  | 0.019635   |
| ActualImprovement    | 0.019461   |
| ImprovementRatio     | 0.99114    |
| MeanKL               | 0.0066005  |
| Entropy              | 2.6489     |
| Perplexity           | 14.138     |
| AveragePolicyStd     | 0.37848    |
| AveragePolicyStd[0]  | 0.42417    |
| AveragePolicyStd[1]  | 0.43563    |
| AveragePolicyStd[2]  | 0.38673    |
| AveragePolicyStd[3]  | 0.32183    |
| AveragePolicyStd[4]  | 0.35168    |
| AveragePolicyStd[5]  | 0.35086    |
| AverageReturn        | 90.503     |
| MinReturn            | 53.942     |
| MaxReturn            | 154.75     |
| StdReturn            | 21.882     |
| AverageEpisodeLength | 121.49     |
| MinEpisodeLength     | 55         |
| MaxEpisodeLength     | 252        |
| StdEpisodeLength     | 43.855     |
| TotalNEpisodes       | 14854      |
| TotalNSamples        | 4.3452e+05 |
| ExplainedVariance    | 0.95419    |
-------------------------------------
[2019-11-19 11:38:02.446333 UTC] Saving snapshot
[2019-11-19 11:38:02.447507 UTC] Starting iteration 87
[2019-11-19 11:38:02.448606 UTC] Start collecting samples
[2019-11-19 11:38:04.673943 UTC] Computing input variables for policy optimization
[2019-11-19 11:38:04.748810 UTC] Performing policy update
[2019-11-19 11:38:04.750303 UTC] Computing gradient in Euclidean space
[2019-11-19 11:38:04.802940 UTC] Computing approximate natural gradient using conjugate gradient algorithm
[2019-11-19 11:38:05.370482 UTC] Performing line search
[2019-11-19 11:38:05.452124 UTC] Updating baseline
[2019-11-19 11:38:06.179591 UTC] Computing logging information
------------------------------------
| Iteration            | 87        |
| ExpectedImprovement  | 0.026022  |
| ActualImprovement    | 0.024631  |
| ImprovementRatio     | 0.94654   |
| MeanKL               | 0.006636  |
| Entropy              | 2.6165    |
| Perplexity           | 13.688    |
| AveragePolicyStd     | 0.37654   |
| AveragePolicyStd[0]  | 0.42319   |
| AveragePolicyStd[1]  | 0.43615   |
| AveragePolicyStd[2]  | 0.38254   |
| AveragePolicyStd[3]  | 0.32045   |
| AveragePolicyStd[4]  | 0.34909   |
| AveragePolicyStd[5]  | 0.34783   |
| AverageReturn        | 94.839    |
| MinReturn            | 53.942    |
| MaxReturn            | 163.79    |
| StdReturn            | 24.971    |
| AverageEpisodeLength | 127.59    |
| MinEpisodeLength     | 55        |
| MaxEpisodeLength     | 252       |
| StdEpisodeLength     | 50.119    |
| TotalNEpisodes       | 14893     |
| TotalNSamples        | 4.398e+05 |
| ExplainedVariance    | 0.92785   |
------------------------------------
[2019-11-19 11:38:07.300413 UTC] Saving snapshot
[2019-11-19 11:38:07.301704 UTC] Starting iteration 88
[2019-11-19 11:38:07.302828 UTC] Start collecting samples
[2019-11-19 11:38:09.492382 UTC] Computing input variables for policy optimization
[2019-11-19 11:38:09.576163 UTC] Performing policy update
[2019-11-19 11:38:09.577368 UTC] Computing gradient in Euclidean space
[2019-11-19 11:38:09.629323 UTC] Computing approximate natural gradient using conjugate gradient algorithm
[2019-11-19 11:38:10.208431 UTC] Performing line search
[2019-11-19 11:38:10.286327 UTC] Updating baseline
[2019-11-19 11:38:10.997587 UTC] Computing logging information
-------------------------------------
| Iteration            | 88         |
| ExpectedImprovement  | 0.019982   |
| ActualImprovement    | 0.020143   |
| ImprovementRatio     | 1.008      |
| MeanKL               | 0.0066079  |
| Entropy              | 2.5735     |
| Perplexity           | 13.112     |
| AveragePolicyStd     | 0.37379    |
| AveragePolicyStd[0]  | 0.42168    |
| AveragePolicyStd[1]  | 0.42973    |
| AveragePolicyStd[2]  | 0.38102    |
| AveragePolicyStd[3]  | 0.31943    |
| AveragePolicyStd[4]  | 0.34547    |
| AveragePolicyStd[5]  | 0.34542    |
| AverageReturn        | 98.631     |
| MinReturn            | 57.639     |
| MaxReturn            | 163.79     |
| StdReturn            | 23.186     |
| AverageEpisodeLength | 133.53     |
| MinEpisodeLength     | 55         |
| MaxEpisodeLength     | 252        |
| StdEpisodeLength     | 45.179     |
| TotalNEpisodes       | 14928      |
| TotalNSamples        | 4.4476e+05 |
| ExplainedVariance    | 0.96434    |
-------------------------------------
[2019-11-19 11:38:12.197540 UTC] Saving snapshot
[2019-11-19 11:38:12.198896 UTC] Starting iteration 89
[2019-11-19 11:38:12.200021 UTC] Start collecting samples
[2019-11-19 11:38:14.329862 UTC] Computing input variables for policy optimization
[2019-11-19 11:38:14.395567 UTC] Performing policy update
[2019-11-19 11:38:14.396551 UTC] Computing gradient in Euclidean space
[2019-11-19 11:38:14.450809 UTC] Computing approximate natural gradient using conjugate gradient algorithm
[2019-11-19 11:38:15.023080 UTC] Performing line search
[2019-11-19 11:38:15.101290 UTC] Updating baseline
[2019-11-19 11:38:15.815450 UTC] Computing logging information
-------------------------------------
| Iteration            | 89         |
| ExpectedImprovement  | 0.019666   |
| ActualImprovement    | 0.019357   |
| ImprovementRatio     | 0.9843     |
| MeanKL               | 0.0066345  |
| Entropy              | 2.5579     |
| Perplexity           | 12.908     |
| AveragePolicyStd     | 0.37284    |
| AveragePolicyStd[0]  | 0.4233     |
| AveragePolicyStd[1]  | 0.42799    |
| AveragePolicyStd[2]  | 0.37902    |
| AveragePolicyStd[3]  | 0.32034    |
| AveragePolicyStd[4]  | 0.34068    |
| AveragePolicyStd[5]  | 0.34574    |
| AverageReturn        | 103.07     |
| MinReturn            | 57.639     |
| MaxReturn            | 193.71     |
| StdReturn            | 27.855     |
| AverageEpisodeLength | 141.27     |
| MinEpisodeLength     | 55         |
| MaxEpisodeLength     | 294        |
| StdEpisodeLength     | 54.784     |
| TotalNEpisodes       | 14961      |
| TotalNSamples        | 4.4976e+05 |
| ExplainedVariance    | 0.97098    |
-------------------------------------
[2019-11-19 11:38:16.934627 UTC] Saving snapshot
[2019-11-19 11:38:16.935782 UTC] Starting iteration 90
[2019-11-19 11:38:16.936680 UTC] Start collecting samples
[2019-11-19 11:38:18.937743 UTC] Computing input variables for policy optimization
[2019-11-19 11:38:19.006676 UTC] Performing policy update
[2019-11-19 11:38:19.007567 UTC] Computing gradient in Euclidean space
[2019-11-19 11:38:19.060857 UTC] Computing approximate natural gradient using conjugate gradient algorithm
[2019-11-19 11:38:19.632187 UTC] Performing line search
[2019-11-19 11:38:19.711091 UTC] Updating baseline
[2019-11-19 11:38:20.416739 UTC] Computing logging information
-------------------------------------
| Iteration            | 90         |
| ExpectedImprovement  | 0.021742   |
| ActualImprovement    | 0.019712   |
| ImprovementRatio     | 0.90661    |
| MeanKL               | 0.0067353  |
| Entropy              | 2.5405     |
| Perplexity           | 12.686     |
| AveragePolicyStd     | 0.3716     |
| AveragePolicyStd[0]  | 0.41809    |
| AveragePolicyStd[1]  | 0.4264     |
| AveragePolicyStd[2]  | 0.37696    |
| AveragePolicyStd[3]  | 0.32141    |
| AveragePolicyStd[4]  | 0.34054    |
| AveragePolicyStd[5]  | 0.34619    |
| AverageReturn        | 106.09     |
| MinReturn            | 49.2       |
| MaxReturn            | 193.71     |
| StdReturn            | 26.698     |
| AverageEpisodeLength | 146.05     |
| MinEpisodeLength     | 59         |
| MaxEpisodeLength     | 294        |
| StdEpisodeLength     | 51.319     |
| TotalNEpisodes       | 14994      |
| TotalNSamples        | 4.5455e+05 |
| ExplainedVariance    | 0.92064    |
-------------------------------------
[2019-11-19 11:38:21.347627 UTC] Saving snapshot
[2019-11-19 11:38:21.367657 UTC] Starting iteration 91
[2019-11-19 11:38:21.368366 UTC] Start collecting samples
[2019-11-19 11:38:23.309810 UTC] Computing input variables for policy optimization
[2019-11-19 11:38:23.379122 UTC] Performing policy update
[2019-11-19 11:38:23.380189 UTC] Computing gradient in Euclidean space
[2019-11-19 11:38:23.433530 UTC] Computing approximate natural gradient using conjugate gradient algorithm
[2019-11-19 11:38:24.025981 UTC] Performing line search
[2019-11-19 11:38:24.109958 UTC] Updating baseline
[2019-11-19 11:38:24.841213 UTC] Computing logging information
-------------------------------------
| Iteration            | 91         |
| ExpectedImprovement  | 0.019383   |
| ActualImprovement    | 0.020151   |
| ImprovementRatio     | 1.0396     |
| MeanKL               | 0.0065229  |
| Entropy              | 2.5229     |
| Perplexity           | 12.465     |
| AveragePolicyStd     | 0.37055    |
| AveragePolicyStd[0]  | 0.42023    |
| AveragePolicyStd[1]  | 0.4228     |
| AveragePolicyStd[2]  | 0.37468    |
| AveragePolicyStd[3]  | 0.31831    |
| AveragePolicyStd[4]  | 0.33972    |
| AveragePolicyStd[5]  | 0.34754    |
| AverageReturn        | 110.18     |
| MinReturn            | 49.2       |
| MaxReturn            | 266.03     |
| StdReturn            | 32.252     |
| AverageEpisodeLength | 150.91     |
| MinEpisodeLength     | 59         |
| MaxEpisodeLength     | 428        |
| StdEpisodeLength     | 60.087     |
| TotalNEpisodes       | 15026      |
| TotalNSamples        | 4.5952e+05 |
| ExplainedVariance    | 0.9218     |
-------------------------------------
[2019-11-19 11:38:25.779377 UTC] Saving snapshot
[2019-11-19 11:38:25.780262 UTC] Starting iteration 92
[2019-11-19 11:38:25.781033 UTC] Start collecting samples
[2019-11-19 11:38:27.689133 UTC] Computing input variables for policy optimization
[2019-11-19 11:38:27.757241 UTC] Performing policy update
[2019-11-19 11:38:27.758234 UTC] Computing gradient in Euclidean space
[2019-11-19 11:38:27.813107 UTC] Computing approximate natural gradient using conjugate gradient algorithm
[2019-11-19 11:38:28.385800 UTC] Performing line search
[2019-11-19 11:38:28.465441 UTC] Updating baseline
[2019-11-19 11:38:29.197758 UTC] Computing logging information
-------------------------------------
| Iteration            | 92         |
| ExpectedImprovement  | 0.019443   |
| ActualImprovement    | 0.019728   |
| ImprovementRatio     | 1.0147     |
| MeanKL               | 0.0067831  |
| Entropy              | 2.4784     |
| Perplexity           | 11.923     |
| AveragePolicyStd     | 0.36773    |
| AveragePolicyStd[0]  | 0.41805    |
| AveragePolicyStd[1]  | 0.41577    |
| AveragePolicyStd[2]  | 0.37271    |
| AveragePolicyStd[3]  | 0.31631    |
| AveragePolicyStd[4]  | 0.3371     |
| AveragePolicyStd[5]  | 0.34644    |
| AverageReturn        | 114.26     |
| MinReturn            | 49.2       |
| MaxReturn            | 266.03     |
| StdReturn            | 33.869     |
| AverageEpisodeLength | 156.87     |
| MinEpisodeLength     | 59         |
| MaxEpisodeLength     | 428        |
| StdEpisodeLength     | 62.52      |
| TotalNEpisodes       | 15056      |
| TotalNSamples        | 4.6460e+05 |
| ExplainedVariance    | 0.96684    |
-------------------------------------
[2019-11-19 11:38:30.429598 UTC] Saving snapshot
[2019-11-19 11:38:30.430448 UTC] Starting iteration 93
[2019-11-19 11:38:30.431329 UTC] Start collecting samples
[2019-11-19 11:38:32.419679 UTC] Computing input variables for policy optimization
[2019-11-19 11:38:32.490107 UTC] Performing policy update
[2019-11-19 11:38:32.491253 UTC] Computing gradient in Euclidean space
[2019-11-19 11:38:32.541195 UTC] Computing approximate natural gradient using conjugate gradient algorithm
[2019-11-19 11:38:33.112434 UTC] Performing line search
[2019-11-19 11:38:33.192356 UTC] Updating baseline
[2019-11-19 11:38:33.991791 UTC] Computing logging information
-------------------------------------
| Iteration            | 93         |
| ExpectedImprovement  | 0.021477   |
| ActualImprovement    | 0.019249   |
| ImprovementRatio     | 0.89625    |
| MeanKL               | 0.0065991  |
| Entropy              | 2.4606     |
| Perplexity           | 11.712     |
| AveragePolicyStd     | 0.36661    |
| AveragePolicyStd[0]  | 0.4167     |
| AveragePolicyStd[1]  | 0.4144     |
| AveragePolicyStd[2]  | 0.3696     |
| AveragePolicyStd[3]  | 0.31548    |
| AveragePolicyStd[4]  | 0.33636    |
| AveragePolicyStd[5]  | 0.34709    |
| AverageReturn        | 115.74     |
| MinReturn            | 37.523     |
| MaxReturn            | 266.03     |
| StdReturn            | 34.936     |
| AverageEpisodeLength | 158.75     |
| MinEpisodeLength     | 60         |
| MaxEpisodeLength     | 428        |
| StdEpisodeLength     | 62.044     |
| TotalNEpisodes       | 15083      |
| TotalNSamples        | 4.6884e+05 |
| ExplainedVariance    | 0.86878    |
-------------------------------------
[2019-11-19 11:38:34.982539 UTC] Saving snapshot
[2019-11-19 11:38:34.983351 UTC] Starting iteration 94
[2019-11-19 11:38:34.984088 UTC] Start collecting samples
[2019-11-19 11:38:36.891915 UTC] Computing input variables for policy optimization
[2019-11-19 11:38:36.958089 UTC] Performing policy update
[2019-11-19 11:38:36.959166 UTC] Computing gradient in Euclidean space
[2019-11-19 11:38:37.010094 UTC] Computing approximate natural gradient using conjugate gradient algorithm
[2019-11-19 11:38:37.586110 UTC] Performing line search
[2019-11-19 11:38:37.665194 UTC] Updating baseline
[2019-11-19 11:38:38.394486 UTC] Computing logging information
-------------------------------------
| Iteration            | 94         |
| ExpectedImprovement  | 0.021343   |
| ActualImprovement    | 0.021554   |
| ImprovementRatio     | 1.0099     |
| MeanKL               | 0.0064879  |
| Entropy              | 2.4475     |
| Perplexity           | 11.559     |
| AveragePolicyStd     | 0.36577    |
| AveragePolicyStd[0]  | 0.41586    |
| AveragePolicyStd[1]  | 0.41472    |
| AveragePolicyStd[2]  | 0.36578    |
| AveragePolicyStd[3]  | 0.31727    |
| AveragePolicyStd[4]  | 0.33567    |
| AveragePolicyStd[5]  | 0.34533    |
| AverageReturn        | 121.76     |
| MinReturn            | 37.523     |
| MaxReturn            | 266.03     |
| StdReturn            | 40.23      |
| AverageEpisodeLength | 170.1      |
| MinEpisodeLength     | 60         |
| MaxEpisodeLength     | 428        |
| StdEpisodeLength     | 72.764     |
| TotalNEpisodes       | 15111      |
| TotalNSamples        | 4.7412e+05 |
| ExplainedVariance    | 0.95835    |
-------------------------------------
[2019-11-19 11:38:39.689077 UTC] Saving snapshot
[2019-11-19 11:38:39.689759 UTC] Starting iteration 95
[2019-11-19 11:38:39.690333 UTC] Start collecting samples
[2019-11-19 11:38:41.658900 UTC] Computing input variables for policy optimization
[2019-11-19 11:38:41.726104 UTC] Performing policy update
[2019-11-19 11:38:41.727123 UTC] Computing gradient in Euclidean space
[2019-11-19 11:38:41.780562 UTC] Computing approximate natural gradient using conjugate gradient algorithm
[2019-11-19 11:38:42.349218 UTC] Performing line search
[2019-11-19 11:38:42.431193 UTC] Updating baseline
[2019-11-19 11:38:43.157450 UTC] Computing logging information
-------------------------------------
| Iteration            | 95         |
| ExpectedImprovement  | 0.022072   |
| ActualImprovement    | 0.021857   |
| ImprovementRatio     | 0.99027    |
| MeanKL               | 0.0066452  |
| Entropy              | 2.4241     |
| Perplexity           | 11.292     |
| AveragePolicyStd     | 0.36423    |
| AveragePolicyStd[0]  | 0.41345    |
| AveragePolicyStd[1]  | 0.41102    |
| AveragePolicyStd[2]  | 0.36327    |
| AveragePolicyStd[3]  | 0.31882    |
| AveragePolicyStd[4]  | 0.33234    |
| AveragePolicyStd[5]  | 0.34649    |
| AverageReturn        | 124.8      |
| MinReturn            | 37.523     |
| MaxReturn            | 271.67     |
| StdReturn            | 40.044     |
| AverageEpisodeLength | 174.81     |
| MinEpisodeLength     | 60         |
| MaxEpisodeLength     | 431        |
| StdEpisodeLength     | 71.182     |
| TotalNEpisodes       | 15135      |
| TotalNSamples        | 4.7836e+05 |
| ExplainedVariance    | 0.97669    |
-------------------------------------
[2019-11-19 11:38:44.334140 UTC] Saving snapshot
[2019-11-19 11:38:44.334968 UTC] Starting iteration 96
[2019-11-19 11:38:44.335565 UTC] Start collecting samples
[2019-11-19 11:38:46.259815 UTC] Computing input variables for policy optimization
[2019-11-19 11:38:46.326894 UTC] Performing policy update
[2019-11-19 11:38:46.328319 UTC] Computing gradient in Euclidean space
[2019-11-19 11:38:46.385644 UTC] Computing approximate natural gradient using conjugate gradient algorithm
[2019-11-19 11:38:46.952309 UTC] Performing line search
[2019-11-19 11:38:47.033168 UTC] Updating baseline
[2019-11-19 11:38:47.745005 UTC] Computing logging information
-------------------------------------
| Iteration            | 96         |
| ExpectedImprovement  | 0.029653   |
| ActualImprovement    | 0.025517   |
| ImprovementRatio     | 0.86051    |
| MeanKL               | 0.0065211  |
| Entropy              | 2.4067     |
| Perplexity           | 11.097     |
| AveragePolicyStd     | 0.36316    |
| AveragePolicyStd[0]  | 0.41027    |
| AveragePolicyStd[1]  | 0.41093    |
| AveragePolicyStd[2]  | 0.36097    |
| AveragePolicyStd[3]  | 0.31781    |
| AveragePolicyStd[4]  | 0.32987    |
| AveragePolicyStd[5]  | 0.34913    |
| AverageReturn        | 130.83     |
| MinReturn            | 13.624     |
| MaxReturn            | 311.76     |
| StdReturn            | 49.303     |
| AverageEpisodeLength | 186.2      |
| MinEpisodeLength     | 36         |
| MaxEpisodeLength     | 495        |
| StdEpisodeLength     | 85.464     |
| TotalNEpisodes       | 15162      |
| TotalNSamples        | 4.8403e+05 |
| ExplainedVariance    | 0.83286    |
-------------------------------------
[2019-11-19 11:38:48.753967 UTC] Saving snapshot
[2019-11-19 11:38:48.754689 UTC] Starting iteration 97
[2019-11-19 11:38:48.755706 UTC] Start collecting samples
[2019-11-19 11:38:50.848928 UTC] Computing input variables for policy optimization
[2019-11-19 11:38:50.916259 UTC] Performing policy update
[2019-11-19 11:38:50.917459 UTC] Computing gradient in Euclidean space
[2019-11-19 11:38:50.971734 UTC] Computing approximate natural gradient using conjugate gradient algorithm
[2019-11-19 11:38:51.542457 UTC] Performing line search
[2019-11-19 11:38:51.622378 UTC] Updating baseline
[2019-11-19 11:38:52.339537 UTC] Computing logging information
-------------------------------------
| Iteration            | 97         |
| ExpectedImprovement  | 0.01999    |
| ActualImprovement    | 0.018846   |
| ImprovementRatio     | 0.94275    |
| MeanKL               | 0.0067309  |
| Entropy              | 2.4021     |
| Perplexity           | 11.047     |
| AveragePolicyStd     | 0.36285    |
| AveragePolicyStd[0]  | 0.40882    |
| AveragePolicyStd[1]  | 0.41008    |
| AveragePolicyStd[2]  | 0.35986    |
| AveragePolicyStd[3]  | 0.31658    |
| AveragePolicyStd[4]  | 0.33069    |
| AveragePolicyStd[5]  | 0.35105    |
| AverageReturn        | 135.73     |
| MinReturn            | 13.624     |
| MaxReturn            | 311.76     |
| StdReturn            | 50.721     |
| AverageEpisodeLength | 193.06     |
| MinEpisodeLength     | 36         |
| MaxEpisodeLength     | 495        |
| StdEpisodeLength     | 88.063     |
| TotalNEpisodes       | 15190      |
| TotalNSamples        | 4.8927e+05 |
| ExplainedVariance    | 0.94234    |
-------------------------------------
[2019-11-19 11:38:53.248093 UTC] Saving snapshot
[2019-11-19 11:38:53.248884 UTC] Starting iteration 98
[2019-11-19 11:38:53.249516 UTC] Start collecting samples
[2019-11-19 11:38:55.072812 UTC] Computing input variables for policy optimization
[2019-11-19 11:38:55.136193 UTC] Performing policy update
[2019-11-19 11:38:55.137397 UTC] Computing gradient in Euclidean space
[2019-11-19 11:38:55.191084 UTC] Computing approximate natural gradient using conjugate gradient algorithm
[2019-11-19 11:38:55.761515 UTC] Performing line search
[2019-11-19 11:38:55.840850 UTC] Updating baseline
[2019-11-19 11:38:56.570573 UTC] Computing logging information
-------------------------------------
| Iteration            | 98         |
| ExpectedImprovement  | 0.028316   |
| ActualImprovement    | 0.026968   |
| ImprovementRatio     | 0.9524     |
| MeanKL               | 0.0065291  |
| Entropy              | 2.3553     |
| Perplexity           | 10.542     |
| AveragePolicyStd     | 0.35997    |
| AveragePolicyStd[0]  | 0.40658    |
| AveragePolicyStd[1]  | 0.40448    |
| AveragePolicyStd[2]  | 0.3589     |
| AveragePolicyStd[3]  | 0.31516    |
| AveragePolicyStd[4]  | 0.32932    |
| AveragePolicyStd[5]  | 0.3454     |
| AverageReturn        | 138.27     |
| MinReturn            | 13.624     |
| MaxReturn            | 311.76     |
| StdReturn            | 53.122     |
| AverageEpisodeLength | 195.85     |
| MinEpisodeLength     | 36         |
| MaxEpisodeLength     | 495        |
| StdEpisodeLength     | 88.647     |
| TotalNEpisodes       | 15213      |
| TotalNSamples        | 4.9406e+05 |
| ExplainedVariance    | 0.90831    |
-------------------------------------
[2019-11-19 11:38:57.557736 UTC] Saving snapshot
[2019-11-19 11:38:57.558747 UTC] Starting iteration 99
[2019-11-19 11:38:57.559715 UTC] Start collecting samples
[2019-11-19 11:38:59.285187 UTC] Computing input variables for policy optimization
[2019-11-19 11:38:59.347717 UTC] Performing policy update
[2019-11-19 11:38:59.349103 UTC] Computing gradient in Euclidean space
[2019-11-19 11:38:59.413961 UTC] Computing approximate natural gradient using conjugate gradient algorithm
[2019-11-19 11:39:00.000474 UTC] Performing line search
[2019-11-19 11:39:00.081582 UTC] Updating baseline
[2019-11-19 11:39:00.811119 UTC] Computing logging information
-------------------------------------
| Iteration            | 99         |
| ExpectedImprovement  | 0.016623   |
| ActualImprovement    | 0.017106   |
| ImprovementRatio     | 1.0291     |
| MeanKL               | 0.0066842  |
| Entropy              | 2.3386     |
| Perplexity           | 10.367     |
| AveragePolicyStd     | 0.35902    |
| AveragePolicyStd[0]  | 0.40406    |
| AveragePolicyStd[1]  | 0.40656    |
| AveragePolicyStd[2]  | 0.35888    |
| AveragePolicyStd[3]  | 0.31544    |
| AveragePolicyStd[4]  | 0.32651    |
| AveragePolicyStd[5]  | 0.34266    |
| AverageReturn        | 139.77     |
| MinReturn            | 13.624     |
| MaxReturn            | 311.76     |
| StdReturn            | 52.248     |
| AverageEpisodeLength | 198.35     |
| MinEpisodeLength     | 36         |
| MaxEpisodeLength     | 495        |
| StdEpisodeLength     | 86.296     |
| TotalNEpisodes       | 15230      |
| TotalNSamples        | 4.9756e+05 |
| ExplainedVariance    | 0.74817    |
-------------------------------------
[2019-11-19 11:39:01.798995 UTC] Saving snapshot
[2019-11-19 11:39:01.799962 UTC] Starting iteration 100
[2019-11-19 11:39:01.800692 UTC] Start collecting samples
[2019-11-19 11:39:03.730179 UTC] Computing input variables for policy optimization
[2019-11-19 11:39:03.794217 UTC] Performing policy update
[2019-11-19 11:39:03.795517 UTC] Computing gradient in Euclidean space
[2019-11-19 11:39:03.852068 UTC] Computing approximate natural gradient using conjugate gradient algorithm
[2019-11-19 11:39:04.419252 UTC] Performing line search
[2019-11-19 11:39:04.506412 UTC] Updating baseline
[2019-11-19 11:39:05.237875 UTC] Computing logging information
-------------------------------------
| Iteration            | 100        |
| ExpectedImprovement  | 0.023034   |
| ActualImprovement    | 0.025226   |
| ImprovementRatio     | 1.0952     |
| MeanKL               | 0.0067071  |
| Entropy              | 2.3174     |
| Perplexity           | 10.149     |
| AveragePolicyStd     | 0.35761    |
| AveragePolicyStd[0]  | 0.40136    |
| AveragePolicyStd[1]  | 0.40153    |
| AveragePolicyStd[2]  | 0.35655    |
| AveragePolicyStd[3]  | 0.31377    |
| AveragePolicyStd[4]  | 0.32855    |
| AveragePolicyStd[5]  | 0.3439     |
| AverageReturn        | 147.88     |
| MinReturn            | 15.981     |
| MaxReturn            | 453.5      |
| StdReturn            | 61.302     |
| AverageEpisodeLength | 210.94     |
| MinEpisodeLength     | 44         |
| MaxEpisodeLength     | 812        |
| StdEpisodeLength     | 106.14     |
| TotalNEpisodes       | 15255      |
| TotalNSamples        | 5.0372e+05 |
| ExplainedVariance    | 0.94059    |
-------------------------------------
[2019-11-19 11:39:06.147146 UTC] Saving snapshot
[2019-11-19 11:39:06.170946 UTC] Starting iteration 101
[2019-11-19 11:39:06.172993 UTC] Start collecting samples
[2019-11-19 11:39:07.868893 UTC] Computing input variables for policy optimization
[2019-11-19 11:39:07.924004 UTC] Performing policy update
[2019-11-19 11:39:07.925216 UTC] Computing gradient in Euclidean space
[2019-11-19 11:39:07.977734 UTC] Computing approximate natural gradient using conjugate gradient algorithm
[2019-11-19 11:39:08.546049 UTC] Performing line search
[2019-11-19 11:39:08.625167 UTC] Updating baseline
[2019-11-19 11:39:09.347379 UTC] Computing logging information
-------------------------------------
| Iteration            | 101        |
| ExpectedImprovement  | 0.02188    |
| ActualImprovement    | 0.021082   |
| ImprovementRatio     | 0.96351    |
| MeanKL               | 0.0066271  |
| Entropy              | 2.2942     |
| Perplexity           | 9.9167     |
| AveragePolicyStd     | 0.35621    |
| AveragePolicyStd[0]  | 0.39853    |
| AveragePolicyStd[1]  | 0.40013    |
| AveragePolicyStd[2]  | 0.35596    |
| AveragePolicyStd[3]  | 0.31355    |
| AveragePolicyStd[4]  | 0.32511    |
| AveragePolicyStd[5]  | 0.34398    |
| AverageReturn        | 151.37     |
| MinReturn            | 15.981     |
| MaxReturn            | 453.5      |
| StdReturn            | 61.79      |
| AverageEpisodeLength | 217.14     |
| MinEpisodeLength     | 44         |
| MaxEpisodeLength     | 812        |
| StdEpisodeLength     | 109.53     |
| TotalNEpisodes       | 15270      |
| TotalNSamples        | 5.0721e+05 |
| ExplainedVariance    | 0.85319    |
-------------------------------------
[2019-11-19 11:39:10.395223 UTC] Saving snapshot
[2019-11-19 11:39:10.396063 UTC] Starting iteration 102
[2019-11-19 11:39:10.396831 UTC] Start collecting samples
[2019-11-19 11:39:12.420046 UTC] Computing input variables for policy optimization
[2019-11-19 11:39:12.519726 UTC] Performing policy update
[2019-11-19 11:39:12.522863 UTC] Computing gradient in Euclidean space
[2019-11-19 11:39:12.604836 UTC] Computing approximate natural gradient using conjugate gradient algorithm
[2019-11-19 11:39:13.359426 UTC] Performing line search
[2019-11-19 11:39:13.435173 UTC] Updating baseline
[2019-11-19 11:39:14.213681 UTC] Computing logging information
-------------------------------------
| Iteration            | 102        |
| ExpectedImprovement  | 0.024004   |
| ActualImprovement    | 0.021948   |
| ImprovementRatio     | 0.91434    |
| MeanKL               | 0.0065782  |
| Entropy              | 2.2821     |
| Perplexity           | 9.7973     |
| AveragePolicyStd     | 0.35552    |
| AveragePolicyStd[0]  | 0.39736    |
| AveragePolicyStd[1]  | 0.40022    |
| AveragePolicyStd[2]  | 0.35414    |
| AveragePolicyStd[3]  | 0.31072    |
| AveragePolicyStd[4]  | 0.32597    |
| AveragePolicyStd[5]  | 0.34474    |
| AverageReturn        | 159.57     |
| MinReturn            | 15.981     |
| MaxReturn            | 453.5      |
| StdReturn            | 66.339     |
| AverageEpisodeLength | 231.32     |
| MinEpisodeLength     | 44         |
| MaxEpisodeLength     | 812        |
| StdEpisodeLength     | 119.17     |
| TotalNEpisodes       | 15292      |
| TotalNSamples        | 5.1272e+05 |
| ExplainedVariance    | 0.91106    |
-------------------------------------
[2019-11-19 11:39:15.675069 UTC] Saving snapshot
[2019-11-19 11:39:15.675619 UTC] Starting iteration 103
[2019-11-19 11:39:15.676198 UTC] Start collecting samples
[2019-11-19 11:39:17.671478 UTC] Computing input variables for policy optimization
[2019-11-19 11:39:17.731996 UTC] Performing policy update
[2019-11-19 11:39:17.733158 UTC] Computing gradient in Euclidean space
[2019-11-19 11:39:17.785921 UTC] Computing approximate natural gradient using conjugate gradient algorithm
[2019-11-19 11:39:18.410368 UTC] Performing line search
[2019-11-19 11:39:18.505915 UTC] Updating baseline
[2019-11-19 11:39:19.333650 UTC] Computing logging information
-------------------------------------
| Iteration            | 103        |
| ExpectedImprovement  | 0.018355   |
| ActualImprovement    | 0.01801    |
| ImprovementRatio     | 0.98119    |
| MeanKL               | 0.0067481  |
| Entropy              | 2.2669     |
| Perplexity           | 9.6499     |
| AveragePolicyStd     | 0.35464    |
| AveragePolicyStd[0]  | 0.39771    |
| AveragePolicyStd[1]  | 0.39843    |
| AveragePolicyStd[2]  | 0.35219    |
| AveragePolicyStd[3]  | 0.30925    |
| AveragePolicyStd[4]  | 0.32614    |
| AveragePolicyStd[5]  | 0.34409    |
| AverageReturn        | 166.63     |
| MinReturn            | 71.399     |
| MaxReturn            | 506.48     |
| StdReturn            | 74.699     |
| AverageEpisodeLength | 242.66     |
| MinEpisodeLength     | 82         |
| MaxEpisodeLength     | 844        |
| StdEpisodeLength     | 134.57     |
| TotalNEpisodes       | 15315      |
| TotalNSamples        | 5.1883e+05 |
| ExplainedVariance    | 0.9531     |
-------------------------------------
[2019-11-19 11:39:20.733818 UTC] Saving snapshot
[2019-11-19 11:39:20.734611 UTC] Starting iteration 104
[2019-11-19 11:39:20.735606 UTC] Start collecting samples
[2019-11-19 11:39:22.483720 UTC] Computing input variables for policy optimization
[2019-11-19 11:39:22.544446 UTC] Performing policy update
[2019-11-19 11:39:22.545848 UTC] Computing gradient in Euclidean space
[2019-11-19 11:39:22.600690 UTC] Computing approximate natural gradient using conjugate gradient algorithm
[2019-11-19 11:39:23.206269 UTC] Performing line search
[2019-11-19 11:39:23.294046 UTC] Updating baseline
[2019-11-19 11:39:24.146202 UTC] Computing logging information
-------------------------------------
| Iteration            | 104        |
| ExpectedImprovement  | 0.027446   |
| ActualImprovement    | 0.021376   |
| ImprovementRatio     | 0.77885    |
| MeanKL               | 0.0066175  |
| Entropy              | 2.2337     |
| Perplexity           | 9.3342     |
| AveragePolicyStd     | 0.35268    |
| AveragePolicyStd[0]  | 0.39605    |
| AveragePolicyStd[1]  | 0.39525    |
| AveragePolicyStd[2]  | 0.34816    |
| AveragePolicyStd[3]  | 0.30669    |
| AveragePolicyStd[4]  | 0.32391    |
| AveragePolicyStd[5]  | 0.34603    |
| AverageReturn        | 170.35     |
| MinReturn            | 9.6583     |
| MaxReturn            | 506.48     |
| StdReturn            | 78.102     |
| AverageEpisodeLength | 248.42     |
| MinEpisodeLength     | 20         |
| MaxEpisodeLength     | 844        |
| StdEpisodeLength     | 140.34     |
| TotalNEpisodes       | 15333      |
| TotalNSamples        | 5.2322e+05 |
| ExplainedVariance    | 0.9255     |
-------------------------------------
[2019-11-19 11:39:25.203322 UTC] Saving snapshot
[2019-11-19 11:39:25.204705 UTC] Starting iteration 105
[2019-11-19 11:39:25.205883 UTC] Start collecting samples
[2019-11-19 11:39:26.926854 UTC] Computing input variables for policy optimization
[2019-11-19 11:39:27.008323 UTC] Performing policy update
[2019-11-19 11:39:27.012344 UTC] Computing gradient in Euclidean space
[2019-11-19 11:39:27.087217 UTC] Computing approximate natural gradient using conjugate gradient algorithm
[2019-11-19 11:39:27.672287 UTC] Performing line search
[2019-11-19 11:39:27.754249 UTC] Updating baseline
[2019-11-19 11:39:28.478936 UTC] Computing logging information
-------------------------------------
| Iteration            | 105        |
| ExpectedImprovement  | 0.019249   |
| ActualImprovement    | 0.018244   |
| ImprovementRatio     | 0.94781    |
| MeanKL               | 0.0066002  |
| Entropy              | 2.208      |
| Perplexity           | 9.0975     |
| AveragePolicyStd     | 0.35112    |
| AveragePolicyStd[0]  | 0.39504    |
| AveragePolicyStd[1]  | 0.3905     |
| AveragePolicyStd[2]  | 0.3468     |
| AveragePolicyStd[3]  | 0.30582    |
| AveragePolicyStd[4]  | 0.3228     |
| AveragePolicyStd[5]  | 0.34574    |
| AverageReturn        | 174.57     |
| MinReturn            | 9.6583     |
| MaxReturn            | 558.54     |
| StdReturn            | 84.486     |
| AverageEpisodeLength | 256.74     |
| MinEpisodeLength     | 20         |
| MaxEpisodeLength     | 1000       |
| StdEpisodeLength     | 155.53     |
| TotalNEpisodes       | 15348      |
| TotalNSamples        | 5.2742e+05 |
| ExplainedVariance    | 0.82488    |
-------------------------------------
[2019-11-19 11:39:29.437065 UTC] Saving snapshot
[2019-11-19 11:39:29.437865 UTC] Starting iteration 106
[2019-11-19 11:39:29.438524 UTC] Start collecting samples
[2019-11-19 11:39:31.171695 UTC] Computing input variables for policy optimization
[2019-11-19 11:39:31.225811 UTC] Performing policy update
[2019-11-19 11:39:31.227103 UTC] Computing gradient in Euclidean space
[2019-11-19 11:39:31.278712 UTC] Computing approximate natural gradient using conjugate gradient algorithm
[2019-11-19 11:39:31.847341 UTC] Performing line search
[2019-11-19 11:39:31.932400 UTC] Updating baseline
[2019-11-19 11:39:32.697512 UTC] Computing logging information
------------------------------------
| Iteration            | 106       |
| ExpectedImprovement  | 0.021094  |
| ActualImprovement    | 0.018539  |
| ImprovementRatio     | 0.87887   |
| MeanKL               | 0.00649   |
| Entropy              | 2.1964    |
| Perplexity           | 8.9928    |
| AveragePolicyStd     | 0.35058   |
| AveragePolicyStd[0]  | 0.3941    |
| AveragePolicyStd[1]  | 0.39223   |
| AveragePolicyStd[2]  | 0.34645   |
| AveragePolicyStd[3]  | 0.30078   |
| AveragePolicyStd[4]  | 0.32331   |
| AveragePolicyStd[5]  | 0.34659   |
| AverageReturn        | 174.36    |
| MinReturn            | 9.6583    |
| MaxReturn            | 558.54    |
| StdReturn            | 86.315    |
| AverageEpisodeLength | 254.72    |
| MinEpisodeLength     | 20        |
| MaxEpisodeLength     | 1000      |
| StdEpisodeLength     | 155.16    |
| TotalNEpisodes       | 15365     |
| TotalNSamples        | 5.317e+05 |
| ExplainedVariance    | 0.78254   |
------------------------------------
[2019-11-19 11:39:33.634118 UTC] Saving snapshot
[2019-11-19 11:39:33.635313 UTC] Starting iteration 107
[2019-11-19 11:39:33.636311 UTC] Start collecting samples
[2019-11-19 11:39:35.304441 UTC] Computing input variables for policy optimization
[2019-11-19 11:39:35.356656 UTC] Performing policy update
[2019-11-19 11:39:35.357799 UTC] Computing gradient in Euclidean space
[2019-11-19 11:39:35.409459 UTC] Computing approximate natural gradient using conjugate gradient algorithm
[2019-11-19 11:39:35.991182 UTC] Performing line search
[2019-11-19 11:39:36.070526 UTC] Updating baseline
[2019-11-19 11:39:36.935656 UTC] Computing logging information
-------------------------------------
| Iteration            | 107        |
| ExpectedImprovement  | 0.021137   |
| ActualImprovement    | 0.021525   |
| ImprovementRatio     | 1.0183     |
| MeanKL               | 0.0068159  |
| Entropy              | 2.1527     |
| Perplexity           | 8.6078     |
| AveragePolicyStd     | 0.34803    |
| AveragePolicyStd[0]  | 0.39257    |
| AveragePolicyStd[1]  | 0.38806    |
| AveragePolicyStd[2]  | 0.34371    |
| AveragePolicyStd[3]  | 0.29927    |
| AveragePolicyStd[4]  | 0.31942    |
| AveragePolicyStd[5]  | 0.34516    |
| AverageReturn        | 176.56     |
| MinReturn            | 9.6583     |
| MaxReturn            | 558.54     |
| StdReturn            | 85.551     |
| AverageEpisodeLength | 256.27     |
| MinEpisodeLength     | 20         |
| MaxEpisodeLength     | 1000       |
| StdEpisodeLength     | 152.81     |
| TotalNEpisodes       | 15375      |
| TotalNSamples        | 5.3413e+05 |
| ExplainedVariance    | 0.94797    |
-------------------------------------
[2019-11-19 11:39:37.992181 UTC] Saving snapshot
[2019-11-19 11:39:37.993178 UTC] Starting iteration 108
[2019-11-19 11:39:37.994030 UTC] Start collecting samples
[2019-11-19 11:39:39.819058 UTC] Computing input variables for policy optimization
[2019-11-19 11:39:39.875796 UTC] Performing policy update
[2019-11-19 11:39:39.876959 UTC] Computing gradient in Euclidean space
[2019-11-19 11:39:39.930694 UTC] Computing approximate natural gradient using conjugate gradient algorithm
[2019-11-19 11:39:40.644145 UTC] Performing line search
[2019-11-19 11:39:40.741836 UTC] Updating baseline
[2019-11-19 11:39:41.625508 UTC] Computing logging information
-------------------------------------
| Iteration            | 108        |
| ExpectedImprovement  | 0.011449   |
| ActualImprovement    | 0.011415   |
| ImprovementRatio     | 0.99701    |
| MeanKL               | 0.0077281  |
| Entropy              | 2.1243     |
| Perplexity           | 8.3669     |
| AveragePolicyStd     | 0.34635    |
| AveragePolicyStd[0]  | 0.38972    |
| AveragePolicyStd[1]  | 0.38591    |
| AveragePolicyStd[2]  | 0.33989    |
| AveragePolicyStd[3]  | 0.29876    |
| AveragePolicyStd[4]  | 0.31794    |
| AveragePolicyStd[5]  | 0.34587    |
| AverageReturn        | 191.75     |
| MinReturn            | 9.6583     |
| MaxReturn            | 611.48     |
| StdReturn            | 117.45     |
| AverageEpisodeLength | 281.91     |
| MinEpisodeLength     | 20         |
| MaxEpisodeLength     | 1000       |
| StdEpisodeLength     | 208.44     |
| TotalNEpisodes       | 15389      |
| TotalNSamples        | 5.4043e+05 |
| ExplainedVariance    | 0.59294    |
-------------------------------------
[2019-11-19 11:39:42.888509 UTC] Saving snapshot
[2019-11-19 11:39:42.889198 UTC] Starting iteration 109
[2019-11-19 11:39:42.890135 UTC] Start collecting samples
[2019-11-19 11:39:44.840270 UTC] Computing input variables for policy optimization
[2019-11-19 11:39:44.892578 UTC] Performing policy update
[2019-11-19 11:39:44.893668 UTC] Computing gradient in Euclidean space
[2019-11-19 11:39:44.944512 UTC] Computing approximate natural gradient using conjugate gradient algorithm
[2019-11-19 11:39:45.533257 UTC] Performing line search
[2019-11-19 11:39:45.613760 UTC] Updating baseline
[2019-11-19 11:39:46.403939 UTC] Computing logging information
-------------------------------------
| Iteration            | 109        |
| ExpectedImprovement  | 0.019902   |
| ActualImprovement    | 0.018681   |
| ImprovementRatio     | 0.93867    |
| MeanKL               | 0.0066689  |
| Entropy              | 2.122      |
| Perplexity           | 8.3481     |
| AveragePolicyStd     | 0.3463     |
| AveragePolicyStd[0]  | 0.3928     |
| AveragePolicyStd[1]  | 0.38554    |
| AveragePolicyStd[2]  | 0.34049    |
| AveragePolicyStd[3]  | 0.29699    |
| AveragePolicyStd[4]  | 0.31884    |
| AveragePolicyStd[5]  | 0.34316    |
| AverageReturn        | 206.08     |
| MinReturn            | 9.6583     |
| MaxReturn            | 620.91     |
| StdReturn            | 140.62     |
| AverageEpisodeLength | 305.99     |
| MinEpisodeLength     | 20         |
| MaxEpisodeLength     | 1000       |
| StdEpisodeLength     | 246.43     |
| TotalNEpisodes       | 15407      |
| TotalNSamples        | 5.4695e+05 |
| ExplainedVariance    | 0.53597    |
-------------------------------------
[2019-11-19 11:39:47.328058 UTC] Saving snapshot
[2019-11-19 11:39:47.329128 UTC] Starting iteration 110
[2019-11-19 11:39:47.329842 UTC] Start collecting samples
[2019-11-19 11:39:49.123756 UTC] Computing input variables for policy optimization
[2019-11-19 11:39:49.180659 UTC] Performing policy update
[2019-11-19 11:39:49.182116 UTC] Computing gradient in Euclidean space
[2019-11-19 11:39:49.234984 UTC] Computing approximate natural gradient using conjugate gradient algorithm
[2019-11-19 11:39:49.853099 UTC] Performing line search
[2019-11-19 11:39:49.939630 UTC] Updating baseline
[2019-11-19 11:39:50.750695 UTC] Computing logging information
-------------------------------------
| Iteration            | 110        |
| ExpectedImprovement  | 0.021461   |
| ActualImprovement    | 0.022748   |
| ImprovementRatio     | 1.0599     |
| MeanKL               | 0.0066512  |
| Entropy              | 2.1208     |
| Perplexity           | 8.3377     |
| AveragePolicyStd     | 0.3463     |
| AveragePolicyStd[0]  | 0.39284    |
| AveragePolicyStd[1]  | 0.38582    |
| AveragePolicyStd[2]  | 0.34089    |
| AveragePolicyStd[3]  | 0.29517    |
| AveragePolicyStd[4]  | 0.31781    |
| AveragePolicyStd[5]  | 0.34527    |
| AverageReturn        | 208.83     |
| MinReturn            | 9.6583     |
| MaxReturn            | 620.91     |
| StdReturn            | 142.37     |
| AverageEpisodeLength | 309.33     |
| MinEpisodeLength     | 20         |
| MaxEpisodeLength     | 1000       |
| StdEpisodeLength     | 248.63     |
| TotalNEpisodes       | 15421      |
| TotalNSamples        | 5.5102e+05 |
| ExplainedVariance    | 0.8765     |
-------------------------------------
[2019-11-19 11:39:51.784561 UTC] Saving snapshot
[2019-11-19 11:39:51.798858 UTC] Starting iteration 111
[2019-11-19 11:39:51.799604 UTC] Start collecting samples
[2019-11-19 11:39:53.643278 UTC] Computing input variables for policy optimization
[2019-11-19 11:39:53.708610 UTC] Performing policy update
[2019-11-19 11:39:53.709929 UTC] Computing gradient in Euclidean space
[2019-11-19 11:39:53.762726 UTC] Computing approximate natural gradient using conjugate gradient algorithm
[2019-11-19 11:39:54.320769 UTC] Performing line search
[2019-11-19 11:39:54.398549 UTC] Updating baseline
[2019-11-19 11:39:55.149287 UTC] Computing logging information
-------------------------------------
| Iteration            | 111        |
| ExpectedImprovement  | 0.011307   |
| ActualImprovement    | 0.011082   |
| ImprovementRatio     | 0.98008    |
| MeanKL               | 0.0072602  |
| Entropy              | 2.1048     |
| Perplexity           | 8.2055     |
| AveragePolicyStd     | 0.3453     |
| AveragePolicyStd[0]  | 0.3901     |
| AveragePolicyStd[1]  | 0.38232    |
| AveragePolicyStd[2]  | 0.34066    |
| AveragePolicyStd[3]  | 0.29481    |
| AveragePolicyStd[4]  | 0.31651    |
| AveragePolicyStd[5]  | 0.34741    |
| AverageReturn        | 225.81     |
| MinReturn            | 37.55      |
| MaxReturn            | 641.24     |
| StdReturn            | 157.2      |
| AverageEpisodeLength | 337.1      |
| MinEpisodeLength     | 67         |
| MaxEpisodeLength     | 1000       |
| StdEpisodeLength     | 272.08     |
| TotalNEpisodes       | 15431      |
| TotalNSamples        | 5.5605e+05 |
| ExplainedVariance    | 0.53814    |
-------------------------------------
[2019-11-19 11:39:56.348599 UTC] Saving snapshot
[2019-11-19 11:39:56.349580 UTC] Starting iteration 112
[2019-11-19 11:39:56.351099 UTC] Start collecting samples
[2019-11-19 11:39:58.005904 UTC] Computing input variables for policy optimization
[2019-11-19 11:39:58.057218 UTC] Performing policy update
[2019-11-19 11:39:58.058450 UTC] Computing gradient in Euclidean space
[2019-11-19 11:39:58.110809 UTC] Computing approximate natural gradient using conjugate gradient algorithm
[2019-11-19 11:39:58.680276 UTC] Performing line search
[2019-11-19 11:39:58.755724 UTC] Updating baseline
[2019-11-19 11:39:59.493242 UTC] Computing logging information
-------------------------------------
| Iteration            | 112        |
| ExpectedImprovement  | 0.02021    |
| ActualImprovement    | 0.01729    |
| ImprovementRatio     | 0.85553    |
| MeanKL               | 0.0067358  |
| Entropy              | 2.1148     |
| Perplexity           | 8.2878     |
| AveragePolicyStd     | 0.34572    |
| AveragePolicyStd[0]  | 0.39298    |
| AveragePolicyStd[1]  | 0.37781    |
| AveragePolicyStd[2]  | 0.33855    |
| AveragePolicyStd[3]  | 0.29976    |
| AveragePolicyStd[4]  | 0.31728    |
| AveragePolicyStd[5]  | 0.34795    |
| AverageReturn        | 231        |
| MinReturn            | 37.55      |
| MaxReturn            | 641.24     |
| StdReturn            | 159.17     |
| AverageEpisodeLength | 343.56     |
| MinEpisodeLength     | 67         |
| MaxEpisodeLength     | 1000       |
| StdEpisodeLength     | 272.66     |
| TotalNEpisodes       | 15442      |
| TotalNSamples        | 5.6013e+05 |
| ExplainedVariance    | 0.68877    |
-------------------------------------
[2019-11-19 11:40:00.535375 UTC] Saving snapshot
[2019-11-19 11:40:00.535978 UTC] Starting iteration 113
[2019-11-19 11:40:00.536814 UTC] Start collecting samples
[2019-11-19 11:40:02.113227 UTC] Computing input variables for policy optimization
[2019-11-19 11:40:02.164380 UTC] Performing policy update
[2019-11-19 11:40:02.165557 UTC] Computing gradient in Euclidean space
[2019-11-19 11:40:02.214704 UTC] Computing approximate natural gradient using conjugate gradient algorithm
[2019-11-19 11:40:02.778055 UTC] Performing line search
[2019-11-19 11:40:02.851357 UTC] Updating baseline
[2019-11-19 11:40:03.565476 UTC] Computing logging information
-------------------------------------
| Iteration            | 113        |
| ExpectedImprovement  | 0.012966   |
| ActualImprovement    | 0.01204    |
| ImprovementRatio     | 0.92862    |
| MeanKL               | 0.0075575  |
| Entropy              | 2.1052     |
| Perplexity           | 8.2086     |
| AveragePolicyStd     | 0.34512    |
| AveragePolicyStd[0]  | 0.3901     |
| AveragePolicyStd[1]  | 0.37986    |
| AveragePolicyStd[2]  | 0.33603    |
| AveragePolicyStd[3]  | 0.29997    |
| AveragePolicyStd[4]  | 0.31924    |
| AveragePolicyStd[5]  | 0.34553    |
| AverageReturn        | 244.63     |
| MinReturn            | 37.55      |
| MaxReturn            | 641.24     |
| StdReturn            | 172.34     |
| AverageEpisodeLength | 364.96     |
| MinEpisodeLength     | 67         |
| MaxEpisodeLength     | 1000       |
| StdEpisodeLength     | 293.23     |
| TotalNEpisodes       | 15450      |
| TotalNSamples        | 5.6422e+05 |
| ExplainedVariance    | 0.63758    |
-------------------------------------
[2019-11-19 11:40:04.575838 UTC] Saving snapshot
[2019-11-19 11:40:04.576708 UTC] Starting iteration 114
[2019-11-19 11:40:04.577648 UTC] Start collecting samples
[2019-11-19 11:40:06.593485 UTC] Computing input variables for policy optimization
[2019-11-19 11:40:06.656487 UTC] Performing policy update
[2019-11-19 11:40:06.658550 UTC] Computing gradient in Euclidean space
[2019-11-19 11:40:06.711311 UTC] Computing approximate natural gradient using conjugate gradient algorithm
[2019-11-19 11:40:07.328972 UTC] Performing line search
[2019-11-19 11:40:07.404705 UTC] Updating baseline
[2019-11-19 11:40:08.125983 UTC] Computing logging information
-------------------------------------
| Iteration            | 114        |
| ExpectedImprovement  | 0.016042   |
| ActualImprovement    | 0.015211   |
| ImprovementRatio     | 0.94821    |
| MeanKL               | 0.0066574  |
| Entropy              | 2.106      |
| Perplexity           | 8.2152     |
| AveragePolicyStd     | 0.34519    |
| AveragePolicyStd[0]  | 0.38851    |
| AveragePolicyStd[1]  | 0.38193    |
| AveragePolicyStd[2]  | 0.33545    |
| AveragePolicyStd[3]  | 0.29927    |
| AveragePolicyStd[4]  | 0.31912    |
| AveragePolicyStd[5]  | 0.34687    |
| AverageReturn        | 259.9      |
| MinReturn            | 37.55      |
| MaxReturn            | 641.24     |
| StdReturn            | 185.09     |
| AverageEpisodeLength | 389.55     |
| MinEpisodeLength     | 65         |
| MaxEpisodeLength     | 1000       |
| StdEpisodeLength     | 313.29     |
| TotalNEpisodes       | 15465      |
| TotalNSamples        | 5.7066e+05 |
| ExplainedVariance    | 0.50234    |
-------------------------------------
[2019-11-19 11:40:09.139159 UTC] Saving snapshot
[2019-11-19 11:40:09.140596 UTC] Starting iteration 115
[2019-11-19 11:40:09.141742 UTC] Start collecting samples
[2019-11-19 11:40:11.201393 UTC] Computing input variables for policy optimization
[2019-11-19 11:40:11.257525 UTC] Performing policy update
[2019-11-19 11:40:11.258587 UTC] Computing gradient in Euclidean space
[2019-11-19 11:40:11.306706 UTC] Computing approximate natural gradient using conjugate gradient algorithm
[2019-11-19 11:40:11.875347 UTC] Performing line search
[2019-11-19 11:40:11.949132 UTC] Updating baseline
[2019-11-19 11:40:12.664866 UTC] Computing logging information
-------------------------------------
| Iteration            | 115        |
| ExpectedImprovement  | 0.014098   |
| ActualImprovement    | 0.012983   |
| ImprovementRatio     | 0.92096    |
| MeanKL               | 0.0072111  |
| Entropy              | 2.0962     |
| Perplexity           | 8.1355     |
| AveragePolicyStd     | 0.34462    |
| AveragePolicyStd[0]  | 0.38791    |
| AveragePolicyStd[1]  | 0.38017    |
| AveragePolicyStd[2]  | 0.33316    |
| AveragePolicyStd[3]  | 0.29944    |
| AveragePolicyStd[4]  | 0.31815    |
| AveragePolicyStd[5]  | 0.34886    |
| AverageReturn        | 269.53     |
| MinReturn            | 37.55      |
| MaxReturn            | 651.04     |
| StdReturn            | 191.92     |
| AverageEpisodeLength | 405.17     |
| MinEpisodeLength     | 65         |
| MaxEpisodeLength     | 1000       |
| StdEpisodeLength     | 322.77     |
| TotalNEpisodes       | 15479      |
| TotalNSamples        | 5.7623e+05 |
| ExplainedVariance    | 0.67797    |
-------------------------------------
[2019-11-19 11:40:13.719961 UTC] Saving snapshot
[2019-11-19 11:40:13.721110 UTC] Starting iteration 116
[2019-11-19 11:40:13.722080 UTC] Start collecting samples
[2019-11-19 11:40:15.307757 UTC] Computing input variables for policy optimization
[2019-11-19 11:40:15.358998 UTC] Performing policy update
[2019-11-19 11:40:15.360309 UTC] Computing gradient in Euclidean space
[2019-11-19 11:40:15.412340 UTC] Computing approximate natural gradient using conjugate gradient algorithm
[2019-11-19 11:40:16.029046 UTC] Performing line search
[2019-11-19 11:40:16.107077 UTC] Updating baseline
[2019-11-19 11:40:16.943982 UTC] Computing logging information
-------------------------------------
| Iteration            | 116        |
| ExpectedImprovement  | 0.011279   |
| ActualImprovement    | 0.010843   |
| ImprovementRatio     | 0.96134    |
| MeanKL               | 0.007388   |
| Entropy              | 2.0571     |
| Perplexity           | 7.823      |
| AveragePolicyStd     | 0.34234    |
| AveragePolicyStd[0]  | 0.38686    |
| AveragePolicyStd[1]  | 0.37487    |
| AveragePolicyStd[2]  | 0.32718    |
| AveragePolicyStd[3]  | 0.29789    |
| AveragePolicyStd[4]  | 0.3187     |
| AveragePolicyStd[5]  | 0.34857    |
| AverageReturn        | 264.96     |
| MinReturn            | 37.55      |
| MaxReturn            | 661.89     |
| StdReturn            | 192.18     |
| AverageEpisodeLength | 395.18     |
| MinEpisodeLength     | 65         |
| MaxEpisodeLength     | 1000       |
| StdEpisodeLength     | 318.33     |
| TotalNEpisodes       | 15487      |
| TotalNSamples        | 5.7958e+05 |
| ExplainedVariance    | 0.65914    |
-------------------------------------
[2019-11-19 11:40:18.002144 UTC] Saving snapshot
[2019-11-19 11:40:18.003171 UTC] Starting iteration 117
[2019-11-19 11:40:18.003893 UTC] Start collecting samples
[2019-11-19 11:40:19.425808 UTC] Computing input variables for policy optimization
[2019-11-19 11:40:19.472633 UTC] Performing policy update
[2019-11-19 11:40:19.473957 UTC] Computing gradient in Euclidean space
[2019-11-19 11:40:19.525356 UTC] Computing approximate natural gradient using conjugate gradient algorithm
[2019-11-19 11:40:20.094690 UTC] Performing line search
[2019-11-19 11:40:20.171074 UTC] Updating baseline
[2019-11-19 11:40:20.974887 UTC] Computing logging information
-------------------------------------
| Iteration            | 117        |
| ExpectedImprovement  | 0.012493   |
| ActualImprovement    | 0.011676   |
| ImprovementRatio     | 0.93463    |
| MeanKL               | 0.0070878  |
| Entropy              | 2.0497     |
| Perplexity           | 7.7652     |
| AveragePolicyStd     | 0.34196    |
| AveragePolicyStd[0]  | 0.38483    |
| AveragePolicyStd[1]  | 0.37795    |
| AveragePolicyStd[2]  | 0.32614    |
| AveragePolicyStd[3]  | 0.29737    |
| AveragePolicyStd[4]  | 0.31778    |
| AveragePolicyStd[5]  | 0.34769    |
| AverageReturn        | 269.82     |
| MinReturn            | 37.55      |
| MaxReturn            | 661.89     |
| StdReturn            | 195.79     |
| AverageEpisodeLength | 402.88     |
| MinEpisodeLength     | 65         |
| MaxEpisodeLength     | 1000       |
| StdEpisodeLength     | 323.51     |
| TotalNEpisodes       | 15488      |
| TotalNSamples        | 5.8058e+05 |
| ExplainedVariance    | 0.054049   |
-------------------------------------
[2019-11-19 11:40:21.992741 UTC] Saving snapshot
[2019-11-19 11:40:21.995097 UTC] Starting iteration 118
[2019-11-19 11:40:21.996025 UTC] Start collecting samples
[2019-11-19 11:40:23.706735 UTC] Computing input variables for policy optimization
[2019-11-19 11:40:23.764823 UTC] Performing policy update
[2019-11-19 11:40:23.766031 UTC] Computing gradient in Euclidean space
[2019-11-19 11:40:23.822383 UTC] Computing approximate natural gradient using conjugate gradient algorithm
[2019-11-19 11:40:24.435085 UTC] Performing line search
[2019-11-19 11:40:24.519701 UTC] Updating baseline
[2019-11-19 11:40:25.257713 UTC] Computing logging information
-------------------------------------
| Iteration            | 118        |
| ExpectedImprovement  | 0.013053   |
| ActualImprovement    | 0.012565   |
| ImprovementRatio     | 0.96262    |
| MeanKL               | 0.0068465  |
| Entropy              | 2.0279     |
| Perplexity           | 7.5981     |
| AveragePolicyStd     | 0.34081    |
| AveragePolicyStd[0]  | 0.38072    |
| AveragePolicyStd[1]  | 0.38161    |
| AveragePolicyStd[2]  | 0.32356    |
| AveragePolicyStd[3]  | 0.29676    |
| AveragePolicyStd[4]  | 0.3132     |
| AveragePolicyStd[5]  | 0.34903    |
| AverageReturn        | 295.93     |
| MinReturn            | 37.55      |
| MaxReturn            | 665.49     |
| StdReturn            | 209.69     |
| AverageEpisodeLength | 442.2      |
| MinEpisodeLength     | 65         |
| MaxEpisodeLength     | 1000       |
| StdEpisodeLength     | 339.79     |
| TotalNEpisodes       | 15499      |
| TotalNSamples        | 5.8956e+05 |
| ExplainedVariance    | 0.2281     |
-------------------------------------
[2019-11-19 11:40:26.285569 UTC] Saving snapshot
[2019-11-19 11:40:26.286345 UTC] Starting iteration 119
[2019-11-19 11:40:26.287351 UTC] Start collecting samples
[2019-11-19 11:40:27.934189 UTC] Computing input variables for policy optimization
[2019-11-19 11:40:27.988702 UTC] Performing policy update
[2019-11-19 11:40:27.989963 UTC] Computing gradient in Euclidean space
[2019-11-19 11:40:28.042794 UTC] Computing approximate natural gradient using conjugate gradient algorithm
[2019-11-19 11:40:28.613857 UTC] Performing line search
[2019-11-19 11:40:28.693136 UTC] Updating baseline
[2019-11-19 11:40:29.449913 UTC] Computing logging information
-------------------------------------
| Iteration            | 119        |
| ExpectedImprovement  | 0.017879   |
| ActualImprovement    | 0.016591   |
| ImprovementRatio     | 0.92796    |
| MeanKL               | 0.0067263  |
| Entropy              | 2.0151     |
| Perplexity           | 7.5015     |
| AveragePolicyStd     | 0.34008    |
| AveragePolicyStd[0]  | 0.38246    |
| AveragePolicyStd[1]  | 0.37776    |
| AveragePolicyStd[2]  | 0.32296    |
| AveragePolicyStd[3]  | 0.29475    |
| AveragePolicyStd[4]  | 0.31477    |
| AveragePolicyStd[5]  | 0.34781    |
| AverageReturn        | 320.54     |
| MinReturn            | 14.42      |
| MaxReturn            | 666.4      |
| StdReturn            | 221.95     |
| AverageEpisodeLength | 480.62     |
| MinEpisodeLength     | 30         |
| MaxEpisodeLength     | 1000       |
| StdEpisodeLength     | 357.03     |
| TotalNEpisodes       | 15515      |
| TotalNSamples        | 5.9772e+05 |
| ExplainedVariance    | 0.47602    |
-------------------------------------
[2019-11-19 11:40:30.504934 UTC] Saving snapshot
[2019-11-19 11:40:30.506179 UTC] Starting iteration 120
[2019-11-19 11:40:30.507509 UTC] Start collecting samples
[2019-11-19 11:40:32.263269 UTC] Computing input variables for policy optimization
[2019-11-19 11:40:32.317185 UTC] Performing policy update
[2019-11-19 11:40:32.318737 UTC] Computing gradient in Euclidean space
[2019-11-19 11:40:32.368882 UTC] Computing approximate natural gradient using conjugate gradient algorithm
[2019-11-19 11:40:32.946582 UTC] Performing line search
[2019-11-19 11:40:33.022273 UTC] Updating baseline
[2019-11-19 11:40:33.766190 UTC] Computing logging information
-------------------------------------
| Iteration            | 120        |
| ExpectedImprovement  | 0.018399   |
| ActualImprovement    | 0.018399   |
| ImprovementRatio     | 1          |
| MeanKL               | 0.0067997  |
| Entropy              | 1.9792     |
| Perplexity           | 7.237      |
| AveragePolicyStd     | 0.3381     |
| AveragePolicyStd[0]  | 0.37943    |
| AveragePolicyStd[1]  | 0.37566    |
| AveragePolicyStd[2]  | 0.32017    |
| AveragePolicyStd[3]  | 0.29042    |
| AveragePolicyStd[4]  | 0.31488    |
| AveragePolicyStd[5]  | 0.34806    |
| AverageReturn        | 303.91     |
| MinReturn            | 14.42      |
| MaxReturn            | 666.4      |
| StdReturn            | 218.3      |
| AverageEpisodeLength | 453.07     |
| MinEpisodeLength     | 30         |
| MaxEpisodeLength     | 1000       |
| StdEpisodeLength     | 349.9      |
| TotalNEpisodes       | 15530      |
| TotalNSamples        | 6.0112e+05 |
| ExplainedVariance    | 0.84753    |
-------------------------------------
[2019-11-19 11:40:34.935192 UTC] Saving snapshot
[2019-11-19 11:40:34.950163 UTC] Starting iteration 121
[2019-11-19 11:40:34.950866 UTC] Start collecting samples
[2019-11-19 11:40:36.756167 UTC] Computing input variables for policy optimization
[2019-11-19 11:40:36.812603 UTC] Performing policy update
[2019-11-19 11:40:36.813829 UTC] Computing gradient in Euclidean space
[2019-11-19 11:40:36.866810 UTC] Computing approximate natural gradient using conjugate gradient algorithm
[2019-11-19 11:40:37.476542 UTC] Performing line search
[2019-11-19 11:40:37.563570 UTC] Updating baseline
[2019-11-19 11:40:38.422004 UTC] Computing logging information
-------------------------------------
| Iteration            | 121        |
| ExpectedImprovement  | 0.014683   |
| ActualImprovement    | 0.013781   |
| ImprovementRatio     | 0.93856    |
| MeanKL               | 0.0067504  |
| Entropy              | 1.9505     |
| Perplexity           | 7.0323     |
| AveragePolicyStd     | 0.33656    |
| AveragePolicyStd[0]  | 0.37882    |
| AveragePolicyStd[1]  | 0.37228    |
| AveragePolicyStd[2]  | 0.31495    |
| AveragePolicyStd[3]  | 0.28733    |
| AveragePolicyStd[4]  | 0.31632    |
| AveragePolicyStd[5]  | 0.34964    |
| AverageReturn        | 306.81     |
| MinReturn            | 14.42      |
| MaxReturn            | 683.6      |
| StdReturn            | 221.82     |
| AverageEpisodeLength | 456.26     |
| MinEpisodeLength     | 30         |
| MaxEpisodeLength     | 1000       |
| StdEpisodeLength     | 352.86     |
| TotalNEpisodes       | 15544      |
| TotalNSamples        | 6.0689e+05 |
| ExplainedVariance    | 0.71941    |
-------------------------------------
[2019-11-19 11:40:39.333658 UTC] Saving snapshot
[2019-11-19 11:40:39.335062 UTC] Starting iteration 122
[2019-11-19 11:40:39.336205 UTC] Start collecting samples
[2019-11-19 11:40:40.956465 UTC] Computing input variables for policy optimization
[2019-11-19 11:40:41.011032 UTC] Performing policy update
[2019-11-19 11:40:41.012453 UTC] Computing gradient in Euclidean space
[2019-11-19 11:40:41.068288 UTC] Computing approximate natural gradient using conjugate gradient algorithm
[2019-11-19 11:40:41.729891 UTC] Performing line search
[2019-11-19 11:40:41.817416 UTC] Updating baseline
[2019-11-19 11:40:42.550317 UTC] Computing logging information
-------------------------------------
| Iteration            | 122        |
| ExpectedImprovement  | 0.013306   |
| ActualImprovement    | 0.012718   |
| ImprovementRatio     | 0.95579    |
| MeanKL               | 0.0071434  |
| Entropy              | 1.9225     |
| Perplexity           | 6.8377     |
| AveragePolicyStd     | 0.33508    |
| AveragePolicyStd[0]  | 0.37845    |
| AveragePolicyStd[1]  | 0.37255    |
| AveragePolicyStd[2]  | 0.31239    |
| AveragePolicyStd[3]  | 0.28568    |
| AveragePolicyStd[4]  | 0.31369    |
| AveragePolicyStd[5]  | 0.34771    |
| AverageReturn        | 306.81     |
| MinReturn            | 14.42      |
| MaxReturn            | 683.6      |
| StdReturn            | 223.42     |
| AverageEpisodeLength | 455.65     |
| MinEpisodeLength     | 30         |
| MaxEpisodeLength     | 1000       |
| StdEpisodeLength     | 353.59     |
| TotalNEpisodes       | 15554      |
| TotalNSamples        | 6.1081e+05 |
| ExplainedVariance    | 0.6021     |
-------------------------------------
[2019-11-19 11:40:43.435238 UTC] Saving snapshot
[2019-11-19 11:40:43.436397 UTC] Starting iteration 123
[2019-11-19 11:40:43.437384 UTC] Start collecting samples
[2019-11-19 11:40:45.354577 UTC] Computing input variables for policy optimization
[2019-11-19 11:40:45.409040 UTC] Performing policy update
[2019-11-19 11:40:45.410184 UTC] Computing gradient in Euclidean space
[2019-11-19 11:40:45.462932 UTC] Computing approximate natural gradient using conjugate gradient algorithm
[2019-11-19 11:40:46.064095 UTC] Performing line search
[2019-11-19 11:40:46.139541 UTC] Updating baseline
[2019-11-19 11:40:46.903240 UTC] Computing logging information
------------------------------------
| Iteration            | 123       |
| ExpectedImprovement  | 0.013784  |
| ActualImprovement    | 0.013247  |
| ImprovementRatio     | 0.96106   |
| MeanKL               | 0.0072867 |
| Entropy              | 1.9288    |
| Perplexity           | 6.881     |
| AveragePolicyStd     | 0.33549   |
| AveragePolicyStd[0]  | 0.37986   |
| AveragePolicyStd[1]  | 0.37765   |
| AveragePolicyStd[2]  | 0.3116    |
| AveragePolicyStd[3]  | 0.28604   |
| AveragePolicyStd[4]  | 0.31634   |
| AveragePolicyStd[5]  | 0.34146   |
| AverageReturn        | 295.95    |
| MinReturn            | 14.42     |
| MaxReturn            | 683.6     |
| StdReturn            | 215.96    |
| AverageEpisodeLength | 436.45    |
| MinEpisodeLength     | 30        |
| MaxEpisodeLength     | 1000      |
| StdEpisodeLength     | 339.73    |
| TotalNEpisodes       | 15566     |
| TotalNSamples        | 6.146e+05 |
| ExplainedVariance    | 0.86322   |
------------------------------------
[2019-11-19 11:40:48.271269 UTC] Saving snapshot
[2019-11-19 11:40:48.272153 UTC] Starting iteration 124
[2019-11-19 11:40:48.272933 UTC] Start collecting samples
[2019-11-19 11:40:51.209882 UTC] Computing input variables for policy optimization
[2019-11-19 11:40:51.262054 UTC] Performing policy update
[2019-11-19 11:40:51.263438 UTC] Computing gradient in Euclidean space
[2019-11-19 11:40:51.316374 UTC] Computing approximate natural gradient using conjugate gradient algorithm
[2019-11-19 11:40:51.958385 UTC] Performing line search
[2019-11-19 11:40:52.046758 UTC] Updating baseline
[2019-11-19 11:40:52.889638 UTC] Computing logging information
-------------------------------------
| Iteration            | 124        |
| ExpectedImprovement  | 0.017224   |
| ActualImprovement    | 0.015772   |
| ImprovementRatio     | 0.91572    |
| MeanKL               | 0.0071144  |
| Entropy              | 1.9127     |
| Perplexity           | 6.7712     |
| AveragePolicyStd     | 0.33478    |
| AveragePolicyStd[0]  | 0.38106    |
| AveragePolicyStd[1]  | 0.37724    |
| AveragePolicyStd[2]  | 0.30851    |
| AveragePolicyStd[3]  | 0.28382    |
| AveragePolicyStd[4]  | 0.31223    |
| AveragePolicyStd[5]  | 0.34583    |
| AverageReturn        | 297.57     |
| MinReturn            | 14.42      |
| MaxReturn            | 683.6      |
| StdReturn            | 216.64     |
| AverageEpisodeLength | 437.72     |
| MinEpisodeLength     | 30         |
| MaxEpisodeLength     | 1000       |
| StdEpisodeLength     | 338.96     |
| TotalNEpisodes       | 15572      |
| TotalNSamples        | 6.1759e+05 |
| ExplainedVariance    | 0.66077    |
-------------------------------------
[2019-11-19 11:40:54.081051 UTC] Saving snapshot
[2019-11-19 11:40:54.082269 UTC] Starting iteration 125
[2019-11-19 11:40:54.083702 UTC] Start collecting samples
[2019-11-19 11:40:55.862373 UTC] Computing input variables for policy optimization
[2019-11-19 11:40:55.917570 UTC] Performing policy update
[2019-11-19 11:40:55.918803 UTC] Computing gradient in Euclidean space
[2019-11-19 11:40:55.975956 UTC] Computing approximate natural gradient using conjugate gradient algorithm
[2019-11-19 11:40:56.690282 UTC] Performing line search
[2019-11-19 11:40:56.838124 UTC] Updating baseline
[2019-11-19 11:40:57.736847 UTC] Computing logging information
-------------------------------------
| Iteration            | 125        |
| ExpectedImprovement  | 0.014566   |
| ActualImprovement    | 0.013884   |
| ImprovementRatio     | 0.95319    |
| MeanKL               | 0.0070603  |
| Entropy              | 1.8983     |
| Perplexity           | 6.6743     |
| AveragePolicyStd     | 0.33402    |
| AveragePolicyStd[0]  | 0.38134    |
| AveragePolicyStd[1]  | 0.37605    |
| AveragePolicyStd[2]  | 0.30635    |
| AveragePolicyStd[3]  | 0.28386    |
| AveragePolicyStd[4]  | 0.31025    |
| AveragePolicyStd[5]  | 0.34625    |
| AverageReturn        | 316.18     |
| MinReturn            | 14.42      |
| MaxReturn            | 683.6      |
| StdReturn            | 223.28     |
| AverageEpisodeLength | 466.95     |
| MinEpisodeLength     | 30         |
| MaxEpisodeLength     | 1000       |
| StdEpisodeLength     | 348.59     |
| TotalNEpisodes       | 15586      |
| TotalNSamples        | 6.2606e+05 |
| ExplainedVariance    | 0.52646    |
-------------------------------------
[2019-11-19 11:40:58.656468 UTC] Saving snapshot
[2019-11-19 11:40:58.657467 UTC] Starting iteration 126
[2019-11-19 11:40:58.658617 UTC] Start collecting samples
[2019-11-19 11:41:00.396282 UTC] Computing input variables for policy optimization
[2019-11-19 11:41:00.446303 UTC] Performing policy update
[2019-11-19 11:41:00.447476 UTC] Computing gradient in Euclidean space
[2019-11-19 11:41:00.497388 UTC] Computing approximate natural gradient using conjugate gradient algorithm
[2019-11-19 11:41:01.573062 UTC] Performing line search
[2019-11-19 11:41:01.655784 UTC] Updating baseline
[2019-11-19 11:41:03.332696 UTC] Computing logging information
-------------------------------------
| Iteration            | 126        |
| ExpectedImprovement  | 0.013786   |
| ActualImprovement    | 0.012588   |
| ImprovementRatio     | 0.9131     |
| MeanKL               | 0.0067328  |
| Entropy              | 1.8948     |
| Perplexity           | 6.6511     |
| AveragePolicyStd     | 0.33405    |
| AveragePolicyStd[0]  | 0.38626    |
| AveragePolicyStd[1]  | 0.3758     |
| AveragePolicyStd[2]  | 0.30624    |
| AveragePolicyStd[3]  | 0.28124    |
| AveragePolicyStd[4]  | 0.30761    |
| AveragePolicyStd[5]  | 0.34713    |
| AverageReturn        | 284.14     |
| MinReturn            | 14.42      |
| MaxReturn            | 683.6      |
| StdReturn            | 205.19     |
| AverageEpisodeLength | 415.44     |
| MinEpisodeLength     | 30         |
| MaxEpisodeLength     | 1000       |
| StdEpisodeLength     | 318.81     |
| TotalNEpisodes       | 15597      |
| TotalNSamples        | 6.3059e+05 |
| ExplainedVariance    | 0.51335    |
-------------------------------------
[2019-11-19 11:41:04.875719 UTC] Saving snapshot
[2019-11-19 11:41:04.876733 UTC] Starting iteration 127
[2019-11-19 11:41:04.877928 UTC] Start collecting samples
[2019-11-19 11:41:08.287406 UTC] Computing input variables for policy optimization
[2019-11-19 11:41:08.449576 UTC] Performing policy update
[2019-11-19 11:41:08.452945 UTC] Computing gradient in Euclidean space
[2019-11-19 11:41:08.593618 UTC] Computing approximate natural gradient using conjugate gradient algorithm
[2019-11-19 11:41:10.014064 UTC] Performing line search
[2019-11-19 11:41:10.202184 UTC] Updating baseline
[2019-11-19 11:41:11.926024 UTC] Computing logging information
------------------------------------
| Iteration            | 127       |
| ExpectedImprovement  | 0.01597   |
| ActualImprovement    | 0.015262  |
| ImprovementRatio     | 0.95569   |
| MeanKL               | 0.0070844 |
| Entropy              | 1.8683    |
| Perplexity           | 6.4773    |
| AveragePolicyStd     | 0.33236   |
| AveragePolicyStd[0]  | 0.38309   |
| AveragePolicyStd[1]  | 0.37174   |
| AveragePolicyStd[2]  | 0.30395   |
| AveragePolicyStd[3]  | 0.2839    |
| AveragePolicyStd[4]  | 0.30811   |
| AveragePolicyStd[5]  | 0.34337   |
| AverageReturn        | 282.07    |
| MinReturn            | 47.071    |
| MaxReturn            | 683.6     |
| StdReturn            | 201.16    |
| AverageEpisodeLength | 410.13    |
| MinEpisodeLength     | 73        |
| MaxEpisodeLength     | 1000      |
| StdEpisodeLength     | 311.77    |
| TotalNEpisodes       | 15607     |
| TotalNSamples        | 6.346e+05 |
| ExplainedVariance    | 0.71233   |
------------------------------------
[2019-11-19 11:41:13.357880 UTC] Saving snapshot
[2019-11-19 11:41:13.358424 UTC] Starting iteration 128
[2019-11-19 11:41:13.358949 UTC] Start collecting samples
[2019-11-19 11:41:16.631313 UTC] Computing input variables for policy optimization
[2019-11-19 11:41:16.769406 UTC] Performing policy update
[2019-11-19 11:41:16.774477 UTC] Computing gradient in Euclidean space
[2019-11-19 11:41:16.883659 UTC] Computing approximate natural gradient using conjugate gradient algorithm
[2019-11-19 11:41:18.072615 UTC] Performing line search
[2019-11-19 11:41:18.211793 UTC] Updating baseline
[2019-11-19 11:41:19.770196 UTC] Computing logging information
-------------------------------------
| Iteration            | 128        |
| ExpectedImprovement  | 0.014186   |
| ActualImprovement    | 0.012837   |
| ImprovementRatio     | 0.90485    |
| MeanKL               | 0.0071416  |
| Entropy              | 1.8506     |
| Perplexity           | 6.3635     |
| AveragePolicyStd     | 0.33144    |
| AveragePolicyStd[0]  | 0.38334    |
| AveragePolicyStd[1]  | 0.36937    |
| AveragePolicyStd[2]  | 0.30358    |
| AveragePolicyStd[3]  | 0.28157    |
| AveragePolicyStd[4]  | 0.30662    |
| AveragePolicyStd[5]  | 0.34416    |
| AverageReturn        | 283.66     |
| MinReturn            | 47.071     |
| MaxReturn            | 683.6      |
| StdReturn            | 200.28     |
| AverageEpisodeLength | 412.45     |
| MinEpisodeLength     | 73         |
| MaxEpisodeLength     | 1000       |
| StdEpisodeLength     | 310.38     |
| TotalNEpisodes       | 15616      |
| TotalNSamples        | 6.3917e+05 |
| ExplainedVariance    | 0.54348    |
-------------------------------------
[2019-11-19 11:41:21.051425 UTC] Saving snapshot
[2019-11-19 11:41:21.052374 UTC] Starting iteration 129
[2019-11-19 11:41:21.053128 UTC] Start collecting samples
[2019-11-19 11:41:24.356966 UTC] Computing input variables for policy optimization
[2019-11-19 11:41:24.529112 UTC] Performing policy update
[2019-11-19 11:41:24.534145 UTC] Computing gradient in Euclidean space
[2019-11-19 11:41:24.667884 UTC] Computing approximate natural gradient using conjugate gradient algorithm
[2019-11-19 11:41:26.136326 UTC] Performing line search
[2019-11-19 11:41:26.348097 UTC] Updating baseline
[2019-11-19 11:41:28.256062 UTC] Computing logging information
-------------------------------------
| Iteration            | 129        |
| ExpectedImprovement  | 0.014615   |
| ActualImprovement    | 0.013438   |
| ImprovementRatio     | 0.91941    |
| MeanKL               | 0.0073186  |
| Entropy              | 1.8173     |
| Perplexity           | 6.1554     |
| AveragePolicyStd     | 0.32944    |
| AveragePolicyStd[0]  | 0.37998    |
| AveragePolicyStd[1]  | 0.36693    |
| AveragePolicyStd[2]  | 0.30149    |
| AveragePolicyStd[3]  | 0.28378    |
| AveragePolicyStd[4]  | 0.30601    |
| AveragePolicyStd[5]  | 0.33845    |
| AverageReturn        | 310.28     |
| MinReturn            | 47.071     |
| MaxReturn            | 684.82     |
| StdReturn            | 214.59     |
| AverageEpisodeLength | 452.45     |
| MinEpisodeLength     | 73         |
| MaxEpisodeLength     | 1000       |
| StdEpisodeLength     | 330.96     |
| TotalNEpisodes       | 15627      |
| TotalNSamples        | 6.4578e+05 |
| ExplainedVariance    | 0.47527    |
-------------------------------------
[2019-11-19 11:41:29.484182 UTC] Saving snapshot
[2019-11-19 11:41:29.485586 UTC] Starting iteration 130
[2019-11-19 11:41:29.486759 UTC] Start collecting samples
[2019-11-19 11:41:33.265944 UTC] Computing input variables for policy optimization
[2019-11-19 11:41:33.457562 UTC] Performing policy update
[2019-11-19 11:41:33.460474 UTC] Computing gradient in Euclidean space
[2019-11-19 11:41:33.598635 UTC] Computing approximate natural gradient using conjugate gradient algorithm
[2019-11-19 11:41:34.404940 UTC] Performing line search
[2019-11-19 11:41:34.494787 UTC] Updating baseline
[2019-11-19 11:41:35.502479 UTC] Computing logging information
-------------------------------------
| Iteration            | 130        |
| ExpectedImprovement  | 0.013899   |
| ActualImprovement    | 0.013472   |
| ImprovementRatio     | 0.96929    |
| MeanKL               | 0.0072448  |
| Entropy              | 1.8189     |
| Perplexity           | 6.1651     |
| AveragePolicyStd     | 0.32964    |
| AveragePolicyStd[0]  | 0.38088    |
| AveragePolicyStd[1]  | 0.36884    |
| AveragePolicyStd[2]  | 0.29952    |
| AveragePolicyStd[3]  | 0.2832     |
| AveragePolicyStd[4]  | 0.30579    |
| AveragePolicyStd[5]  | 0.33959    |
| AverageReturn        | 324.78     |
| MinReturn            | 47.071     |
| MaxReturn            | 684.82     |
| StdReturn            | 218.31     |
| AverageEpisodeLength | 473.65     |
| MinEpisodeLength     | 73         |
| MaxEpisodeLength     | 1000       |
| StdEpisodeLength     | 334.99     |
| TotalNEpisodes       | 15635      |
| TotalNSamples        | 6.5046e+05 |
| ExplainedVariance    | 0.54852    |
-------------------------------------
[2019-11-19 11:41:36.848883 UTC] Saving snapshot
[2019-11-19 11:41:36.874492 UTC] Starting iteration 131
[2019-11-19 11:41:36.875194 UTC] Start collecting samples
[2019-11-19 11:41:40.036362 UTC] Computing input variables for policy optimization
[2019-11-19 11:41:40.232637 UTC] Performing policy update
[2019-11-19 11:41:40.237518 UTC] Computing gradient in Euclidean space
[2019-11-19 11:41:40.369846 UTC] Computing approximate natural gradient using conjugate gradient algorithm
[2019-11-19 11:41:41.575782 UTC] Performing line search
[2019-11-19 11:41:41.784442 UTC] Updating baseline
[2019-11-19 11:41:43.491823 UTC] Computing logging information
-------------------------------------
| Iteration            | 131        |
| ExpectedImprovement  | 0.013462   |
| ActualImprovement    | 0.012258   |
| ImprovementRatio     | 0.91057    |
| MeanKL               | 0.0071048  |
| Entropy              | 1.7936     |
| Perplexity           | 6.0109     |
| AveragePolicyStd     | 0.32826    |
| AveragePolicyStd[0]  | 0.38182    |
| AveragePolicyStd[1]  | 0.36732    |
| AveragePolicyStd[2]  | 0.29773    |
| AveragePolicyStd[3]  | 0.2847     |
| AveragePolicyStd[4]  | 0.3025     |
| AveragePolicyStd[5]  | 0.33548    |
| AverageReturn        | 326        |
| MinReturn            | 47.071     |
| MaxReturn            | 684.82     |
| StdReturn            | 217.46     |
| AverageEpisodeLength | 475.43     |
| MinEpisodeLength     | 73         |
| MaxEpisodeLength     | 1000       |
| StdEpisodeLength     | 333.81     |
| TotalNEpisodes       | 15640      |
| TotalNSamples        | 6.5255e+05 |
| ExplainedVariance    | 0.69779    |
-------------------------------------
[2019-11-19 11:41:44.674576 UTC] Saving snapshot
[2019-11-19 11:41:44.675206 UTC] Starting iteration 132
[2019-11-19 11:41:44.675898 UTC] Start collecting samples
[2019-11-19 11:41:48.066056 UTC] Computing input variables for policy optimization
[2019-11-19 11:41:48.207200 UTC] Performing policy update
[2019-11-19 11:41:48.209529 UTC] Computing gradient in Euclidean space
[2019-11-19 11:41:48.331738 UTC] Computing approximate natural gradient using conjugate gradient algorithm
[2019-11-19 11:41:49.766480 UTC] Performing line search
[2019-11-19 11:41:49.960805 UTC] Updating baseline
[2019-11-19 11:41:51.701479 UTC] Computing logging information
------------------------------------
| Iteration            | 132       |
| ExpectedImprovement  | 0.014003  |
| ActualImprovement    | 0.013172  |
| ImprovementRatio     | 0.9407    |
| MeanKL               | 0.0064469 |
| Entropy              | 1.7639    |
| Perplexity           | 5.8354    |
| AveragePolicyStd     | 0.32677   |
| AveragePolicyStd[0]  | 0.3828    |
| AveragePolicyStd[1]  | 0.36325   |
| AveragePolicyStd[2]  | 0.29088   |
| AveragePolicyStd[3]  | 0.28406   |
| AveragePolicyStd[4]  | 0.3014    |
| AveragePolicyStd[5]  | 0.33822   |
| AverageReturn        | 347.23    |
| MinReturn            | 106.83    |
| MaxReturn            | 692.34    |
| StdReturn            | 225.14    |
| AverageEpisodeLength | 506.71    |
| MinEpisodeLength     | 129       |
| MaxEpisodeLength     | 1000      |
| StdEpisodeLength     | 344.26    |
| TotalNEpisodes       | 15651     |
| TotalNSamples        | 6.6e+05   |
| ExplainedVariance    | 0.31113   |
------------------------------------
[2019-11-19 11:41:53.210220 UTC] Saving snapshot
[2019-11-19 11:41:53.211995 UTC] Starting iteration 133
[2019-11-19 11:41:53.213701 UTC] Start collecting samples
[2019-11-19 11:41:56.425982 UTC] Computing input variables for policy optimization
[2019-11-19 11:41:56.586234 UTC] Performing policy update
[2019-11-19 11:41:56.588997 UTC] Computing gradient in Euclidean space
[2019-11-19 11:41:56.703790 UTC] Computing approximate natural gradient using conjugate gradient algorithm
[2019-11-19 11:41:58.028879 UTC] Performing line search
[2019-11-19 11:41:58.184142 UTC] Updating baseline
[2019-11-19 11:41:59.974440 UTC] Computing logging information
-------------------------------------
| Iteration            | 133        |
| ExpectedImprovement  | 0.017315   |
| ActualImprovement    | 0.016328   |
| ImprovementRatio     | 0.94301    |
| MeanKL               | 0.0067288  |
| Entropy              | 1.7582     |
| Perplexity           | 5.802      |
| AveragePolicyStd     | 0.32662    |
| AveragePolicyStd[0]  | 0.38398    |
| AveragePolicyStd[1]  | 0.36359    |
| AveragePolicyStd[2]  | 0.29065    |
| AveragePolicyStd[3]  | 0.28116    |
| AveragePolicyStd[4]  | 0.2993     |
| AveragePolicyStd[5]  | 0.34104    |
| AverageReturn        | 355.85     |
| MinReturn            | 35.773     |
| MaxReturn            | 692.34     |
| StdReturn            | 231.69     |
| AverageEpisodeLength | 519.97     |
| MinEpisodeLength     | 70         |
| MaxEpisodeLength     | 1000       |
| StdEpisodeLength     | 351.4      |
| TotalNEpisodes       | 15659      |
| TotalNSamples        | 6.6488e+05 |
| ExplainedVariance    | 0.0067491  |
-------------------------------------
[2019-11-19 11:42:01.367024 UTC] Saving snapshot
[2019-11-19 11:42:01.367963 UTC] Starting iteration 134
[2019-11-19 11:42:01.368815 UTC] Start collecting samples
[2019-11-19 11:42:04.836803 UTC] Computing input variables for policy optimization
[2019-11-19 11:42:05.009299 UTC] Performing policy update
[2019-11-19 11:42:05.010826 UTC] Computing gradient in Euclidean space
[2019-11-19 11:42:05.167503 UTC] Computing approximate natural gradient using conjugate gradient algorithm
[2019-11-19 11:42:06.411334 UTC] Performing line search
[2019-11-19 11:42:06.515782 UTC] Updating baseline
[2019-11-19 11:42:07.656103 UTC] Computing logging information
-------------------------------------
| Iteration            | 134        |
| ExpectedImprovement  | 0.013677   |
| ActualImprovement    | 0.013533   |
| ImprovementRatio     | 0.98946    |
| MeanKL               | 0.007118   |
| Entropy              | 1.7372     |
| Perplexity           | 5.6811     |
| AveragePolicyStd     | 0.32532    |
| AveragePolicyStd[0]  | 0.38055    |
| AveragePolicyStd[1]  | 0.3613     |
| AveragePolicyStd[2]  | 0.29042    |
| AveragePolicyStd[3]  | 0.28174    |
| AveragePolicyStd[4]  | 0.29968    |
| AveragePolicyStd[5]  | 0.33822    |
| AverageReturn        | 371.52     |
| MinReturn            | 35.773     |
| MaxReturn            | 696.94     |
| StdReturn            | 236.06     |
| AverageEpisodeLength | 543.04     |
| MinEpisodeLength     | 70         |
| MaxEpisodeLength     | 1000       |
| StdEpisodeLength     | 356.96     |
| TotalNEpisodes       | 15664      |
| TotalNSamples        | 6.6839e+05 |
| ExplainedVariance    | 0.2974     |
-------------------------------------
[2019-11-19 11:42:09.227458 UTC] Saving snapshot
[2019-11-19 11:42:09.228779 UTC] Starting iteration 135
[2019-11-19 11:42:09.229892 UTC] Start collecting samples
[2019-11-19 11:42:12.805620 UTC] Computing input variables for policy optimization
[2019-11-19 11:42:12.919561 UTC] Performing policy update
[2019-11-19 11:42:12.928502 UTC] Computing gradient in Euclidean space
[2019-11-19 11:42:13.034508 UTC] Computing approximate natural gradient using conjugate gradient algorithm
[2019-11-19 11:42:14.335730 UTC] Performing line search
[2019-11-19 11:42:14.507775 UTC] Updating baseline
[2019-11-19 11:42:16.089151 UTC] Computing logging information
-------------------------------------
| Iteration            | 135        |
| ExpectedImprovement  | 0.013215   |
| ActualImprovement    | 0.012949   |
| ImprovementRatio     | 0.97987    |
| MeanKL               | 0.0072265  |
| Entropy              | 1.6919     |
| Perplexity           | 5.4298     |
| AveragePolicyStd     | 0.32272    |
| AveragePolicyStd[0]  | 0.37923    |
| AveragePolicyStd[1]  | 0.35368    |
| AveragePolicyStd[2]  | 0.2912     |
| AveragePolicyStd[3]  | 0.28023    |
| AveragePolicyStd[4]  | 0.29924    |
| AveragePolicyStd[5]  | 0.33276    |
| AverageReturn        | 377.31     |
| MinReturn            | 35.773     |
| MaxReturn            | 698.2      |
| StdReturn            | 238.64     |
| AverageEpisodeLength | 549.87     |
| MinEpisodeLength     | 70         |
| MaxEpisodeLength     | 1000       |
| StdEpisodeLength     | 359.51     |
| TotalNEpisodes       | 15674      |
| TotalNSamples        | 6.7457e+05 |
| ExplainedVariance    | 0.39057    |
-------------------------------------
[2019-11-19 11:42:17.308213 UTC] Saving snapshot
[2019-11-19 11:42:17.309086 UTC] Starting iteration 136
[2019-11-19 11:42:17.309954 UTC] Start collecting samples
[2019-11-19 11:42:20.275619 UTC] Computing input variables for policy optimization
[2019-11-19 11:42:20.401761 UTC] Performing policy update
[2019-11-19 11:42:20.402994 UTC] Computing gradient in Euclidean space
[2019-11-19 11:42:20.504444 UTC] Computing approximate natural gradient using conjugate gradient algorithm
[2019-11-19 11:42:21.805958 UTC] Performing line search
[2019-11-19 11:42:21.990032 UTC] Updating baseline
[2019-11-19 11:42:23.530869 UTC] Computing logging information
-------------------------------------
| Iteration            | 136        |
| ExpectedImprovement  | 0.015242   |
| ActualImprovement    | 0.014548   |
| ImprovementRatio     | 0.9545     |
| MeanKL               | 0.0070472  |
| Entropy              | 1.6918     |
| Perplexity           | 5.4293     |
| AveragePolicyStd     | 0.32275    |
| AveragePolicyStd[0]  | 0.37928    |
| AveragePolicyStd[1]  | 0.353      |
| AveragePolicyStd[2]  | 0.29052    |
| AveragePolicyStd[3]  | 0.28084    |
| AveragePolicyStd[4]  | 0.2973     |
| AveragePolicyStd[5]  | 0.33555    |
| AverageReturn        | 386.43     |
| MinReturn            | 35.773     |
| MaxReturn            | 698.2      |
| StdReturn            | 242.63     |
| AverageEpisodeLength | 560.87     |
| MinEpisodeLength     | 68         |
| MaxEpisodeLength     | 1000       |
| StdEpisodeLength     | 363.89     |
| TotalNEpisodes       | 15686      |
| TotalNSamples        | 6.8215e+05 |
| ExplainedVariance    | 0.39855    |
-------------------------------------
[2019-11-19 11:42:24.837546 UTC] Saving snapshot
[2019-11-19 11:42:24.838353 UTC] Starting iteration 137
[2019-11-19 11:42:24.839597 UTC] Start collecting samples
[2019-11-19 11:42:27.969543 UTC] Computing input variables for policy optimization
[2019-11-19 11:42:28.137921 UTC] Performing policy update
[2019-11-19 11:42:28.140110 UTC] Computing gradient in Euclidean space
[2019-11-19 11:42:28.270710 UTC] Computing approximate natural gradient using conjugate gradient algorithm
[2019-11-19 11:42:29.256707 UTC] Performing line search
[2019-11-19 11:42:29.363001 UTC] Updating baseline
[2019-11-19 11:42:30.524353 UTC] Computing logging information
-------------------------------------
| Iteration            | 137        |
| ExpectedImprovement  | 0.014475   |
| ActualImprovement    | 0.014353   |
| ImprovementRatio     | 0.99156    |
| MeanKL               | 0.0065723  |
| Entropy              | 1.6785     |
| Perplexity           | 5.3575     |
| AveragePolicyStd     | 0.32208    |
| AveragePolicyStd[0]  | 0.37882    |
| AveragePolicyStd[1]  | 0.35167    |
| AveragePolicyStd[2]  | 0.28773    |
| AveragePolicyStd[3]  | 0.28096    |
| AveragePolicyStd[4]  | 0.29622    |
| AveragePolicyStd[5]  | 0.33708    |
| AverageReturn        | 387.87     |
| MinReturn            | 35.773     |
| MaxReturn            | 698.2      |
| StdReturn            | 242.65     |
| AverageEpisodeLength | 562.88     |
| MinEpisodeLength     | 68         |
| MaxEpisodeLength     | 1000       |
| StdEpisodeLength     | 363.5      |
| TotalNEpisodes       | 15692      |
| TotalNSamples        | 6.8479e+05 |
| ExplainedVariance    | 0.69134    |
-------------------------------------
[2019-11-19 11:42:31.940199 UTC] Saving snapshot
[2019-11-19 11:42:31.941260 UTC] Starting iteration 138
[2019-11-19 11:42:31.942114 UTC] Start collecting samples
[2019-11-19 11:42:36.515449 UTC] Computing input variables for policy optimization
[2019-11-19 11:42:36.685035 UTC] Performing policy update
[2019-11-19 11:42:36.687692 UTC] Computing gradient in Euclidean space
[2019-11-19 11:42:36.783095 UTC] Computing approximate natural gradient using conjugate gradient algorithm
[2019-11-19 11:42:37.628900 UTC] Performing line search
[2019-11-19 11:42:37.743199 UTC] Updating baseline
[2019-11-19 11:42:38.955521 UTC] Computing logging information
-------------------------------------
| Iteration            | 138        |
| ExpectedImprovement  | 0.013701   |
| ActualImprovement    | 0.012941   |
| ImprovementRatio     | 0.94455    |
| MeanKL               | 0.0076596  |
| Entropy              | 1.6944     |
| Perplexity           | 5.4436     |
| AveragePolicyStd     | 0.32298    |
| AveragePolicyStd[0]  | 0.38035    |
| AveragePolicyStd[1]  | 0.35506    |
| AveragePolicyStd[2]  | 0.28916    |
| AveragePolicyStd[3]  | 0.28125    |
| AveragePolicyStd[4]  | 0.2964     |
| AveragePolicyStd[5]  | 0.33563    |
| AverageReturn        | 394.04     |
| MinReturn            | 35.773     |
| MaxReturn            | 699.66     |
| StdReturn            | 243.08     |
| AverageEpisodeLength | 571.85     |
| MinEpisodeLength     | 68         |
| MaxEpisodeLength     | 1000       |
| StdEpisodeLength     | 363.73     |
| TotalNEpisodes       | 15696      |
| TotalNSamples        | 6.8678e+05 |
| ExplainedVariance    | 0.66175    |
-------------------------------------
[2019-11-19 11:42:40.250601 UTC] Saving snapshot
[2019-11-19 11:42:40.251174 UTC] Starting iteration 139
[2019-11-19 11:42:40.251830 UTC] Start collecting samples
[2019-11-19 11:42:43.418407 UTC] Computing input variables for policy optimization
[2019-11-19 11:42:43.617752 UTC] Performing policy update
[2019-11-19 11:42:43.620210 UTC] Computing gradient in Euclidean space
[2019-11-19 11:42:43.764651 UTC] Computing approximate natural gradient using conjugate gradient algorithm
[2019-11-19 11:42:45.145874 UTC] Performing line search
[2019-11-19 11:42:45.338500 UTC] Updating baseline
[2019-11-19 11:42:47.045752 UTC] Computing logging information
-------------------------------------
| Iteration            | 139        |
| ExpectedImprovement  | 0.011768   |
| ActualImprovement    | 0.011134   |
| ImprovementRatio     | 0.94607    |
| MeanKL               | 0.0072122  |
| Entropy              | 1.6692     |
| Perplexity           | 5.3082     |
| AveragePolicyStd     | 0.3217     |
| AveragePolicyStd[0]  | 0.38147    |
| AveragePolicyStd[1]  | 0.35392    |
| AveragePolicyStd[2]  | 0.29037    |
| AveragePolicyStd[3]  | 0.2784     |
| AveragePolicyStd[4]  | 0.29417    |
| AveragePolicyStd[5]  | 0.33185    |
| AverageReturn        | 408.84     |
| MinReturn            | 35.773     |
| MaxReturn            | 700.65     |
| StdReturn            | 243.61     |
| AverageEpisodeLength | 592.83     |
| MinEpisodeLength     | 68         |
| MaxEpisodeLength     | 1000       |
| StdEpisodeLength     | 362.72     |
| TotalNEpisodes       | 15705      |
| TotalNSamples        | 6.9339e+05 |
| ExplainedVariance    | 0.34401    |
-------------------------------------
[2019-11-19 11:42:48.371073 UTC] Saving snapshot
[2019-11-19 11:42:48.371790 UTC] Starting iteration 140
[2019-11-19 11:42:48.373039 UTC] Start collecting samples
[2019-11-19 11:42:51.868744 UTC] Computing input variables for policy optimization
[2019-11-19 11:42:52.027121 UTC] Performing policy update
[2019-11-19 11:42:52.033266 UTC] Computing gradient in Euclidean space
[2019-11-19 11:42:52.173598 UTC] Computing approximate natural gradient using conjugate gradient algorithm
[2019-11-19 11:42:53.558884 UTC] Performing line search
[2019-11-19 11:42:53.730094 UTC] Updating baseline
[2019-11-19 11:42:55.386395 UTC] Computing logging information
------------------------------------
| Iteration            | 140       |
| ExpectedImprovement  | 0.013666  |
| ActualImprovement    | 0.012302  |
| ImprovementRatio     | 0.90024   |
| MeanKL               | 0.0077189 |
| Entropy              | 1.6361    |
| Perplexity           | 5.135     |
| AveragePolicyStd     | 0.31994   |
| AveragePolicyStd[0]  | 0.38117   |
| AveragePolicyStd[1]  | 0.35229   |
| AveragePolicyStd[2]  | 0.29262   |
| AveragePolicyStd[3]  | 0.2757    |
| AveragePolicyStd[4]  | 0.29167   |
| AveragePolicyStd[5]  | 0.3262    |
| AverageReturn        | 424.07    |
| MinReturn            | 35.773    |
| MaxReturn            | 700.65    |
| StdReturn            | 246.22    |
| AverageEpisodeLength | 614.44    |
| MinEpisodeLength     | 68        |
| MaxEpisodeLength     | 1000      |
| StdEpisodeLength     | 364.8     |
| TotalNEpisodes       | 15714     |
| TotalNSamples        | 7.001e+05 |
| ExplainedVariance    | 0.39042   |
------------------------------------
[2019-11-19 11:42:56.600435 UTC] Saving snapshot
[2019-11-19 11:42:56.618461 UTC] Starting iteration 141
[2019-11-19 11:42:56.619012 UTC] Start collecting samples
[2019-11-19 11:42:59.896873 UTC] Computing input variables for policy optimization
[2019-11-19 11:43:00.026020 UTC] Performing policy update
[2019-11-19 11:43:00.028133 UTC] Computing gradient in Euclidean space
[2019-11-19 11:43:00.137997 UTC] Computing approximate natural gradient using conjugate gradient algorithm
[2019-11-19 11:43:01.623737 UTC] Performing line search
[2019-11-19 11:43:01.821582 UTC] Updating baseline
[2019-11-19 11:43:03.502442 UTC] Computing logging information
-------------------------------------
| Iteration            | 141        |
| ExpectedImprovement  | 0.014262   |
| ActualImprovement    | 0.013465   |
| ImprovementRatio     | 0.94415    |
| MeanKL               | 0.0072189  |
| Entropy              | 1.638      |
| Perplexity           | 5.1446     |
| AveragePolicyStd     | 0.32002    |
| AveragePolicyStd[0]  | 0.38059    |
| AveragePolicyStd[1]  | 0.35126    |
| AveragePolicyStd[2]  | 0.2928     |
| AveragePolicyStd[3]  | 0.27473    |
| AveragePolicyStd[4]  | 0.29291    |
| AveragePolicyStd[5]  | 0.32782    |
| AverageReturn        | 424.93     |
| MinReturn            | 35.773     |
| MaxReturn            | 700.65     |
| StdReturn            | 246.14     |
| AverageEpisodeLength | 615.11     |
| MinEpisodeLength     | 68         |
| MaxEpisodeLength     | 1000       |
| StdEpisodeLength     | 364.2      |
| TotalNEpisodes       | 15718      |
| TotalNSamples        | 7.0268e+05 |
| ExplainedVariance    | 0.26519    |
-------------------------------------
[2019-11-19 11:43:04.654472 UTC] Saving snapshot
[2019-11-19 11:43:04.655290 UTC] Starting iteration 142
[2019-11-19 11:43:04.656429 UTC] Start collecting samples
[2019-11-19 11:43:07.935787 UTC] Computing input variables for policy optimization
[2019-11-19 11:43:08.094803 UTC] Performing policy update
[2019-11-19 11:43:08.097413 UTC] Computing gradient in Euclidean space
[2019-11-19 11:43:08.272265 UTC] Computing approximate natural gradient using conjugate gradient algorithm
[2019-11-19 11:43:09.339840 UTC] Performing line search
[2019-11-19 11:43:09.417820 UTC] Updating baseline
[2019-11-19 11:43:10.365643 UTC] Computing logging information
-------------------------------------
| Iteration            | 142        |
| ExpectedImprovement  | 0.017077   |
| ActualImprovement    | 0.015738   |
| ImprovementRatio     | 0.9216     |
| MeanKL               | 0.0071107  |
| Entropy              | 1.6313     |
| Perplexity           | 5.1106     |
| AveragePolicyStd     | 0.31971    |
| AveragePolicyStd[0]  | 0.37805    |
| AveragePolicyStd[1]  | 0.35261    |
| AveragePolicyStd[2]  | 0.29383    |
| AveragePolicyStd[3]  | 0.27171    |
| AveragePolicyStd[4]  | 0.29226    |
| AveragePolicyStd[5]  | 0.32978    |
| AverageReturn        | 438.22     |
| MinReturn            | 35.773     |
| MaxReturn            | 701.56     |
| StdReturn            | 249.41     |
| AverageEpisodeLength | 634.42     |
| MinEpisodeLength     | 52         |
| MaxEpisodeLength     | 1000       |
| StdEpisodeLength     | 367.94     |
| TotalNEpisodes       | 15723      |
| TotalNSamples        | 7.0673e+05 |
| ExplainedVariance    | 0.027257   |
-------------------------------------
[2019-11-19 11:43:11.795573 UTC] Saving snapshot
[2019-11-19 11:43:11.796519 UTC] Starting iteration 143
[2019-11-19 11:43:11.797161 UTC] Start collecting samples
[2019-11-19 11:43:15.185822 UTC] Computing input variables for policy optimization
[2019-11-19 11:43:15.340213 UTC] Performing policy update
[2019-11-19 11:43:15.342698 UTC] Computing gradient in Euclidean space
[2019-11-19 11:43:15.481017 UTC] Computing approximate natural gradient using conjugate gradient algorithm
[2019-11-19 11:43:17.067554 UTC] Performing line search
[2019-11-19 11:43:17.258497 UTC] Updating baseline
[2019-11-19 11:43:19.150105 UTC] Computing logging information
-------------------------------------
| Iteration            | 143        |
| ExpectedImprovement  | 0.015141   |
| ActualImprovement    | 0.0145     |
| ImprovementRatio     | 0.95763    |
| MeanKL               | 0.0071528  |
| Entropy              | 1.5915     |
| Perplexity           | 4.911      |
| AveragePolicyStd     | 0.3176     |
| AveragePolicyStd[0]  | 0.37496    |
| AveragePolicyStd[1]  | 0.34853    |
| AveragePolicyStd[2]  | 0.29067    |
| AveragePolicyStd[3]  | 0.26826    |
| AveragePolicyStd[4]  | 0.29293    |
| AveragePolicyStd[5]  | 0.33022    |
| AverageReturn        | 448.87     |
| MinReturn            | 35.773     |
| MaxReturn            | 706.6      |
| StdReturn            | 254.83     |
| AverageEpisodeLength | 649.1      |
| MinEpisodeLength     | 52         |
| MaxEpisodeLength     | 1000       |
| StdEpisodeLength     | 375        |
| TotalNEpisodes       | 15733      |
| TotalNSamples        | 7.1408e+05 |
| ExplainedVariance    | 0.084647   |
-------------------------------------
[2019-11-19 11:43:20.520908 UTC] Saving snapshot
[2019-11-19 11:43:20.521423 UTC] Starting iteration 144
[2019-11-19 11:43:20.522150 UTC] Start collecting samples
[2019-11-19 11:43:23.694333 UTC] Computing input variables for policy optimization
[2019-11-19 11:43:23.831726 UTC] Performing policy update
[2019-11-19 11:43:23.833553 UTC] Computing gradient in Euclidean space
[2019-11-19 11:43:23.939293 UTC] Computing approximate natural gradient using conjugate gradient algorithm
[2019-11-19 11:43:25.176989 UTC] Performing line search
[2019-11-19 11:43:25.332189 UTC] Updating baseline
[2019-11-19 11:43:27.159184 UTC] Computing logging information
-------------------------------------
| Iteration            | 144        |
| ExpectedImprovement  | 0.011861   |
| ActualImprovement    | 0.011578   |
| ImprovementRatio     | 0.97612    |
| MeanKL               | 0.0077273  |
| Entropy              | 1.5832     |
| Perplexity           | 4.8704     |
| AveragePolicyStd     | 0.31705    |
| AveragePolicyStd[0]  | 0.37301    |
| AveragePolicyStd[1]  | 0.34742    |
| AveragePolicyStd[2]  | 0.28982    |
| AveragePolicyStd[3]  | 0.26948    |
| AveragePolicyStd[4]  | 0.29357    |
| AveragePolicyStd[5]  | 0.329      |
| AverageReturn        | 459.45     |
| MinReturn            | 35.773     |
| MaxReturn            | 708.55     |
| StdReturn            | 255.09     |
| AverageEpisodeLength | 663.22     |
| MinEpisodeLength     | 52         |
| MaxEpisodeLength     | 1000       |
| StdEpisodeLength     | 374.48     |
| TotalNEpisodes       | 15742      |
| TotalNSamples        | 7.2022e+05 |
| ExplainedVariance    | 0.31893    |
-------------------------------------
[2019-11-19 11:43:28.507648 UTC] Saving snapshot
[2019-11-19 11:43:28.508374 UTC] Starting iteration 145
[2019-11-19 11:43:28.509047 UTC] Start collecting samples
[2019-11-19 11:43:31.858059 UTC] Computing input variables for policy optimization
[2019-11-19 11:43:32.045745 UTC] Performing policy update
[2019-11-19 11:43:32.049342 UTC] Computing gradient in Euclidean space
[2019-11-19 11:43:32.122244 UTC] Computing approximate natural gradient using conjugate gradient algorithm
[2019-11-19 11:43:32.788701 UTC] Performing line search
[2019-11-19 11:43:32.890843 UTC] Updating baseline
[2019-11-19 11:43:33.859342 UTC] Computing logging information
-------------------------------------
| Iteration            | 145        |
| ExpectedImprovement  | 0.014233   |
| ActualImprovement    | 0.014979   |
| ImprovementRatio     | 1.0524     |
| MeanKL               | 0.0074688  |
| Entropy              | 1.6022     |
| Perplexity           | 4.964      |
| AveragePolicyStd     | 0.31813    |
| AveragePolicyStd[0]  | 0.37564    |
| AveragePolicyStd[1]  | 0.34816    |
| AveragePolicyStd[2]  | 0.29343    |
| AveragePolicyStd[3]  | 0.26966    |
| AveragePolicyStd[4]  | 0.2909     |
| AveragePolicyStd[5]  | 0.33098    |
| AverageReturn        | 448.98     |
| MinReturn            | 35.773     |
| MaxReturn            | 708.55     |
| StdReturn            | 258.17     |
| AverageEpisodeLength | 646.36     |
| MinEpisodeLength     | 52         |
| MaxEpisodeLength     | 1000       |
| StdEpisodeLength     | 377.93     |
| TotalNEpisodes       | 15749      |
| TotalNSamples        | 7.2417e+05 |
| ExplainedVariance    | 0.33403    |
-------------------------------------
[2019-11-19 11:43:35.243178 UTC] Saving snapshot
[2019-11-19 11:43:35.243714 UTC] Starting iteration 146
[2019-11-19 11:43:35.244355 UTC] Start collecting samples
[2019-11-19 11:43:38.781569 UTC] Computing input variables for policy optimization
[2019-11-19 11:43:38.954712 UTC] Performing policy update
[2019-11-19 11:43:38.957320 UTC] Computing gradient in Euclidean space
[2019-11-19 11:43:39.078803 UTC] Computing approximate natural gradient using conjugate gradient algorithm
[2019-11-19 11:43:40.426750 UTC] Performing line search
[2019-11-19 11:43:40.572524 UTC] Updating baseline
[2019-11-19 11:43:42.497652 UTC] Computing logging information
-------------------------------------
| Iteration            | 146        |
| ExpectedImprovement  | 0.012786   |
| ActualImprovement    | 0.012429   |
| ImprovementRatio     | 0.97204    |
| MeanKL               | 0.0072199  |
| Entropy              | 1.5933     |
| Perplexity           | 4.9202     |
| AveragePolicyStd     | 0.31772    |
| AveragePolicyStd[0]  | 0.37576    |
| AveragePolicyStd[1]  | 0.34774    |
| AveragePolicyStd[2]  | 0.29371    |
| AveragePolicyStd[3]  | 0.26783    |
| AveragePolicyStd[4]  | 0.29017    |
| AveragePolicyStd[5]  | 0.3311     |
| AverageReturn        | 453.46     |
| MinReturn            | 35.847     |
| MaxReturn            | 708.55     |
| StdReturn            | 259.93     |
| AverageEpisodeLength | 650.9      |
| MinEpisodeLength     | 52         |
| MaxEpisodeLength     | 1000       |
| StdEpisodeLength     | 380.21     |
| TotalNEpisodes       | 15758      |
| TotalNSamples        | 7.2987e+05 |
| ExplainedVariance    | 0.21744    |
-------------------------------------
[2019-11-19 11:43:43.790722 UTC] Saving snapshot
[2019-11-19 11:43:43.791656 UTC] Starting iteration 147
[2019-11-19 11:43:43.792484 UTC] Start collecting samples
[2019-11-19 11:43:46.890010 UTC] Computing input variables for policy optimization
[2019-11-19 11:43:47.050260 UTC] Performing policy update
[2019-11-19 11:43:47.052281 UTC] Computing gradient in Euclidean space
[2019-11-19 11:43:47.178947 UTC] Computing approximate natural gradient using conjugate gradient algorithm
[2019-11-19 11:43:48.513772 UTC] Performing line search
[2019-11-19 11:43:48.696639 UTC] Updating baseline
[2019-11-19 11:43:50.871468 UTC] Computing logging information
------------------------------------
| Iteration            | 147       |
| ExpectedImprovement  | 0.014214  |
| ActualImprovement    | 0.012985  |
| ImprovementRatio     | 0.91348   |
| MeanKL               | 0.0071701 |
| Entropy              | 1.5939    |
| Perplexity           | 4.9228    |
| AveragePolicyStd     | 0.31784   |
| AveragePolicyStd[0]  | 0.3765    |
| AveragePolicyStd[1]  | 0.34885   |
| AveragePolicyStd[2]  | 0.29364   |
| AveragePolicyStd[3]  | 0.26594   |
| AveragePolicyStd[4]  | 0.2907    |
| AveragePolicyStd[5]  | 0.33139   |
| AverageReturn        | 462.2     |
| MinReturn            | 35.847    |
| MaxReturn            | 708.55    |
| StdReturn            | 255.8     |
| AverageEpisodeLength | 662.62    |
| MinEpisodeLength     | 52        |
| MaxEpisodeLength     | 1000      |
| StdEpisodeLength     | 374.47    |
| TotalNEpisodes       | 15765     |
| TotalNSamples        | 7.348e+05 |
| ExplainedVariance    | 0.34978   |
------------------------------------
[2019-11-19 11:43:52.134668 UTC] Saving snapshot
[2019-11-19 11:43:52.135320 UTC] Starting iteration 148
[2019-11-19 11:43:52.136284 UTC] Start collecting samples
[2019-11-19 11:43:55.377742 UTC] Computing input variables for policy optimization
[2019-11-19 11:43:55.544113 UTC] Performing policy update
[2019-11-19 11:43:55.547181 UTC] Computing gradient in Euclidean space
[2019-11-19 11:43:55.662470 UTC] Computing approximate natural gradient using conjugate gradient algorithm
[2019-11-19 11:43:57.079024 UTC] Performing line search
[2019-11-19 11:43:57.226484 UTC] Updating baseline
[2019-11-19 11:43:59.100026 UTC] Computing logging information
-------------------------------------
| Iteration            | 148        |
| ExpectedImprovement  | 0.01393    |
| ActualImprovement    | 0.012525   |
| ImprovementRatio     | 0.89915    |
| MeanKL               | 0.0068238  |
| Entropy              | 1.5879     |
| Perplexity           | 4.8936     |
| AveragePolicyStd     | 0.31759    |
| AveragePolicyStd[0]  | 0.37726    |
| AveragePolicyStd[1]  | 0.35032    |
| AveragePolicyStd[2]  | 0.29391    |
| AveragePolicyStd[3]  | 0.26434    |
| AveragePolicyStd[4]  | 0.29124    |
| AveragePolicyStd[5]  | 0.32846    |
| AverageReturn        | 460.77     |
| MinReturn            | 35.847     |
| MaxReturn            | 708.55     |
| StdReturn            | 255.17     |
| AverageEpisodeLength | 659.99     |
| MinEpisodeLength     | 52         |
| MaxEpisodeLength     | 1000       |
| StdEpisodeLength     | 372.97     |
| TotalNEpisodes       | 15772      |
| TotalNSamples        | 7.3945e+05 |
| ExplainedVariance    | 0.40339    |
-------------------------------------
[2019-11-19 11:44:00.494596 UTC] Saving snapshot
[2019-11-19 11:44:00.495159 UTC] Starting iteration 149
[2019-11-19 11:44:00.495755 UTC] Start collecting samples
[2019-11-19 11:44:04.127093 UTC] Computing input variables for policy optimization
[2019-11-19 11:44:04.298170 UTC] Performing policy update
[2019-11-19 11:44:04.300472 UTC] Computing gradient in Euclidean space
[2019-11-19 11:44:04.431124 UTC] Computing approximate natural gradient using conjugate gradient algorithm
[2019-11-19 11:44:05.812331 UTC] Performing line search
[2019-11-19 11:44:05.976856 UTC] Updating baseline
[2019-11-19 11:44:08.158346 UTC] Computing logging information
-------------------------------------
| Iteration            | 149        |
| ExpectedImprovement  | 0.012301   |
| ActualImprovement    | 0.011523   |
| ImprovementRatio     | 0.93672    |
| MeanKL               | 0.0075893  |
| Entropy              | 1.5675     |
| Perplexity           | 4.7948     |
| AveragePolicyStd     | 0.31671    |
| AveragePolicyStd[0]  | 0.37586    |
| AveragePolicyStd[1]  | 0.35331    |
| AveragePolicyStd[2]  | 0.29402    |
| AveragePolicyStd[3]  | 0.26081    |
| AveragePolicyStd[4]  | 0.28717    |
| AveragePolicyStd[5]  | 0.32909    |
| AverageReturn        | 474.23     |
| MinReturn            | 35.847     |
| MaxReturn            | 708.82     |
| StdReturn            | 251.03     |
| AverageEpisodeLength | 678.92     |
| MinEpisodeLength     | 52         |
| MaxEpisodeLength     | 1000       |
| StdEpisodeLength     | 366.11     |
| TotalNEpisodes       | 15778      |
| TotalNSamples        | 7.4406e+05 |
| ExplainedVariance    | 0.44742    |
-------------------------------------
[2019-11-19 11:44:09.695501 UTC] Saving snapshot
[2019-11-19 11:44:09.696069 UTC] Starting iteration 150
[2019-11-19 11:44:09.696542 UTC] Start collecting samples
[2019-11-19 11:44:13.474236 UTC] Computing input variables for policy optimization
[2019-11-19 11:44:13.697695 UTC] Performing policy update
[2019-11-19 11:44:13.705215 UTC] Computing gradient in Euclidean space
[2019-11-19 11:44:13.848333 UTC] Computing approximate natural gradient using conjugate gradient algorithm
[2019-11-19 11:44:15.081285 UTC] Performing line search
[2019-11-19 11:44:15.287752 UTC] Updating baseline
[2019-11-19 11:44:17.153624 UTC] Computing logging information
-------------------------------------
| Iteration            | 150        |
| ExpectedImprovement  | 0.013637   |
| ActualImprovement    | 0.01305    |
| ImprovementRatio     | 0.95692    |
| MeanKL               | 0.0070443  |
| Entropy              | 1.5719     |
| Perplexity           | 4.8157     |
| AveragePolicyStd     | 0.31693    |
| AveragePolicyStd[0]  | 0.37229    |
| AveragePolicyStd[1]  | 0.3573     |
| AveragePolicyStd[2]  | 0.29319    |
| AveragePolicyStd[3]  | 0.2607     |
| AveragePolicyStd[4]  | 0.28804    |
| AveragePolicyStd[5]  | 0.33004    |
| AverageReturn        | 470.34     |
| MinReturn            | 35.847     |
| MaxReturn            | 708.82     |
| StdReturn            | 252.31     |
| AverageEpisodeLength | 672.58     |
| MinEpisodeLength     | 52         |
| MaxEpisodeLength     | 1000       |
| StdEpisodeLength     | 368.02     |
| TotalNEpisodes       | 15786      |
| TotalNSamples        | 7.4941e+05 |
| ExplainedVariance    | 0.4812     |
-------------------------------------
[2019-11-19 11:44:18.601912 UTC] Saving snapshot
[2019-11-19 11:44:18.618310 UTC] Starting iteration 151
[2019-11-19 11:44:18.619014 UTC] Start collecting samples
[2019-11-19 11:44:22.263793 UTC] Computing input variables for policy optimization
[2019-11-19 11:44:22.414261 UTC] Performing policy update
[2019-11-19 11:44:22.416798 UTC] Computing gradient in Euclidean space
[2019-11-19 11:44:22.542289 UTC] Computing approximate natural gradient using conjugate gradient algorithm
[2019-11-19 11:44:23.931267 UTC] Performing line search
[2019-11-19 11:44:24.103746 UTC] Updating baseline
[2019-11-19 11:44:25.827816 UTC] Computing logging information
-------------------------------------
| Iteration            | 151        |
| ExpectedImprovement  | 0.012868   |
| ActualImprovement    | 0.01185    |
| ImprovementRatio     | 0.92094    |
| MeanKL               | 0.0074816  |
| Entropy              | 1.5924     |
| Perplexity           | 4.9157     |
| AveragePolicyStd     | 0.31796    |
| AveragePolicyStd[0]  | 0.37606    |
| AveragePolicyStd[1]  | 0.35957    |
| AveragePolicyStd[2]  | 0.29111    |
| AveragePolicyStd[3]  | 0.26486    |
| AveragePolicyStd[4]  | 0.29125    |
| AveragePolicyStd[5]  | 0.32493    |
| AverageReturn        | 489.1      |
| MinReturn            | 35.847     |
| MaxReturn            | 708.82     |
| StdReturn            | 250.72     |
| AverageEpisodeLength | 699.55     |
| MinEpisodeLength     | 52         |
| MaxEpisodeLength     | 1000       |
| StdEpisodeLength     | 365.42     |
| TotalNEpisodes       | 15793      |
| TotalNSamples        | 7.5506e+05 |
| ExplainedVariance    | 0.26365    |
-------------------------------------
[2019-11-19 11:44:27.048353 UTC] Saving snapshot
[2019-11-19 11:44:27.049102 UTC] Starting iteration 152
[2019-11-19 11:44:27.050291 UTC] Start collecting samples
[2019-11-19 11:44:30.405774 UTC] Computing input variables for policy optimization
[2019-11-19 11:44:30.532754 UTC] Performing policy update
[2019-11-19 11:44:30.535123 UTC] Computing gradient in Euclidean space
[2019-11-19 11:44:30.635323 UTC] Computing approximate natural gradient using conjugate gradient algorithm
[2019-11-19 11:44:31.807493 UTC] Performing line search
[2019-11-19 11:44:31.961971 UTC] Updating baseline
[2019-11-19 11:44:33.597862 UTC] Computing logging information
-------------------------------------
| Iteration            | 152        |
| ExpectedImprovement  | 0.013395   |
| ActualImprovement    | 0.011701   |
| ImprovementRatio     | 0.87353    |
| MeanKL               | 0.007681   |
| Entropy              | 1.6035     |
| Perplexity           | 4.9702     |
| AveragePolicyStd     | 0.3186     |
| AveragePolicyStd[0]  | 0.37653    |
| AveragePolicyStd[1]  | 0.36048    |
| AveragePolicyStd[2]  | 0.29217    |
| AveragePolicyStd[3]  | 0.26373    |
| AveragePolicyStd[4]  | 0.29195    |
| AveragePolicyStd[5]  | 0.32671    |
| AverageReturn        | 481.46     |
| MinReturn            | 35.847     |
| MaxReturn            | 708.82     |
| StdReturn            | 253.47     |
| AverageEpisodeLength | 687.73     |
| MinEpisodeLength     | 52         |
| MaxEpisodeLength     | 1000       |
| StdEpisodeLength     | 369.51     |
| TotalNEpisodes       | 15802      |
| TotalNSamples        | 7.5988e+05 |
| ExplainedVariance    | 0.58591    |
-------------------------------------
[2019-11-19 11:44:34.881657 UTC] Saving snapshot
[2019-11-19 11:44:34.882809 UTC] Starting iteration 153
[2019-11-19 11:44:34.883741 UTC] Start collecting samples
[2019-11-19 11:44:38.069415 UTC] Computing input variables for policy optimization
[2019-11-19 11:44:38.277625 UTC] Performing policy update
[2019-11-19 11:44:38.283998 UTC] Computing gradient in Euclidean space
[2019-11-19 11:44:38.409283 UTC] Computing approximate natural gradient using conjugate gradient algorithm
[2019-11-19 11:44:39.584195 UTC] Performing line search
[2019-11-19 11:44:39.734662 UTC] Updating baseline
[2019-11-19 11:44:40.981622 UTC] Computing logging information
------------------------------------
| Iteration            | 153       |
| ExpectedImprovement  | 0.015093  |
| ActualImprovement    | 0.010857  |
| ImprovementRatio     | 0.71938   |
| MeanKL               | 0.0069891 |
| Entropy              | 1.5963    |
| Perplexity           | 4.935     |
| AveragePolicyStd     | 0.31826   |
| AveragePolicyStd[0]  | 0.37785   |
| AveragePolicyStd[1]  | 0.35912   |
| AveragePolicyStd[2]  | 0.29071   |
| AveragePolicyStd[3]  | 0.26356   |
| AveragePolicyStd[4]  | 0.29166   |
| AveragePolicyStd[5]  | 0.32666   |
| AverageReturn        | 458.8     |
| MinReturn            | 35.847    |
| MaxReturn            | 708.82    |
| StdReturn            | 259.98    |
| AverageEpisodeLength | 653.59    |
| MinEpisodeLength     | 52        |
| MaxEpisodeLength     | 1000      |
| StdEpisodeLength     | 378.44    |
| TotalNEpisodes       | 15812     |
| TotalNSamples        | 7.65e+05  |
| ExplainedVariance    | 0.4434    |
------------------------------------
[2019-11-19 11:44:42.365621 UTC] Saving snapshot
[2019-11-19 11:44:42.367443 UTC] Starting iteration 154
[2019-11-19 11:44:42.368148 UTC] Start collecting samples
[2019-11-19 11:44:46.258846 UTC] Computing input variables for policy optimization
[2019-11-19 11:44:46.453841 UTC] Performing policy update
[2019-11-19 11:44:46.454877 UTC] Computing gradient in Euclidean space
[2019-11-19 11:44:46.581160 UTC] Computing approximate natural gradient using conjugate gradient algorithm
[2019-11-19 11:44:47.628870 UTC] Performing line search
[2019-11-19 11:44:47.801329 UTC] Updating baseline
[2019-11-19 11:44:49.345553 UTC] Computing logging information
-------------------------------------
| Iteration            | 154        |
| ExpectedImprovement  | 0.013066   |
| ActualImprovement    | 0.012551   |
| ImprovementRatio     | 0.96057    |
| MeanKL               | 0.0070802  |
| Entropy              | 1.5915     |
| Perplexity           | 4.9113     |
| AveragePolicyStd     | 0.31801    |
| AveragePolicyStd[0]  | 0.37528    |
| AveragePolicyStd[1]  | 0.35964    |
| AveragePolicyStd[2]  | 0.29224    |
| AveragePolicyStd[3]  | 0.26117    |
| AveragePolicyStd[4]  | 0.29195    |
| AveragePolicyStd[5]  | 0.32778    |
| AverageReturn        | 463.09     |
| MinReturn            | 35.847     |
| MaxReturn            | 708.82     |
| StdReturn            | 260.97     |
| AverageEpisodeLength | 659.11     |
| MinEpisodeLength     | 52         |
| MaxEpisodeLength     | 1000       |
| StdEpisodeLength     | 380.22     |
| TotalNEpisodes       | 15818      |
| TotalNSamples        | 7.6859e+05 |
| ExplainedVariance    | 0.34082    |
-------------------------------------
[2019-11-19 11:44:50.721336 UTC] Saving snapshot
[2019-11-19 11:44:50.722207 UTC] Starting iteration 155
[2019-11-19 11:44:50.722991 UTC] Start collecting samples
[2019-11-19 11:44:54.407533 UTC] Computing input variables for policy optimization
[2019-11-19 11:44:54.538965 UTC] Performing policy update
[2019-11-19 11:44:54.544131 UTC] Computing gradient in Euclidean space
[2019-11-19 11:44:54.680391 UTC] Computing approximate natural gradient using conjugate gradient algorithm
[2019-11-19 11:44:55.790773 UTC] Performing line search
[2019-11-19 11:44:55.884666 UTC] Updating baseline
[2019-11-19 11:44:57.121610 UTC] Computing logging information
-------------------------------------
| Iteration            | 155        |
| ExpectedImprovement  | 0.014076   |
| ActualImprovement    | 0.012773   |
| ImprovementRatio     | 0.90744    |
| MeanKL               | 0.0068469  |
| Entropy              | 1.5727     |
| Perplexity           | 4.8198     |
| AveragePolicyStd     | 0.31698    |
| AveragePolicyStd[0]  | 0.37306    |
| AveragePolicyStd[1]  | 0.3574     |
| AveragePolicyStd[2]  | 0.29244    |
| AveragePolicyStd[3]  | 0.26083    |
| AveragePolicyStd[4]  | 0.28905    |
| AveragePolicyStd[5]  | 0.32907    |
| AverageReturn        | 454.85     |
| MinReturn            | 46.465     |
| MaxReturn            | 708.82     |
| StdReturn            | 259.36     |
| AverageEpisodeLength | 646.53     |
| MinEpisodeLength     | 69         |
| MaxEpisodeLength     | 1000       |
| StdEpisodeLength     | 378.36     |
| TotalNEpisodes       | 15825      |
| TotalNSamples        | 7.7339e+05 |
| ExplainedVariance    | 0.33913    |
-------------------------------------
[2019-11-19 11:44:58.360879 UTC] Saving snapshot
[2019-11-19 11:44:58.361562 UTC] Starting iteration 156
[2019-11-19 11:44:58.362357 UTC] Start collecting samples
[2019-11-19 11:45:01.735542 UTC] Computing input variables for policy optimization
[2019-11-19 11:45:01.939162 UTC] Performing policy update
[2019-11-19 11:45:01.941970 UTC] Computing gradient in Euclidean space
[2019-11-19 11:45:02.082150 UTC] Computing approximate natural gradient using conjugate gradient algorithm
[2019-11-19 11:45:03.309959 UTC] Performing line search
[2019-11-19 11:45:03.485795 UTC] Updating baseline
[2019-11-19 11:45:04.989748 UTC] Computing logging information
-------------------------------------
| Iteration            | 156        |
| ExpectedImprovement  | 0.015417   |
| ActualImprovement    | 0.014429   |
| ImprovementRatio     | 0.93592    |
| MeanKL               | 0.0071995  |
| Entropy              | 1.5466     |
| Perplexity           | 4.6956     |
| AveragePolicyStd     | 0.31556    |
| AveragePolicyStd[0]  | 0.3737     |
| AveragePolicyStd[1]  | 0.35121    |
| AveragePolicyStd[2]  | 0.29309    |
| AveragePolicyStd[3]  | 0.26056    |
| AveragePolicyStd[4]  | 0.28566    |
| AveragePolicyStd[5]  | 0.32918    |
| AverageReturn        | 461.46     |
| MinReturn            | 48.966     |
| MaxReturn            | 708.82     |
| StdReturn            | 257.65     |
| AverageEpisodeLength | 655.55     |
| MinEpisodeLength     | 71         |
| MaxEpisodeLength     | 1000       |
| StdEpisodeLength     | 375.83     |
| TotalNEpisodes       | 15830      |
| TotalNSamples        | 7.7756e+05 |
| ExplainedVariance    | 0.10613    |
-------------------------------------
[2019-11-19 11:45:06.342041 UTC] Saving snapshot
[2019-11-19 11:45:06.342812 UTC] Starting iteration 157
[2019-11-19 11:45:06.343510 UTC] Start collecting samples
[2019-11-19 11:45:09.959858 UTC] Computing input variables for policy optimization
[2019-11-19 11:45:10.051876 UTC] Performing policy update
[2019-11-19 11:45:10.053202 UTC] Computing gradient in Euclidean space
[2019-11-19 11:45:10.144735 UTC] Computing approximate natural gradient using conjugate gradient algorithm
[2019-11-19 11:45:11.429085 UTC] Performing line search
[2019-11-19 11:45:11.573962 UTC] Updating baseline
[2019-11-19 11:45:13.523087 UTC] Computing logging information
-------------------------------------
| Iteration            | 157        |
| ExpectedImprovement  | 0.01134    |
| ActualImprovement    | 0.010814   |
| ImprovementRatio     | 0.95363    |
| MeanKL               | 0.0077515  |
| Entropy              | 1.5181     |
| Perplexity           | 4.5634     |
| AveragePolicyStd     | 0.31421    |
| AveragePolicyStd[0]  | 0.37139    |
| AveragePolicyStd[1]  | 0.35353    |
| AveragePolicyStd[2]  | 0.28853    |
| AveragePolicyStd[3]  | 0.2564     |
| AveragePolicyStd[4]  | 0.28824    |
| AveragePolicyStd[5]  | 0.32716    |
| AverageReturn        | 473.12     |
| MinReturn            | 64.424     |
| MaxReturn            | 708.82     |
| StdReturn            | 255.05     |
| AverageEpisodeLength | 672.34     |
| MinEpisodeLength     | 91         |
| MaxEpisodeLength     | 1000       |
| StdEpisodeLength     | 371.89     |
| TotalNEpisodes       | 15837      |
| TotalNSamples        | 7.8388e+05 |
| ExplainedVariance    | 0.20618    |
-------------------------------------
[2019-11-19 11:45:14.760177 UTC] Saving snapshot
[2019-11-19 11:45:14.760789 UTC] Starting iteration 158
[2019-11-19 11:45:14.761509 UTC] Start collecting samples
[2019-11-19 11:45:18.035196 UTC] Computing input variables for policy optimization
[2019-11-19 11:45:18.207784 UTC] Performing policy update
[2019-11-19 11:45:18.210432 UTC] Computing gradient in Euclidean space
[2019-11-19 11:45:18.323751 UTC] Computing approximate natural gradient using conjugate gradient algorithm
[2019-11-19 11:45:19.722760 UTC] Performing line search
[2019-11-19 11:45:19.900729 UTC] Updating baseline
[2019-11-19 11:45:21.710503 UTC] Computing logging information
-------------------------------------
| Iteration            | 158        |
| ExpectedImprovement  | 0.013596   |
| ActualImprovement    | 0.01338    |
| ImprovementRatio     | 0.98411    |
| MeanKL               | 0.0071577  |
| Entropy              | 1.5144     |
| Perplexity           | 4.5468     |
| AveragePolicyStd     | 0.31398    |
| AveragePolicyStd[0]  | 0.36976    |
| AveragePolicyStd[1]  | 0.3503     |
| AveragePolicyStd[2]  | 0.28693    |
| AveragePolicyStd[3]  | 0.25518    |
| AveragePolicyStd[4]  | 0.29064    |
| AveragePolicyStd[5]  | 0.33108    |
| AverageReturn        | 480.37     |
| MinReturn            | 64.424     |
| MaxReturn            | 708.82     |
| StdReturn            | 252.77     |
| AverageEpisodeLength | 683.87     |
| MinEpisodeLength     | 91         |
| MaxEpisodeLength     | 1000       |
| StdEpisodeLength     | 368.52     |
| TotalNEpisodes       | 15843      |
| TotalNSamples        | 7.8881e+05 |
| ExplainedVariance    | 0.30453    |
-------------------------------------
[2019-11-19 11:45:22.914086 UTC] Saving snapshot
[2019-11-19 11:45:22.914773 UTC] Starting iteration 159
[2019-11-19 11:45:22.915437 UTC] Start collecting samples
[2019-11-19 11:45:26.240231 UTC] Computing input variables for policy optimization
[2019-11-19 11:45:26.306103 UTC] Performing policy update
[2019-11-19 11:45:26.310439 UTC] Computing gradient in Euclidean space
[2019-11-19 11:45:26.375969 UTC] Computing approximate natural gradient using conjugate gradient algorithm
[2019-11-19 11:45:27.081704 UTC] Performing line search
[2019-11-19 11:45:27.276438 UTC] Updating baseline
[2019-11-19 11:45:29.145202 UTC] Computing logging information
-------------------------------------
| Iteration            | 159        |
| ExpectedImprovement  | 0.011973   |
| ActualImprovement    | 0.011519   |
| ImprovementRatio     | 0.96204    |
| MeanKL               | 0.0079658  |
| Entropy              | 1.5306     |
| Perplexity           | 4.621      |
| AveragePolicyStd     | 0.31489    |
| AveragePolicyStd[0]  | 0.37138    |
| AveragePolicyStd[1]  | 0.35073    |
| AveragePolicyStd[2]  | 0.29021    |
| AveragePolicyStd[3]  | 0.25463    |
| AveragePolicyStd[4]  | 0.28933    |
| AveragePolicyStd[5]  | 0.33305    |
| AverageReturn        | 480.39     |
| MinReturn            | 64.424     |
| MaxReturn            | 708.82     |
| StdReturn            | 252.3      |
| AverageEpisodeLength | 683.78     |
| MinEpisodeLength     | 91         |
| MaxEpisodeLength     | 1000       |
| StdEpisodeLength     | 368.19     |
| TotalNEpisodes       | 15849      |
| TotalNSamples        | 7.9255e+05 |
| ExplainedVariance    | 0.54028    |
-------------------------------------
[2019-11-19 11:45:30.461736 UTC] Saving snapshot
[2019-11-19 11:45:30.462267 UTC] Starting iteration 160
[2019-11-19 11:45:30.463146 UTC] Start collecting samples
[2019-11-19 11:45:34.088456 UTC] Computing input variables for policy optimization
[2019-11-19 11:45:34.261103 UTC] Performing policy update
[2019-11-19 11:45:34.263779 UTC] Computing gradient in Euclidean space
[2019-11-19 11:45:34.390704 UTC] Computing approximate natural gradient using conjugate gradient algorithm
[2019-11-19 11:45:35.850889 UTC] Performing line search
[2019-11-19 11:45:36.030270 UTC] Updating baseline
[2019-11-19 11:45:38.024849 UTC] Computing logging information
-------------------------------------
| Iteration            | 160        |
| ExpectedImprovement  | 0.014232   |
| ActualImprovement    | 0.01375    |
| ImprovementRatio     | 0.96613    |
| MeanKL               | 0.0072038  |
| Entropy              | 1.55       |
| Perplexity           | 4.7117     |
| AveragePolicyStd     | 0.31588    |
| AveragePolicyStd[0]  | 0.37352    |
| AveragePolicyStd[1]  | 0.35035    |
| AveragePolicyStd[2]  | 0.28968    |
| AveragePolicyStd[3]  | 0.25519    |
| AveragePolicyStd[4]  | 0.29362    |
| AveragePolicyStd[5]  | 0.33295    |
| AverageReturn        | 499.09     |
| MinReturn            | 64.424     |
| MaxReturn            | 712.25     |
| StdReturn            | 246.08     |
| AverageEpisodeLength | 711.1      |
| MinEpisodeLength     | 91         |
| MaxEpisodeLength     | 1000       |
| StdEpisodeLength     | 357.72     |
| TotalNEpisodes       | 15857      |
| TotalNSamples        | 7.9998e+05 |
| ExplainedVariance    | 0.13397    |
-------------------------------------
[2019-11-19 11:45:39.330469 UTC] Saving snapshot
[2019-11-19 11:45:39.350797 UTC] Starting iteration 161
[2019-11-19 11:45:39.351919 UTC] Start collecting samples
[2019-11-19 11:45:42.408541 UTC] Computing input variables for policy optimization
[2019-11-19 11:45:42.566323 UTC] Performing policy update
[2019-11-19 11:45:42.570646 UTC] Computing gradient in Euclidean space
[2019-11-19 11:45:42.711482 UTC] Computing approximate natural gradient using conjugate gradient algorithm
[2019-11-19 11:45:44.765285 UTC] Performing line search
[2019-11-19 11:45:44.912723 UTC] Updating baseline
[2019-11-19 11:45:45.884009 UTC] Computing logging information
-------------------------------------
| Iteration            | 161        |
| ExpectedImprovement  | 0.011898   |
| ActualImprovement    | 0.011563   |
| ImprovementRatio     | 0.97187    |
| MeanKL               | 0.0075003  |
| Entropy              | 1.54       |
| Perplexity           | 4.6645     |
| AveragePolicyStd     | 0.31535    |
| AveragePolicyStd[0]  | 0.37525    |
| AveragePolicyStd[1]  | 0.34596    |
| AveragePolicyStd[2]  | 0.28807    |
| AveragePolicyStd[3]  | 0.25518    |
| AveragePolicyStd[4]  | 0.29456    |
| AveragePolicyStd[5]  | 0.33306    |
| AverageReturn        | 503.93     |
| MinReturn            | 64.424     |
| MaxReturn            | 712.25     |
| StdReturn            | 245.4      |
| AverageEpisodeLength | 718.13     |
| MinEpisodeLength     | 91         |
| MaxEpisodeLength     | 1000       |
| StdEpisodeLength     | 356.42     |
| TotalNEpisodes       | 15861      |
| TotalNSamples        | 8.0398e+05 |
| ExplainedVariance    | 0.16181    |
-------------------------------------
[2019-11-19 11:45:47.545809 UTC] Saving snapshot
[2019-11-19 11:45:47.546924 UTC] Starting iteration 162
[2019-11-19 11:45:47.547495 UTC] Start collecting samples
[2019-11-19 11:45:51.561714 UTC] Computing input variables for policy optimization
[2019-11-19 11:45:51.769186 UTC] Performing policy update
[2019-11-19 11:45:51.770333 UTC] Computing gradient in Euclidean space
[2019-11-19 11:45:51.894219 UTC] Computing approximate natural gradient using conjugate gradient algorithm
[2019-11-19 11:45:53.190582 UTC] Performing line search
[2019-11-19 11:45:53.385903 UTC] Updating baseline
[2019-11-19 11:45:55.145575 UTC] Computing logging information
-------------------------------------
| Iteration            | 162        |
| ExpectedImprovement  | 0.011686   |
| ActualImprovement    | 0.011338   |
| ImprovementRatio     | 0.97026    |
| MeanKL               | 0.0071879  |
| Entropy              | 1.556      |
| Perplexity           | 4.7399     |
| AveragePolicyStd     | 0.31618    |
| AveragePolicyStd[0]  | 0.37631    |
| AveragePolicyStd[1]  | 0.34652    |
| AveragePolicyStd[2]  | 0.28909    |
| AveragePolicyStd[3]  | 0.2572     |
| AveragePolicyStd[4]  | 0.29242    |
| AveragePolicyStd[5]  | 0.33555    |
| AverageReturn        | 504.78     |
| MinReturn            | 64.424     |
| MaxReturn            | 713.07     |
| StdReturn            | 245.18     |
| AverageEpisodeLength | 720.37     |
| MinEpisodeLength     | 91         |
| MaxEpisodeLength     | 1000       |
| StdEpisodeLength     | 354.62     |
| TotalNEpisodes       | 15866      |
| TotalNSamples        | 8.0784e+05 |
| ExplainedVariance    | 0.35279    |
-------------------------------------
[2019-11-19 11:45:56.495548 UTC] Saving snapshot
[2019-11-19 11:45:56.496061 UTC] Starting iteration 163
[2019-11-19 11:45:56.496623 UTC] Start collecting samples
[2019-11-19 11:45:59.666889 UTC] Computing input variables for policy optimization
[2019-11-19 11:45:59.845321 UTC] Performing policy update
[2019-11-19 11:45:59.847729 UTC] Computing gradient in Euclidean space
[2019-11-19 11:45:59.993524 UTC] Computing approximate natural gradient using conjugate gradient algorithm
[2019-11-19 11:46:01.267705 UTC] Performing line search
[2019-11-19 11:46:01.434987 UTC] Updating baseline
[2019-11-19 11:46:03.172394 UTC] Computing logging information
------------------------------------
| Iteration            | 163       |
| ExpectedImprovement  | 0.012097  |
| ActualImprovement    | 0.011392  |
| ImprovementRatio     | 0.94171   |
| MeanKL               | 0.0081262 |
| Entropy              | 1.528     |
| Perplexity           | 4.609     |
| AveragePolicyStd     | 0.31449   |
| AveragePolicyStd[0]  | 0.36761   |
| AveragePolicyStd[1]  | 0.3463    |
| AveragePolicyStd[2]  | 0.28903   |
| AveragePolicyStd[3]  | 0.25812   |
| AveragePolicyStd[4]  | 0.29006   |
| AveragePolicyStd[5]  | 0.33582   |
| AverageReturn        | 516.16    |
| MinReturn            | 64.424    |
| MaxReturn            | 713.07    |
| StdReturn            | 245.19    |
| AverageEpisodeLength | 735.65    |
| MinEpisodeLength     | 91        |
| MaxEpisodeLength     | 1000      |
| StdEpisodeLength     | 354.31    |
| TotalNEpisodes       | 15876     |
| TotalNSamples        | 8.163e+05 |
| ExplainedVariance    | 0.18316   |
------------------------------------
[2019-11-19 11:46:04.541796 UTC] Saving snapshot
[2019-11-19 11:46:04.542375 UTC] Starting iteration 164
[2019-11-19 11:46:04.543158 UTC] Start collecting samples
[2019-11-19 11:46:07.699383 UTC] Computing input variables for policy optimization
[2019-11-19 11:46:07.839700 UTC] Performing policy update
[2019-11-19 11:46:07.843119 UTC] Computing gradient in Euclidean space
[2019-11-19 11:46:07.961147 UTC] Computing approximate natural gradient using conjugate gradient algorithm
[2019-11-19 11:46:09.257114 UTC] Performing line search
[2019-11-19 11:46:09.420314 UTC] Updating baseline
[2019-11-19 11:46:10.899727 UTC] Computing logging information
-------------------------------------
| Iteration            | 164        |
| ExpectedImprovement  | 0.023355   |
| ActualImprovement    | 0.022433   |
| ImprovementRatio     | 0.9605     |
| MeanKL               | 0.0064915  |
| Entropy              | 1.5045     |
| Perplexity           | 4.502      |
| AveragePolicyStd     | 0.31333    |
| AveragePolicyStd[0]  | 0.36698    |
| AveragePolicyStd[1]  | 0.34407    |
| AveragePolicyStd[2]  | 0.29031    |
| AveragePolicyStd[3]  | 0.25347    |
| AveragePolicyStd[4]  | 0.29158    |
| AveragePolicyStd[5]  | 0.33354    |
| AverageReturn        | 504.24     |
| MinReturn            | 36.024     |
| MaxReturn            | 713.07     |
| StdReturn            | 250.94     |
| AverageEpisodeLength | 718.67     |
| MinEpisodeLength     | 73         |
| MaxEpisodeLength     | 1000       |
| StdEpisodeLength     | 361.75     |
| TotalNEpisodes       | 15883      |
| TotalNSamples        | 8.1948e+05 |
| ExplainedVariance    | 0.37125    |
-------------------------------------
[2019-11-19 11:46:12.074758 UTC] Saving snapshot
[2019-11-19 11:46:12.075481 UTC] Starting iteration 165
[2019-11-19 11:46:12.076634 UTC] Start collecting samples
[2019-11-19 11:46:15.255956 UTC] Computing input variables for policy optimization
[2019-11-19 11:46:15.420080 UTC] Performing policy update
[2019-11-19 11:46:15.431407 UTC] Computing gradient in Euclidean space
[2019-11-19 11:46:15.558446 UTC] Computing approximate natural gradient using conjugate gradient algorithm
[2019-11-19 11:46:16.231897 UTC] Performing line search
[2019-11-19 11:46:16.327914 UTC] Updating baseline
[2019-11-19 11:46:17.844576 UTC] Computing logging information
-------------------------------------
| Iteration            | 165        |
| ExpectedImprovement  | 0.011373   |
| ActualImprovement    | 0.01101    |
| ImprovementRatio     | 0.96809    |
| MeanKL               | 0.0087439  |
| Entropy              | 1.5093     |
| Perplexity           | 4.5235     |
| AveragePolicyStd     | 0.31347    |
| AveragePolicyStd[0]  | 0.36477    |
| AveragePolicyStd[1]  | 0.34256    |
| AveragePolicyStd[2]  | 0.2899     |
| AveragePolicyStd[3]  | 0.25471    |
| AveragePolicyStd[4]  | 0.29257    |
| AveragePolicyStd[5]  | 0.33632    |
| AverageReturn        | 512.7      |
| MinReturn            | 36.024     |
| MaxReturn            | 713.07     |
| StdReturn            | 249.98     |
| AverageEpisodeLength | 730.39     |
| MinEpisodeLength     | 73         |
| MaxEpisodeLength     | 1000       |
| StdEpisodeLength     | 359.6      |
| TotalNEpisodes       | 15888      |
| TotalNSamples        | 8.2368e+05 |
| ExplainedVariance    | 0.15269    |
-------------------------------------
[2019-11-19 11:46:19.209564 UTC] Saving snapshot
[2019-11-19 11:46:19.211358 UTC] Starting iteration 166
[2019-11-19 11:46:19.213324 UTC] Start collecting samples
[2019-11-19 11:46:22.864919 UTC] Computing input variables for policy optimization
[2019-11-19 11:46:22.981937 UTC] Performing policy update
[2019-11-19 11:46:22.984912 UTC] Computing gradient in Euclidean space
[2019-11-19 11:46:23.097019 UTC] Computing approximate natural gradient using conjugate gradient algorithm
[2019-11-19 11:46:24.294233 UTC] Performing line search
[2019-11-19 11:46:24.437670 UTC] Updating baseline
[2019-11-19 11:46:26.111749 UTC] Computing logging information
-------------------------------------
| Iteration            | 166        |
| ExpectedImprovement  | 0.01329    |
| ActualImprovement    | 0.011959   |
| ImprovementRatio     | 0.89986    |
| MeanKL               | 0.006777   |
| Entropy              | 1.5158     |
| Perplexity           | 4.5528     |
| AveragePolicyStd     | 0.31396    |
| AveragePolicyStd[0]  | 0.36649    |
| AveragePolicyStd[1]  | 0.34386    |
| AveragePolicyStd[2]  | 0.28792    |
| AveragePolicyStd[3]  | 0.25388    |
| AveragePolicyStd[4]  | 0.29263    |
| AveragePolicyStd[5]  | 0.33899    |
| AverageReturn        | 522.23     |
| MinReturn            | 36.024     |
| MaxReturn            | 713.07     |
| StdReturn            | 248.31     |
| AverageEpisodeLength | 743.63     |
| MinEpisodeLength     | 73         |
| MaxEpisodeLength     | 1000       |
| StdEpisodeLength     | 356.92     |
| TotalNEpisodes       | 15894      |
| TotalNSamples        | 8.2968e+05 |
| ExplainedVariance    | 0.15272    |
-------------------------------------
[2019-11-19 11:46:27.388385 UTC] Saving snapshot
[2019-11-19 11:46:27.388858 UTC] Starting iteration 167
[2019-11-19 11:46:27.389798 UTC] Start collecting samples
[2019-11-19 11:46:30.617388 UTC] Computing input variables for policy optimization
[2019-11-19 11:46:30.775428 UTC] Performing policy update
[2019-11-19 11:46:30.779822 UTC] Computing gradient in Euclidean space
[2019-11-19 11:46:30.971522 UTC] Computing approximate natural gradient using conjugate gradient algorithm
[2019-11-19 11:46:32.114629 UTC] Performing line search
[2019-11-19 11:46:32.263662 UTC] Updating baseline
[2019-11-19 11:46:34.180163 UTC] Computing logging information
-------------------------------------
| Iteration            | 167        |
| ExpectedImprovement  | 0.013271   |
| ActualImprovement    | 0.01144    |
| ImprovementRatio     | 0.86205    |
| MeanKL               | 0.007239   |
| Entropy              | 1.4847     |
| Perplexity           | 4.4136     |
| AveragePolicyStd     | 0.31247    |
| AveragePolicyStd[0]  | 0.36544    |
| AveragePolicyStd[1]  | 0.34245    |
| AveragePolicyStd[2]  | 0.28658    |
| AveragePolicyStd[3]  | 0.24893    |
| AveragePolicyStd[4]  | 0.29458    |
| AveragePolicyStd[5]  | 0.33685    |
| AverageReturn        | 532.63     |
| MinReturn            | 36.024     |
| MaxReturn            | 713.07     |
| StdReturn            | 245        |
| AverageEpisodeLength | 758.71     |
| MinEpisodeLength     | 73         |
| MaxEpisodeLength     | 1000       |
| StdEpisodeLength     | 351.76     |
| TotalNEpisodes       | 15900      |
| TotalNSamples        | 8.3434e+05 |
| ExplainedVariance    | 0.23342    |
-------------------------------------
[2019-11-19 11:46:35.646583 UTC] Saving snapshot
[2019-11-19 11:46:35.647675 UTC] Starting iteration 168
[2019-11-19 11:46:35.648654 UTC] Start collecting samples
[2019-11-19 11:46:39.497175 UTC] Computing input variables for policy optimization
[2019-11-19 11:46:39.663280 UTC] Performing policy update
[2019-11-19 11:46:39.665982 UTC] Computing gradient in Euclidean space
[2019-11-19 11:46:39.778332 UTC] Computing approximate natural gradient using conjugate gradient algorithm
[2019-11-19 11:46:41.206497 UTC] Performing line search
[2019-11-19 11:46:41.383092 UTC] Updating baseline
[2019-11-19 11:46:43.236761 UTC] Computing logging information
-------------------------------------
| Iteration            | 168        |
| ExpectedImprovement  | 0.019214   |
| ActualImprovement    | 0.017178   |
| ImprovementRatio     | 0.89399    |
| MeanKL               | 0.0066667  |
| Entropy              | 1.4693     |
| Perplexity           | 4.3461     |
| AveragePolicyStd     | 0.31179    |
| AveragePolicyStd[0]  | 0.36569    |
| AveragePolicyStd[1]  | 0.34052    |
| AveragePolicyStd[2]  | 0.2855     |
| AveragePolicyStd[3]  | 0.24656    |
| AveragePolicyStd[4]  | 0.29399    |
| AveragePolicyStd[5]  | 0.3385     |
| AverageReturn        | 538.98     |
| MinReturn            | 12.813     |
| MaxReturn            | 713.07     |
| StdReturn            | 243.23     |
| AverageEpisodeLength | 768.98     |
| MinEpisodeLength     | 33         |
| MaxEpisodeLength     | 1000       |
| StdEpisodeLength     | 346.68     |
| TotalNEpisodes       | 15908      |
| TotalNSamples        | 8.3943e+05 |
| ExplainedVariance    | 0.29801    |
-------------------------------------
[2019-11-19 11:46:45.115219 UTC] Saving snapshot
[2019-11-19 11:46:45.116554 UTC] Starting iteration 169
[2019-11-19 11:46:45.117442 UTC] Start collecting samples
[2019-11-19 11:46:49.479542 UTC] Computing input variables for policy optimization
[2019-11-19 11:46:49.705081 UTC] Performing policy update
[2019-11-19 11:46:49.708036 UTC] Computing gradient in Euclidean space
[2019-11-19 11:46:49.848812 UTC] Computing approximate natural gradient using conjugate gradient algorithm
[2019-11-19 11:46:50.908510 UTC] Performing line search
[2019-11-19 11:46:50.993613 UTC] Updating baseline
[2019-11-19 11:46:52.071091 UTC] Computing logging information
-------------------------------------
| Iteration            | 169        |
| ExpectedImprovement  | 0.016122   |
| ActualImprovement    | 0.012868   |
| ImprovementRatio     | 0.79815    |
| MeanKL               | 0.0066559  |
| Entropy              | 1.4579     |
| Perplexity           | 4.2968     |
| AveragePolicyStd     | 0.3111     |
| AveragePolicyStd[0]  | 0.36515    |
| AveragePolicyStd[1]  | 0.33775    |
| AveragePolicyStd[2]  | 0.28586    |
| AveragePolicyStd[3]  | 0.24745    |
| AveragePolicyStd[4]  | 0.29311    |
| AveragePolicyStd[5]  | 0.33727    |
| AverageReturn        | 547.83     |
| MinReturn            | 12.813     |
| MaxReturn            | 713.07     |
| StdReturn            | 238.08     |
| AverageEpisodeLength | 781.28     |
| MinEpisodeLength     | 33         |
| MaxEpisodeLength     | 1000       |
| StdEpisodeLength     | 338.86     |
| TotalNEpisodes       | 15912      |
| TotalNSamples        | 8.4312e+05 |
| ExplainedVariance    | 0.03102    |
-------------------------------------
[2019-11-19 11:46:53.612991 UTC] Saving snapshot
[2019-11-19 11:46:53.614047 UTC] Starting iteration 170
[2019-11-19 11:46:53.614949 UTC] Start collecting samples
[2019-11-19 11:46:57.393029 UTC] Computing input variables for policy optimization
[2019-11-19 11:46:57.574061 UTC] Performing policy update
[2019-11-19 11:46:57.575655 UTC] Computing gradient in Euclidean space
[2019-11-19 11:46:57.666666 UTC] Computing approximate natural gradient using conjugate gradient algorithm
[2019-11-19 11:46:59.040706 UTC] Performing line search
[2019-11-19 11:46:59.221319 UTC] Updating baseline
[2019-11-19 11:47:01.721361 UTC] Computing logging information
-------------------------------------
| Iteration            | 170        |
| ExpectedImprovement  | 0.011041   |
| ActualImprovement    | 0.011483   |
| ImprovementRatio     | 1.04       |
| MeanKL               | 0.0077673  |
| Entropy              | 1.4383     |
| Perplexity           | 4.2134     |
| AveragePolicyStd     | 0.31018    |
| AveragePolicyStd[0]  | 0.36313    |
| AveragePolicyStd[1]  | 0.33879    |
| AveragePolicyStd[2]  | 0.2858     |
| AveragePolicyStd[3]  | 0.24541    |
| AveragePolicyStd[4]  | 0.29006    |
| AveragePolicyStd[5]  | 0.3379     |
| AverageReturn        | 558.8      |
| MinReturn            | 12.813     |
| MaxReturn            | 715.78     |
| StdReturn            | 233.18     |
| AverageEpisodeLength | 796.7      |
| MinEpisodeLength     | 33         |
| MaxEpisodeLength     | 1000       |
| StdEpisodeLength     | 330.61     |
| TotalNEpisodes       | 15917      |
| TotalNSamples        | 8.4812e+05 |
| ExplainedVariance    | 0.04959    |
-------------------------------------
[2019-11-19 11:47:03.379679 UTC] Saving snapshot
[2019-11-19 11:47:03.399034 UTC] Starting iteration 171
[2019-11-19 11:47:03.399952 UTC] Start collecting samples
[2019-11-19 11:47:07.534583 UTC] Computing input variables for policy optimization
[2019-11-19 11:47:07.710010 UTC] Performing policy update
[2019-11-19 11:47:07.713170 UTC] Computing gradient in Euclidean space
[2019-11-19 11:47:07.795304 UTC] Computing approximate natural gradient using conjugate gradient algorithm
[2019-11-19 11:47:09.011383 UTC] Performing line search
[2019-11-19 11:47:09.149134 UTC] Updating baseline
[2019-11-19 11:47:11.105800 UTC] Computing logging information
-------------------------------------
| Iteration            | 171        |
| ExpectedImprovement  | 0.015001   |
| ActualImprovement    | 0.013913   |
| ImprovementRatio     | 0.92745    |
| MeanKL               | 0.0069874  |
| Entropy              | 1.4647     |
| Perplexity           | 4.3261     |
| AveragePolicyStd     | 0.3117     |
| AveragePolicyStd[0]  | 0.36538    |
| AveragePolicyStd[1]  | 0.34094    |
| AveragePolicyStd[2]  | 0.28719    |
| AveragePolicyStd[3]  | 0.24433    |
| AveragePolicyStd[4]  | 0.29099    |
| AveragePolicyStd[5]  | 0.34138    |
| AverageReturn        | 576.23     |
| MinReturn            | 12.813     |
| MaxReturn            | 715.78     |
| StdReturn            | 222.97     |
| AverageEpisodeLength | 821.61     |
| MinEpisodeLength     | 33         |
| MaxEpisodeLength     | 1000       |
| StdEpisodeLength     | 313.7      |
| TotalNEpisodes       | 15924      |
| TotalNSamples        | 8.5455e+05 |
| ExplainedVariance    | 0.064379   |
-------------------------------------
[2019-11-19 11:47:12.684369 UTC] Saving snapshot
[2019-11-19 11:47:12.685155 UTC] Starting iteration 172
[2019-11-19 11:47:12.686020 UTC] Start collecting samples
[2019-11-19 11:47:15.980717 UTC] Computing input variables for policy optimization
[2019-11-19 11:47:16.115319 UTC] Performing policy update
[2019-11-19 11:47:16.117006 UTC] Computing gradient in Euclidean space
[2019-11-19 11:47:16.218143 UTC] Computing approximate natural gradient using conjugate gradient algorithm
[2019-11-19 11:47:17.371051 UTC] Performing line search
[2019-11-19 11:47:17.495240 UTC] Updating baseline
[2019-11-19 11:47:18.876297 UTC] Computing logging information
-------------------------------------
| Iteration            | 172        |
| ExpectedImprovement  | 0.012406   |
| ActualImprovement    | 0.011831   |
| ImprovementRatio     | 0.95365    |
| MeanKL               | 0.0070714  |
| Entropy              | 1.4409     |
| Perplexity           | 4.2243     |
| AveragePolicyStd     | 0.31057    |
| AveragePolicyStd[0]  | 0.36446    |
| AveragePolicyStd[1]  | 0.34046    |
| AveragePolicyStd[2]  | 0.28462    |
| AveragePolicyStd[3]  | 0.24161    |
| AveragePolicyStd[4]  | 0.29206    |
| AveragePolicyStd[5]  | 0.34022    |
| AverageReturn        | 573.65     |
| MinReturn            | 12.813     |
| MaxReturn            | 715.82     |
| StdReturn            | 223.1      |
| AverageEpisodeLength | 818.58     |
| MinEpisodeLength     | 33         |
| MaxEpisodeLength     | 1000       |
| StdEpisodeLength     | 312.78     |
| TotalNEpisodes       | 15929      |
| TotalNSamples        | 8.5842e+05 |
| ExplainedVariance    | 0.44118    |
-------------------------------------
[2019-11-19 11:47:20.426611 UTC] Saving snapshot
[2019-11-19 11:47:20.427603 UTC] Starting iteration 173
[2019-11-19 11:47:20.428528 UTC] Start collecting samples
[2019-11-19 11:47:24.182356 UTC] Computing input variables for policy optimization
[2019-11-19 11:47:24.345458 UTC] Performing policy update
[2019-11-19 11:47:24.347033 UTC] Computing gradient in Euclidean space
[2019-11-19 11:47:24.456151 UTC] Computing approximate natural gradient using conjugate gradient algorithm
[2019-11-19 11:47:25.925061 UTC] Performing line search
[2019-11-19 11:47:26.060490 UTC] Updating baseline
[2019-11-19 11:47:27.881691 UTC] Computing logging information
-------------------------------------
| Iteration            | 173        |
| ExpectedImprovement  | 0.010525   |
| ActualImprovement    | 0.010477   |
| ImprovementRatio     | 0.99548    |
| MeanKL               | 0.0076055  |
| Entropy              | 1.4292     |
| Perplexity           | 4.1754     |
| AveragePolicyStd     | 0.30996    |
| AveragePolicyStd[0]  | 0.36052    |
| AveragePolicyStd[1]  | 0.34525    |
| AveragePolicyStd[2]  | 0.28762    |
| AveragePolicyStd[3]  | 0.24012    |
| AveragePolicyStd[4]  | 0.2895     |
| AveragePolicyStd[5]  | 0.33677    |
| AverageReturn        | 571.23     |
| MinReturn            | 12.813     |
| MaxReturn            | 715.82     |
| StdReturn            | 223.36     |
| AverageEpisodeLength | 815.47     |
| MinEpisodeLength     | 33         |
| MaxEpisodeLength     | 1000       |
| StdEpisodeLength     | 311.67     |
| TotalNEpisodes       | 15936      |
| TotalNSamples        | 8.6442e+05 |
| ExplainedVariance    | 0.29905    |
-------------------------------------
[2019-11-19 11:47:29.447537 UTC] Saving snapshot
[2019-11-19 11:47:29.448837 UTC] Starting iteration 174
[2019-11-19 11:47:29.449546 UTC] Start collecting samples
[2019-11-19 11:47:32.677803 UTC] Computing input variables for policy optimization
[2019-11-19 11:47:32.810837 UTC] Performing policy update
[2019-11-19 11:47:32.813300 UTC] Computing gradient in Euclidean space
[2019-11-19 11:47:32.926472 UTC] Computing approximate natural gradient using conjugate gradient algorithm
[2019-11-19 11:47:34.248691 UTC] Performing line search
[2019-11-19 11:47:34.445439 UTC] Updating baseline
[2019-11-19 11:47:36.610880 UTC] Computing logging information
------------------------------------
| Iteration            | 174       |
| ExpectedImprovement  | 0.010383  |
| ActualImprovement    | 0.01029   |
| ImprovementRatio     | 0.99104   |
| MeanKL               | 0.0080175 |
| Entropy              | 1.4038    |
| Perplexity           | 4.0708    |
| AveragePolicyStd     | 0.3087    |
| AveragePolicyStd[0]  | 0.35892   |
| AveragePolicyStd[1]  | 0.34015   |
| AveragePolicyStd[2]  | 0.28474   |
| AveragePolicyStd[3]  | 0.23909   |
| AveragePolicyStd[4]  | 0.28829   |
| AveragePolicyStd[5]  | 0.341     |
| AverageReturn        | 576.33    |
| MinReturn            | 12.813    |
| MaxReturn            | 715.82    |
| StdReturn            | 221       |
| AverageEpisodeLength | 821.88    |
| MinEpisodeLength     | 33        |
| MaxEpisodeLength     | 1000      |
| StdEpisodeLength     | 307.53    |
| TotalNEpisodes       | 15941     |
| TotalNSamples        | 8.69e+05  |
| ExplainedVariance    | 0.27258   |
------------------------------------
[2019-11-19 11:47:38.181534 UTC] Saving snapshot
[2019-11-19 11:47:38.182417 UTC] Starting iteration 175
[2019-11-19 11:47:38.183207 UTC] Start collecting samples
[2019-11-19 11:47:41.921406 UTC] Computing input variables for policy optimization
[2019-11-19 11:47:42.044656 UTC] Performing policy update
[2019-11-19 11:47:42.046489 UTC] Computing gradient in Euclidean space
[2019-11-19 11:47:42.163320 UTC] Computing approximate natural gradient using conjugate gradient algorithm
[2019-11-19 11:47:43.475403 UTC] Performing line search
[2019-11-19 11:47:43.637661 UTC] Updating baseline
[2019-11-19 11:47:45.515404 UTC] Computing logging information
-------------------------------------
| Iteration            | 175        |
| ExpectedImprovement  | 0.01033    |
| ActualImprovement    | 0.01014    |
| ImprovementRatio     | 0.98158    |
| MeanKL               | 0.0081013  |
| Entropy              | 1.4177     |
| Perplexity           | 4.1276     |
| AveragePolicyStd     | 0.30925    |
| AveragePolicyStd[0]  | 0.35782    |
| AveragePolicyStd[1]  | 0.33725    |
| AveragePolicyStd[2]  | 0.28426    |
| AveragePolicyStd[3]  | 0.24139    |
| AveragePolicyStd[4]  | 0.29117    |
| AveragePolicyStd[5]  | 0.34362    |
| AverageReturn        | 578.44     |
| MinReturn            | 12.813     |
| MaxReturn            | 716.41     |
| StdReturn            | 218.78     |
| AverageEpisodeLength | 825.84     |
| MinEpisodeLength     | 33         |
| MaxEpisodeLength     | 1000       |
| StdEpisodeLength     | 303.17     |
| TotalNEpisodes       | 15947      |
| TotalNSamples        | 8.7395e+05 |
| ExplainedVariance    | 0.30392    |
-------------------------------------
[2019-11-19 11:47:47.070721 UTC] Saving snapshot
[2019-11-19 11:47:47.072615 UTC] Starting iteration 176
[2019-11-19 11:47:47.074322 UTC] Start collecting samples
[2019-11-19 11:47:50.800074 UTC] Computing input variables for policy optimization
[2019-11-19 11:47:50.944799 UTC] Performing policy update
[2019-11-19 11:47:50.953988 UTC] Computing gradient in Euclidean space
[2019-11-19 11:47:51.052588 UTC] Computing approximate natural gradient using conjugate gradient algorithm
[2019-11-19 11:47:52.116298 UTC] Performing line search
[2019-11-19 11:47:52.258233 UTC] Updating baseline
[2019-11-19 11:47:53.621420 UTC] Computing logging information
-------------------------------------
| Iteration            | 176        |
| ExpectedImprovement  | 0.012876   |
| ActualImprovement    | 0.011993   |
| ImprovementRatio     | 0.93147    |
| MeanKL               | 0.0074291  |
| Entropy              | 1.4306     |
| Perplexity           | 4.1813     |
| AveragePolicyStd     | 0.30993    |
| AveragePolicyStd[0]  | 0.35969    |
| AveragePolicyStd[1]  | 0.33615    |
| AveragePolicyStd[2]  | 0.28311    |
| AveragePolicyStd[3]  | 0.24281    |
| AveragePolicyStd[4]  | 0.29175    |
| AveragePolicyStd[5]  | 0.34609    |
| AverageReturn        | 575.13     |
| MinReturn            | 12.813     |
| MaxReturn            | 716.41     |
| StdReturn            | 220.8      |
| AverageEpisodeLength | 821.97     |
| MinEpisodeLength     | 33         |
| MaxEpisodeLength     | 1000       |
| StdEpisodeLength     | 305.32     |
| TotalNEpisodes       | 15953      |
| TotalNSamples        | 8.7875e+05 |
| ExplainedVariance    | 0.12714    |
-------------------------------------
[2019-11-19 11:47:55.093443 UTC] Saving snapshot
[2019-11-19 11:47:55.094161 UTC] Starting iteration 177
[2019-11-19 11:47:55.095297 UTC] Start collecting samples
[2019-11-19 11:47:58.366418 UTC] Computing input variables for policy optimization
[2019-11-19 11:47:58.503583 UTC] Performing policy update
[2019-11-19 11:47:58.505346 UTC] Computing gradient in Euclidean space
[2019-11-19 11:47:58.642492 UTC] Computing approximate natural gradient using conjugate gradient algorithm
[2019-11-19 11:48:00.408902 UTC] Performing line search
[2019-11-19 11:48:00.588054 UTC] Updating baseline
[2019-11-19 11:48:02.691976 UTC] Computing logging information
-------------------------------------
| Iteration            | 177        |
| ExpectedImprovement  | 0.015258   |
| ActualImprovement    | 0.014078   |
| ImprovementRatio     | 0.92269    |
| MeanKL               | 0.0070152  |
| Entropy              | 1.4237     |
| Perplexity           | 4.1524     |
| AveragePolicyStd     | 0.30963    |
| AveragePolicyStd[0]  | 0.35785    |
| AveragePolicyStd[1]  | 0.33673    |
| AveragePolicyStd[2]  | 0.28271    |
| AveragePolicyStd[3]  | 0.24263    |
| AveragePolicyStd[4]  | 0.28912    |
| AveragePolicyStd[5]  | 0.34877    |
| AverageReturn        | 577.57     |
| MinReturn            | 12.813     |
| MaxReturn            | 716.41     |
| StdReturn            | 218.45     |
| AverageEpisodeLength | 824.7      |
| MinEpisodeLength     | 33         |
| MaxEpisodeLength     | 1000       |
| StdEpisodeLength     | 302.96     |
| TotalNEpisodes       | 15957      |
| TotalNSamples        | 8.8245e+05 |
| ExplainedVariance    | 0.15633    |
-------------------------------------
[2019-11-19 11:48:04.138764 UTC] Saving snapshot
[2019-11-19 11:48:04.139326 UTC] Starting iteration 178
[2019-11-19 11:48:04.140105 UTC] Start collecting samples
[2019-11-19 11:48:07.598268 UTC] Computing input variables for policy optimization
[2019-11-19 11:48:07.676202 UTC] Performing policy update
[2019-11-19 11:48:07.677508 UTC] Computing gradient in Euclidean space
[2019-11-19 11:48:07.750848 UTC] Computing approximate natural gradient using conjugate gradient algorithm
[2019-11-19 11:48:08.558243 UTC] Performing line search
[2019-11-19 11:48:08.650914 UTC] Updating baseline
[2019-11-19 11:48:10.104135 UTC] Computing logging information
-------------------------------------
| Iteration            | 178        |
| ExpectedImprovement  | 0.012702   |
| ActualImprovement    | 0.012064   |
| ImprovementRatio     | 0.94979    |
| MeanKL               | 0.00731    |
| Entropy              | 1.4193     |
| Perplexity           | 4.1342     |
| AveragePolicyStd     | 0.30936    |
| AveragePolicyStd[0]  | 0.3568     |
| AveragePolicyStd[1]  | 0.33437    |
| AveragePolicyStd[2]  | 0.28226    |
| AveragePolicyStd[3]  | 0.24334    |
| AveragePolicyStd[4]  | 0.28904    |
| AveragePolicyStd[5]  | 0.35035    |
| AverageReturn        | 579.03     |
| MinReturn            | 12.813     |
| MaxReturn            | 716.41     |
| StdReturn            | 217        |
| AverageEpisodeLength | 827.44     |
| MinEpisodeLength     | 33         |
| MaxEpisodeLength     | 1000       |
| StdEpisodeLength     | 302.69     |
| TotalNEpisodes       | 15965      |
| TotalNSamples        | 8.8958e+05 |
| ExplainedVariance    | 0.081842   |
-------------------------------------
[2019-11-19 11:48:11.501552 UTC] Saving snapshot
[2019-11-19 11:48:11.502369 UTC] Starting iteration 179
[2019-11-19 11:48:11.503290 UTC] Start collecting samples
[2019-11-19 11:48:15.133626 UTC] Computing input variables for policy optimization
[2019-11-19 11:48:15.290924 UTC] Performing policy update
[2019-11-19 11:48:15.293603 UTC] Computing gradient in Euclidean space
[2019-11-19 11:48:15.419476 UTC] Computing approximate natural gradient using conjugate gradient algorithm
[2019-11-19 11:48:16.669095 UTC] Performing line search
[2019-11-19 11:48:16.815143 UTC] Updating baseline
[2019-11-19 11:48:18.710757 UTC] Computing logging information
------------------------------------
| Iteration            | 179       |
| ExpectedImprovement  | 0.01223   |
| ActualImprovement    | 0.011717  |
| ImprovementRatio     | 0.95803   |
| MeanKL               | 0.0078003 |
| Entropy              | 1.406     |
| Perplexity           | 4.0797    |
| AveragePolicyStd     | 0.30875   |
| AveragePolicyStd[0]  | 0.35917   |
| AveragePolicyStd[1]  | 0.3306    |
| AveragePolicyStd[2]  | 0.2805    |
| AveragePolicyStd[3]  | 0.24256   |
| AveragePolicyStd[4]  | 0.28925   |
| AveragePolicyStd[5]  | 0.35042   |
| AverageReturn        | 575.39    |
| MinReturn            | 12.813    |
| MaxReturn            | 716.41    |
| StdReturn            | 217.77    |
| AverageEpisodeLength | 823.19    |
| MinEpisodeLength     | 33        |
| MaxEpisodeLength     | 1000      |
| StdEpisodeLength     | 302.01    |
| TotalNEpisodes       | 15972     |
| TotalNSamples        | 8.954e+05 |
| ExplainedVariance    | 0.25095   |
------------------------------------
[2019-11-19 11:48:20.257658 UTC] Saving snapshot
[2019-11-19 11:48:20.258307 UTC] Starting iteration 180
[2019-11-19 11:48:20.259125 UTC] Start collecting samples
[2019-11-19 11:48:23.891946 UTC] Computing input variables for policy optimization
[2019-11-19 11:48:24.031306 UTC] Performing policy update
[2019-11-19 11:48:24.032678 UTC] Computing gradient in Euclidean space
[2019-11-19 11:48:24.099448 UTC] Computing approximate natural gradient using conjugate gradient algorithm
[2019-11-19 11:48:24.896734 UTC] Performing line search
[2019-11-19 11:48:24.984336 UTC] Updating baseline
[2019-11-19 11:48:25.905516 UTC] Computing logging information
-------------------------------------
| Iteration            | 180        |
| ExpectedImprovement  | 0.015636   |
| ActualImprovement    | 0.013757   |
| ImprovementRatio     | 0.87983    |
| MeanKL               | 0.0067039  |
| Entropy              | 1.3877     |
| Perplexity           | 4.0058     |
| AveragePolicyStd     | 0.30793    |
| AveragePolicyStd[0]  | 0.35593    |
| AveragePolicyStd[1]  | 0.33175    |
| AveragePolicyStd[2]  | 0.28082    |
| AveragePolicyStd[3]  | 0.2389     |
| AveragePolicyStd[4]  | 0.28896    |
| AveragePolicyStd[5]  | 0.35126    |
| AverageReturn        | 577.35     |
| MinReturn            | 12.813     |
| MaxReturn            | 716.41     |
| StdReturn            | 212.2      |
| AverageEpisodeLength | 826.44     |
| MinEpisodeLength     | 33         |
| MaxEpisodeLength     | 1000       |
| StdEpisodeLength     | 294.49     |
| TotalNEpisodes       | 15979      |
| TotalNSamples        | 8.9953e+05 |
| ExplainedVariance    | 0.45175    |
-------------------------------------
[2019-11-19 11:48:27.770080 UTC] Saving snapshot
[2019-11-19 11:48:27.790095 UTC] Starting iteration 181
[2019-11-19 11:48:27.790819 UTC] Start collecting samples
[2019-11-19 11:48:32.399941 UTC] Computing input variables for policy optimization
[2019-11-19 11:48:32.574613 UTC] Performing policy update
[2019-11-19 11:48:32.577410 UTC] Computing gradient in Euclidean space
[2019-11-19 11:48:32.647351 UTC] Computing approximate natural gradient using conjugate gradient algorithm
[2019-11-19 11:48:33.412719 UTC] Performing line search
[2019-11-19 11:48:33.510466 UTC] Updating baseline
[2019-11-19 11:48:35.132880 UTC] Computing logging information
-------------------------------------
| Iteration            | 181        |
| ExpectedImprovement  | 0.015587   |
| ActualImprovement    | 0.014849   |
| ImprovementRatio     | 0.95262    |
| MeanKL               | 0.0067433  |
| Entropy              | 1.3775     |
| Perplexity           | 3.965      |
| AveragePolicyStd     | 0.30743    |
| AveragePolicyStd[0]  | 0.35797    |
| AveragePolicyStd[1]  | 0.33211    |
| AveragePolicyStd[2]  | 0.27815    |
| AveragePolicyStd[3]  | 0.23925    |
| AveragePolicyStd[4]  | 0.28887    |
| AveragePolicyStd[5]  | 0.34824    |
| AverageReturn        | 576.74     |
| MinReturn            | 12.813     |
| MaxReturn            | 718.52     |
| StdReturn            | 214.53     |
| AverageEpisodeLength | 825.1      |
| MinEpisodeLength     | 33         |
| MaxEpisodeLength     | 1000       |
| StdEpisodeLength     | 297.13     |
| TotalNEpisodes       | 15985      |
| TotalNSamples        | 9.0399e+05 |
| ExplainedVariance    | 0.21153    |
-------------------------------------
[2019-11-19 11:48:36.656250 UTC] Saving snapshot
[2019-11-19 11:48:36.657080 UTC] Starting iteration 182
[2019-11-19 11:48:36.658681 UTC] Start collecting samples
[2019-11-19 11:48:40.238890 UTC] Computing input variables for policy optimization
[2019-11-19 11:48:40.321869 UTC] Performing policy update
[2019-11-19 11:48:40.326518 UTC] Computing gradient in Euclidean space
[2019-11-19 11:48:40.386784 UTC] Computing approximate natural gradient using conjugate gradient algorithm
[2019-11-19 11:48:41.202710 UTC] Performing line search
[2019-11-19 11:48:41.371968 UTC] Updating baseline
[2019-11-19 11:48:42.838826 UTC] Computing logging information
------------------------------------
| Iteration            | 182       |
| ExpectedImprovement  | 0.014404  |
| ActualImprovement    | 0.012559  |
| ImprovementRatio     | 0.87189   |
| MeanKL               | 0.0075846 |
| Entropy              | 1.3902    |
| Perplexity           | 4.0156    |
| AveragePolicyStd     | 0.30785   |
| AveragePolicyStd[0]  | 0.35406   |
| AveragePolicyStd[1]  | 0.3318    |
| AveragePolicyStd[2]  | 0.2817    |
| AveragePolicyStd[3]  | 0.24063   |
| AveragePolicyStd[4]  | 0.2905    |
| AveragePolicyStd[5]  | 0.34841   |
| AverageReturn        | 577.34    |
| MinReturn            | 12.813    |
| MaxReturn            | 718.52    |
| StdReturn            | 213.69    |
| AverageEpisodeLength | 826.22    |
| MinEpisodeLength     | 33        |
| MaxEpisodeLength     | 1000      |
| StdEpisodeLength     | 294.98    |
| TotalNEpisodes       | 15991     |
| TotalNSamples        | 9.093e+05 |
| ExplainedVariance    | 0.24829   |
------------------------------------
[2019-11-19 11:48:44.666185 UTC] Saving snapshot
[2019-11-19 11:48:44.667155 UTC] Starting iteration 183
[2019-11-19 11:48:44.668193 UTC] Start collecting samples
[2019-11-19 11:48:48.421826 UTC] Computing input variables for policy optimization
[2019-11-19 11:48:48.681620 UTC] Performing policy update
[2019-11-19 11:48:48.685357 UTC] Computing gradient in Euclidean space
[2019-11-19 11:48:48.822721 UTC] Computing approximate natural gradient using conjugate gradient algorithm
[2019-11-19 11:48:50.286199 UTC] Performing line search
[2019-11-19 11:48:50.393222 UTC] Updating baseline
[2019-11-19 11:48:51.516073 UTC] Computing logging information
-------------------------------------
| Iteration            | 183        |
| ExpectedImprovement  | 0.014522   |
| ActualImprovement    | 0.01366    |
| ImprovementRatio     | 0.94063    |
| MeanKL               | 0.0073397  |
| Entropy              | 1.3779     |
| Perplexity           | 3.9665     |
| AveragePolicyStd     | 0.30717    |
| AveragePolicyStd[0]  | 0.35399    |
| AveragePolicyStd[1]  | 0.32749    |
| AveragePolicyStd[2]  | 0.28301    |
| AveragePolicyStd[3]  | 0.24065    |
| AveragePolicyStd[4]  | 0.28904    |
| AveragePolicyStd[5]  | 0.34886    |
| AverageReturn        | 570.03     |
| MinReturn            | 12.813     |
| MaxReturn            | 718.52     |
| StdReturn            | 217.32     |
| AverageEpisodeLength | 819.29     |
| MinEpisodeLength     | 33         |
| MaxEpisodeLength     | 1000       |
| StdEpisodeLength     | 301.07     |
| TotalNEpisodes       | 15999      |
| TotalNSamples        | 9.1527e+05 |
| ExplainedVariance    | 0.38728    |
-------------------------------------
[2019-11-19 11:48:53.823754 UTC] Saving snapshot
[2019-11-19 11:48:53.824719 UTC] Starting iteration 184
[2019-11-19 11:48:53.825791 UTC] Start collecting samples
[2019-11-19 11:48:58.269412 UTC] Computing input variables for policy optimization
[2019-11-19 11:48:58.432909 UTC] Performing policy update
[2019-11-19 11:48:58.436651 UTC] Computing gradient in Euclidean space
[2019-11-19 11:48:58.573232 UTC] Computing approximate natural gradient using conjugate gradient algorithm
[2019-11-19 11:49:00.553892 UTC] Performing line search
[2019-11-19 11:49:00.759931 UTC] Updating baseline
[2019-11-19 11:49:02.838892 UTC] Computing logging information
-------------------------------------
| Iteration            | 184        |
| ExpectedImprovement  | 0.019901   |
| ActualImprovement    | 0.017449   |
| ImprovementRatio     | 0.87682    |
| MeanKL               | 0.0065283  |
| Entropy              | 1.3753     |
| Perplexity           | 3.9563     |
| AveragePolicyStd     | 0.30707    |
| AveragePolicyStd[0]  | 0.3552     |
| AveragePolicyStd[1]  | 0.3287     |
| AveragePolicyStd[2]  | 0.28242    |
| AveragePolicyStd[3]  | 0.23965    |
| AveragePolicyStd[4]  | 0.2903     |
| AveragePolicyStd[5]  | 0.34616    |
| AverageReturn        | 566.21     |
| MinReturn            | 12.992     |
| MaxReturn            | 718.52     |
| StdReturn            | 219.02     |
| AverageEpisodeLength | 813.88     |
| MinEpisodeLength     | 34         |
| MaxEpisodeLength     | 1000       |
| StdEpisodeLength     | 305.19     |
| TotalNEpisodes       | 16007      |
| TotalNSamples        | 9.1982e+05 |
| ExplainedVariance    | 0.44417    |
-------------------------------------
[2019-11-19 11:49:04.451468 UTC] Saving snapshot
[2019-11-19 11:49:04.452173 UTC] Starting iteration 185
[2019-11-19 11:49:04.453376 UTC] Start collecting samples
[2019-11-19 11:49:08.202025 UTC] Computing input variables for policy optimization
[2019-11-19 11:49:08.385858 UTC] Performing policy update
[2019-11-19 11:49:08.387512 UTC] Computing gradient in Euclidean space
[2019-11-19 11:49:08.448373 UTC] Computing approximate natural gradient using conjugate gradient algorithm
[2019-11-19 11:49:09.297261 UTC] Performing line search
[2019-11-19 11:49:09.410431 UTC] Updating baseline
[2019-11-19 11:49:10.869388 UTC] Computing logging information
------------------------------------
| Iteration            | 185       |
| ExpectedImprovement  | 0.01307   |
| ActualImprovement    | 0.012631  |
| ImprovementRatio     | 0.96641   |
| MeanKL               | 0.0070648 |
| Entropy              | 1.3477    |
| Perplexity           | 3.8486    |
| AveragePolicyStd     | 0.30565   |
| AveragePolicyStd[0]  | 0.35341   |
| AveragePolicyStd[1]  | 0.3286    |
| AveragePolicyStd[2]  | 0.27888   |
| AveragePolicyStd[3]  | 0.23928   |
| AveragePolicyStd[4]  | 0.28985   |
| AveragePolicyStd[5]  | 0.34391   |
| AverageReturn        | 563.71    |
| MinReturn            | 12.992    |
| MaxReturn            | 718.52    |
| StdReturn            | 220.86    |
| AverageEpisodeLength | 810.78    |
| MinEpisodeLength     | 34        |
| MaxEpisodeLength     | 1000      |
| StdEpisodeLength     | 307.96    |
| TotalNEpisodes       | 16013     |
| TotalNSamples        | 9.252e+05 |
| ExplainedVariance    | 0.15666   |
------------------------------------
[2019-11-19 11:49:12.499730 UTC] Saving snapshot
[2019-11-19 11:49:12.506183 UTC] Starting iteration 186
[2019-11-19 11:49:12.510045 UTC] Start collecting samples
[2019-11-19 11:49:16.172749 UTC] Computing input variables for policy optimization
[2019-11-19 11:49:16.389912 UTC] Performing policy update
[2019-11-19 11:49:16.394052 UTC] Computing gradient in Euclidean space
[2019-11-19 11:49:16.502388 UTC] Computing approximate natural gradient using conjugate gradient algorithm
[2019-11-19 11:49:17.874958 UTC] Performing line search
[2019-11-19 11:49:18.043969 UTC] Updating baseline
[2019-11-19 11:49:19.923548 UTC] Computing logging information
-------------------------------------
| Iteration            | 186        |
| ExpectedImprovement  | 0.014387   |
| ActualImprovement    | 0.013064   |
| ImprovementRatio     | 0.90807    |
| MeanKL               | 0.0071287  |
| Entropy              | 1.3447     |
| Perplexity           | 3.8371     |
| AveragePolicyStd     | 0.30574    |
| AveragePolicyStd[0]  | 0.35535    |
| AveragePolicyStd[1]  | 0.32966    |
| AveragePolicyStd[2]  | 0.27604    |
| AveragePolicyStd[3]  | 0.23702    |
| AveragePolicyStd[4]  | 0.29063    |
| AveragePolicyStd[5]  | 0.34576    |
| AverageReturn        | 552.01     |
| MinReturn            | 12.992     |
| MaxReturn            | 718.52     |
| StdReturn            | 228.74     |
| AverageEpisodeLength | 794.09     |
| MinEpisodeLength     | 34         |
| MaxEpisodeLength     | 1000       |
| StdEpisodeLength     | 319.99     |
| TotalNEpisodes       | 16017      |
| TotalNSamples        | 9.2753e+05 |
| ExplainedVariance    | 0.46023    |
-------------------------------------
[2019-11-19 11:49:21.299431 UTC] Saving snapshot
[2019-11-19 11:49:21.300241 UTC] Starting iteration 187
[2019-11-19 11:49:21.301050 UTC] Start collecting samples
[2019-11-19 11:49:25.059293 UTC] Computing input variables for policy optimization
[2019-11-19 11:49:25.264592 UTC] Performing policy update
[2019-11-19 11:49:25.268721 UTC] Computing gradient in Euclidean space
[2019-11-19 11:49:25.453480 UTC] Computing approximate natural gradient using conjugate gradient algorithm
[2019-11-19 11:49:26.501966 UTC] Performing line search
[2019-11-19 11:49:26.690831 UTC] Updating baseline
[2019-11-19 11:49:28.206783 UTC] Computing logging information
-------------------------------------
| Iteration            | 187        |
| ExpectedImprovement  | 0.01206    |
| ActualImprovement    | 0.011278   |
| ImprovementRatio     | 0.93519    |
| MeanKL               | 0.0074424  |
| Entropy              | 1.3437     |
| Perplexity           | 3.8334     |
| AveragePolicyStd     | 0.30576    |
| AveragePolicyStd[0]  | 0.35635    |
| AveragePolicyStd[1]  | 0.32865    |
| AveragePolicyStd[2]  | 0.27759    |
| AveragePolicyStd[3]  | 0.23583    |
| AveragePolicyStd[4]  | 0.28969    |
| AveragePolicyStd[5]  | 0.34643    |
| AverageReturn        | 547.32     |
| MinReturn            | 12.992     |
| MaxReturn            | 718.52     |
| StdReturn            | 230.87     |
| AverageEpisodeLength | 787.04     |
| MinEpisodeLength     | 34         |
| MaxEpisodeLength     | 1000       |
| StdEpisodeLength     | 322.81     |
| TotalNEpisodes       | 16028      |
| TotalNSamples        | 9.3612e+05 |
| ExplainedVariance    | 0.33968    |
-------------------------------------
[2019-11-19 11:49:29.535658 UTC] Saving snapshot
[2019-11-19 11:49:29.536288 UTC] Starting iteration 188
[2019-11-19 11:49:29.536871 UTC] Start collecting samples
[2019-11-19 11:49:33.659230 UTC] Computing input variables for policy optimization
[2019-11-19 11:49:33.822474 UTC] Performing policy update
[2019-11-19 11:49:33.825076 UTC] Computing gradient in Euclidean space
[2019-11-19 11:49:33.961298 UTC] Computing approximate natural gradient using conjugate gradient algorithm
[2019-11-19 11:49:35.186856 UTC] Performing line search
[2019-11-19 11:49:35.280548 UTC] Updating baseline
[2019-11-19 11:49:36.451383 UTC] Computing logging information
-------------------------------------
| Iteration            | 188        |
| ExpectedImprovement  | 0.011905   |
| ActualImprovement    | 0.011614   |
| ImprovementRatio     | 0.97554    |
| MeanKL               | 0.0072672  |
| Entropy              | 1.3388     |
| Perplexity           | 3.8146     |
| AveragePolicyStd     | 0.30537    |
| AveragePolicyStd[0]  | 0.35501    |
| AveragePolicyStd[1]  | 0.33046    |
| AveragePolicyStd[2]  | 0.27855    |
| AveragePolicyStd[3]  | 0.23767    |
| AveragePolicyStd[4]  | 0.28676    |
| AveragePolicyStd[5]  | 0.34377    |
| AverageReturn        | 541.39     |
| MinReturn            | 12.992     |
| MaxReturn            | 718.52     |
| StdReturn            | 234.02     |
| AverageEpisodeLength | 778.62     |
| MinEpisodeLength     | 34         |
| MaxEpisodeLength     | 1000       |
| StdEpisodeLength     | 328.08     |
| TotalNEpisodes       | 16030      |
| TotalNSamples        | 9.3728e+05 |
| ExplainedVariance    | 0.58076    |
-------------------------------------
[2019-11-19 11:49:37.915636 UTC] Saving snapshot
[2019-11-19 11:49:37.916790 UTC] Starting iteration 189
[2019-11-19 11:49:37.917762 UTC] Start collecting samples
[2019-11-19 11:49:43.897379 UTC] Computing input variables for policy optimization
[2019-11-19 11:49:44.159694 UTC] Performing policy update
[2019-11-19 11:49:44.164656 UTC] Computing gradient in Euclidean space
[2019-11-19 11:49:44.492362 UTC] Computing approximate natural gradient using conjugate gradient algorithm
[2019-11-19 11:49:46.608627 UTC] Performing line search
[2019-11-19 11:49:46.838758 UTC] Updating baseline
[2019-11-19 11:49:49.932829 UTC] Computing logging information
-------------------------------------
| Iteration            | 189        |
| ExpectedImprovement  | 0.013051   |
| ActualImprovement    | 0.012392   |
| ImprovementRatio     | 0.9495     |
| MeanKL               | 0.0068705  |
| Entropy              | 1.3315     |
| Perplexity           | 3.7868     |
| AveragePolicyStd     | 0.30487    |
| AveragePolicyStd[0]  | 0.35421    |
| AveragePolicyStd[1]  | 0.32584    |
| AveragePolicyStd[2]  | 0.27863    |
| AveragePolicyStd[3]  | 0.23891    |
| AveragePolicyStd[4]  | 0.28729    |
| AveragePolicyStd[5]  | 0.34434    |
| AverageReturn        | 543.22     |
| MinReturn            | 12.992     |
| MaxReturn            | 718.52     |
| StdReturn            | 232.59     |
| AverageEpisodeLength | 782.12     |
| MinEpisodeLength     | 34         |
| MaxEpisodeLength     | 1000       |
| StdEpisodeLength     | 326.12     |
| TotalNEpisodes       | 16037      |
| TotalNSamples        | 9.4364e+05 |
| ExplainedVariance    | 0.35151    |
-------------------------------------
[2019-11-19 11:49:51.380492 UTC] Saving snapshot
[2019-11-19 11:49:51.381412 UTC] Starting iteration 190
[2019-11-19 11:49:51.382437 UTC] Start collecting samples
[2019-11-19 11:49:56.341694 UTC] Computing input variables for policy optimization
[2019-11-19 11:49:56.641057 UTC] Performing policy update
[2019-11-19 11:49:56.648052 UTC] Computing gradient in Euclidean space
[2019-11-19 11:49:56.800357 UTC] Computing approximate natural gradient using conjugate gradient algorithm
[2019-11-19 11:49:59.016303 UTC] Performing line search
[2019-11-19 11:49:59.282723 UTC] Updating baseline
[2019-11-19 11:50:02.515614 UTC] Computing logging information
-------------------------------------
| Iteration            | 190        |
| ExpectedImprovement  | 0.011143   |
| ActualImprovement    | 0.010829   |
| ImprovementRatio     | 0.97184    |
| MeanKL               | 0.0084263  |
| Entropy              | 1.3097     |
| Perplexity           | 3.7052     |
| AveragePolicyStd     | 0.30365    |
| AveragePolicyStd[0]  | 0.34925    |
| AveragePolicyStd[1]  | 0.32553    |
| AveragePolicyStd[2]  | 0.27629    |
| AveragePolicyStd[3]  | 0.23957    |
| AveragePolicyStd[4]  | 0.28733    |
| AveragePolicyStd[5]  | 0.34395    |
| AverageReturn        | 540.89     |
| MinReturn            | 12.992     |
| MaxReturn            | 718.52     |
| StdReturn            | 234.62     |
| AverageEpisodeLength | 778.2      |
| MinEpisodeLength     | 34         |
| MaxEpisodeLength     | 1000       |
| StdEpisodeLength     | 329.35     |
| TotalNEpisodes       | 16046      |
| TotalNSamples        | 9.5077e+05 |
| ExplainedVariance    | 0.33136    |
-------------------------------------
[2019-11-19 11:50:03.877218 UTC] Saving snapshot
[2019-11-19 11:50:03.894310 UTC] Starting iteration 191
[2019-11-19 11:50:03.895313 UTC] Start collecting samples
[2019-11-19 11:50:08.650120 UTC] Computing input variables for policy optimization
[2019-11-19 11:50:08.845479 UTC] Performing policy update
[2019-11-19 11:50:08.847658 UTC] Computing gradient in Euclidean space
[2019-11-19 11:50:08.981418 UTC] Computing approximate natural gradient using conjugate gradient algorithm
[2019-11-19 11:50:10.964364 UTC] Performing line search
[2019-11-19 11:50:11.180781 UTC] Updating baseline
[2019-11-19 11:50:13.820512 UTC] Computing logging information
-------------------------------------
| Iteration            | 191        |
| ExpectedImprovement  | 0.01305    |
| ActualImprovement    | 0.012922   |
| ImprovementRatio     | 0.99022    |
| MeanKL               | 0.0077488  |
| Entropy              | 1.337      |
| Perplexity           | 3.8077     |
| AveragePolicyStd     | 0.3051     |
| AveragePolicyStd[0]  | 0.35305    |
| AveragePolicyStd[1]  | 0.32799    |
| AveragePolicyStd[2]  | 0.27801    |
| AveragePolicyStd[3]  | 0.24126    |
| AveragePolicyStd[4]  | 0.28487    |
| AveragePolicyStd[5]  | 0.34542    |
| AverageReturn        | 539.79     |
| MinReturn            | 12.992     |
| MaxReturn            | 718.52     |
| StdReturn            | 235.66     |
| AverageEpisodeLength | 776.16     |
| MinEpisodeLength     | 34         |
| MaxEpisodeLength     | 1000       |
| StdEpisodeLength     | 330.32     |
| TotalNEpisodes       | 16049      |
| TotalNSamples        | 9.5328e+05 |
| ExplainedVariance    | 0.45208    |
-------------------------------------
[2019-11-19 11:50:15.155213 UTC] Saving snapshot
[2019-11-19 11:50:15.156207 UTC] Starting iteration 192
[2019-11-19 11:50:15.157035 UTC] Start collecting samples
[2019-11-19 11:50:19.669323 UTC] Computing input variables for policy optimization
[2019-11-19 11:50:19.917974 UTC] Performing policy update
[2019-11-19 11:50:19.925444 UTC] Computing gradient in Euclidean space
[2019-11-19 11:50:20.131793 UTC] Computing approximate natural gradient using conjugate gradient algorithm
[2019-11-19 11:50:22.133676 UTC] Performing line search
[2019-11-19 11:50:22.363400 UTC] Updating baseline
[2019-11-19 11:50:25.354216 UTC] Computing logging information
-------------------------------------
| Iteration            | 192        |
| ExpectedImprovement  | 0.01119    |
| ActualImprovement    | 0.010876   |
| ImprovementRatio     | 0.97196    |
| MeanKL               | 0.0071374  |
| Entropy              | 1.3628     |
| Perplexity           | 3.907      |
| AveragePolicyStd     | 0.30642    |
| AveragePolicyStd[0]  | 0.35339    |
| AveragePolicyStd[1]  | 0.32971    |
| AveragePolicyStd[2]  | 0.28048    |
| AveragePolicyStd[3]  | 0.24172    |
| AveragePolicyStd[4]  | 0.28543    |
| AveragePolicyStd[5]  | 0.34779    |
| AverageReturn        | 529.59     |
| MinReturn            | 12.992     |
| MaxReturn            | 718.52     |
| StdReturn            | 234.71     |
| AverageEpisodeLength | 764.29     |
| MinEpisodeLength     | 34         |
| MaxEpisodeLength     | 1000       |
| StdEpisodeLength     | 327.7      |
| TotalNEpisodes       | 16060      |
| TotalNSamples        | 9.6114e+05 |
| ExplainedVariance    | 0.42051    |
-------------------------------------
[2019-11-19 11:50:26.760943 UTC] Saving snapshot
[2019-11-19 11:50:26.761411 UTC] Starting iteration 193
[2019-11-19 11:50:26.762179 UTC] Start collecting samples
[2019-11-19 11:50:32.577354 UTC] Computing input variables for policy optimization
[2019-11-19 11:50:32.804652 UTC] Performing policy update
[2019-11-19 11:50:32.809781 UTC] Computing gradient in Euclidean space
[2019-11-19 11:50:32.938464 UTC] Computing approximate natural gradient using conjugate gradient algorithm
[2019-11-19 11:50:35.108701 UTC] Performing line search
[2019-11-19 11:50:35.319625 UTC] Updating baseline
[2019-11-19 11:50:38.144260 UTC] Computing logging information
-------------------------------------
| Iteration            | 193        |
| ExpectedImprovement  | 0.013244   |
| ActualImprovement    | 0.012574   |
| ImprovementRatio     | 0.94938    |
| MeanKL               | 0.0073203  |
| Entropy              | 1.3639     |
| Perplexity           | 3.9113     |
| AveragePolicyStd     | 0.30644    |
| AveragePolicyStd[0]  | 0.35368    |
| AveragePolicyStd[1]  | 0.33249    |
| AveragePolicyStd[2]  | 0.2784     |
| AveragePolicyStd[3]  | 0.2427     |
| AveragePolicyStd[4]  | 0.28644    |
| AveragePolicyStd[5]  | 0.34494    |
| AverageReturn        | 520.55     |
| MinReturn            | 12.992     |
| MaxReturn            | 722.83     |
| StdReturn            | 237.26     |
| AverageEpisodeLength | 751.64     |
| MinEpisodeLength     | 34         |
| MaxEpisodeLength     | 1000       |
| StdEpisodeLength     | 331.4      |
| TotalNEpisodes       | 16065      |
| TotalNSamples        | 9.6475e+05 |
| ExplainedVariance    | 0.45615    |
-------------------------------------
[2019-11-19 11:50:39.560383 UTC] Saving snapshot
[2019-11-19 11:50:39.561142 UTC] Starting iteration 194
[2019-11-19 11:50:39.562164 UTC] Start collecting samples
[2019-11-19 11:50:44.534369 UTC] Computing input variables for policy optimization
[2019-11-19 11:50:44.733771 UTC] Performing policy update
[2019-11-19 11:50:44.747922 UTC] Computing gradient in Euclidean space
[2019-11-19 11:50:44.902713 UTC] Computing approximate natural gradient using conjugate gradient algorithm
[2019-11-19 11:50:46.740390 UTC] Performing line search
[2019-11-19 11:50:46.988369 UTC] Updating baseline
[2019-11-19 11:50:50.018391 UTC] Computing logging information
-------------------------------------
| Iteration            | 194        |
| ExpectedImprovement  | 0.013686   |
| ActualImprovement    | 0.012738   |
| ImprovementRatio     | 0.93069    |
| MeanKL               | 0.0070663  |
| Entropy              | 1.3503     |
| Perplexity           | 3.8585     |
| AveragePolicyStd     | 0.30575    |
| AveragePolicyStd[0]  | 0.3509     |
| AveragePolicyStd[1]  | 0.33146    |
| AveragePolicyStd[2]  | 0.27639    |
| AveragePolicyStd[3]  | 0.24372    |
| AveragePolicyStd[4]  | 0.28407    |
| AveragePolicyStd[5]  | 0.34798    |
| AverageReturn        | 518.84     |
| MinReturn            | 12.992     |
| MaxReturn            | 722.83     |
| StdReturn            | 240.79     |
| AverageEpisodeLength | 748.37     |
| MinEpisodeLength     | 34         |
| MaxEpisodeLength     | 1000       |
| StdEpisodeLength     | 336.67     |
| TotalNEpisodes       | 16069      |
| TotalNSamples        | 9.6782e+05 |
| ExplainedVariance    | 0.02967    |
-------------------------------------
[2019-11-19 11:50:51.607417 UTC] Saving snapshot
[2019-11-19 11:50:51.608723 UTC] Starting iteration 195
[2019-11-19 11:50:51.610255 UTC] Start collecting samples
[2019-11-19 11:50:57.002772 UTC] Computing input variables for policy optimization
[2019-11-19 11:50:57.213449 UTC] Performing policy update
[2019-11-19 11:50:57.222959 UTC] Computing gradient in Euclidean space
[2019-11-19 11:50:57.371298 UTC] Computing approximate natural gradient using conjugate gradient algorithm
[2019-11-19 11:50:59.406642 UTC] Performing line search
[2019-11-19 11:50:59.679086 UTC] Updating baseline
[2019-11-19 11:51:02.161616 UTC] Computing logging information
-------------------------------------
| Iteration            | 195        |
| ExpectedImprovement  | 0.01337    |
| ActualImprovement    | 0.012695   |
| ImprovementRatio     | 0.94951    |
| MeanKL               | 0.0078784  |
| Entropy              | 1.3472     |
| Perplexity           | 3.8465     |
| AveragePolicyStd     | 0.30558    |
| AveragePolicyStd[0]  | 0.35185    |
| AveragePolicyStd[1]  | 0.33178    |
| AveragePolicyStd[2]  | 0.27724    |
| AveragePolicyStd[3]  | 0.24331    |
| AveragePolicyStd[4]  | 0.28367    |
| AveragePolicyStd[5]  | 0.34563    |
| AverageReturn        | 534.16     |
| MinReturn            | 12.992     |
| MaxReturn            | 722.83     |
| StdReturn            | 236.13     |
| AverageEpisodeLength | 769.95     |
| MinEpisodeLength     | 34         |
| MaxEpisodeLength     | 1000       |
| StdEpisodeLength     | 328.54     |
| TotalNEpisodes       | 16074      |
| TotalNSamples        | 9.7282e+05 |
| ExplainedVariance    | 0.031546   |
-------------------------------------
[2019-11-19 11:51:03.729672 UTC] Saving snapshot
[2019-11-19 11:51:03.731098 UTC] Starting iteration 196
[2019-11-19 11:51:03.732665 UTC] Start collecting samples
[2019-11-19 11:51:08.992676 UTC] Computing input variables for policy optimization
[2019-11-19 11:51:09.315860 UTC] Performing policy update
[2019-11-19 11:51:09.321692 UTC] Computing gradient in Euclidean space
[2019-11-19 11:51:09.538308 UTC] Computing approximate natural gradient using conjugate gradient algorithm
[2019-11-19 11:51:11.717919 UTC] Performing line search
[2019-11-19 11:51:11.977957 UTC] Updating baseline
[2019-11-19 11:51:16.405090 UTC] Computing logging information
-------------------------------------
| Iteration            | 196        |
| ExpectedImprovement  | 0.011666   |
| ActualImprovement    | 0.011221   |
| ImprovementRatio     | 0.96182    |
| MeanKL               | 0.0073011  |
| Entropy              | 1.3214     |
| Perplexity           | 3.7487     |
| AveragePolicyStd     | 0.30443    |
| AveragePolicyStd[0]  | 0.34945    |
| AveragePolicyStd[1]  | 0.33364    |
| AveragePolicyStd[2]  | 0.27542    |
| AveragePolicyStd[3]  | 0.24154    |
| AveragePolicyStd[4]  | 0.27967    |
| AveragePolicyStd[5]  | 0.34686    |
| AverageReturn        | 547.32     |
| MinReturn            | 12.992     |
| MaxReturn            | 722.83     |
| StdReturn            | 227.59     |
| AverageEpisodeLength | 788.59     |
| MinEpisodeLength     | 34         |
| MaxEpisodeLength     | 1000       |
| StdEpisodeLength     | 315.41     |
| TotalNEpisodes       | 16083      |
| TotalNSamples        | 9.8085e+05 |
| ExplainedVariance    | 0.16854    |
-------------------------------------
[2019-11-19 11:51:18.105723 UTC] Saving snapshot
[2019-11-19 11:51:18.107210 UTC] Starting iteration 197
[2019-11-19 11:51:18.108990 UTC] Start collecting samples
[2019-11-19 11:51:23.567263 UTC] Computing input variables for policy optimization
[2019-11-19 11:51:23.816380 UTC] Performing policy update
[2019-11-19 11:51:23.818036 UTC] Computing gradient in Euclidean space
[2019-11-19 11:51:23.989514 UTC] Computing approximate natural gradient using conjugate gradient algorithm
[2019-11-19 11:51:26.174360 UTC] Performing line search
[2019-11-19 11:51:26.491659 UTC] Updating baseline
[2019-11-19 11:51:29.014164 UTC] Computing logging information
-------------------------------------
| Iteration            | 197        |
| ExpectedImprovement  | 0.013429   |
| ActualImprovement    | 0.012855   |
| ImprovementRatio     | 0.95721    |
| MeanKL               | 0.007058   |
| Entropy              | 1.3036     |
| Perplexity           | 3.6827     |
| AveragePolicyStd     | 0.30353    |
| AveragePolicyStd[0]  | 0.34814    |
| AveragePolicyStd[1]  | 0.32825    |
| AveragePolicyStd[2]  | 0.27407    |
| AveragePolicyStd[3]  | 0.2416     |
| AveragePolicyStd[4]  | 0.27912    |
| AveragePolicyStd[5]  | 0.34996    |
| AverageReturn        | 526.55     |
| MinReturn            | 12.992     |
| MaxReturn            | 722.83     |
| StdReturn            | 235.96     |
| AverageEpisodeLength | 758.39     |
| MinEpisodeLength     | 34         |
| MaxEpisodeLength     | 1000       |
| StdEpisodeLength     | 330.11     |
| TotalNEpisodes       | 16090      |
| TotalNSamples        | 9.8414e+05 |
| ExplainedVariance    | 0.18983    |
-------------------------------------
[2019-11-19 11:51:30.579733 UTC] Saving snapshot
[2019-11-19 11:51:30.580597 UTC] Starting iteration 198
[2019-11-19 11:51:30.581234 UTC] Start collecting samples
[2019-11-19 11:51:35.312417 UTC] Computing input variables for policy optimization
[2019-11-19 11:51:35.567659 UTC] Performing policy update
[2019-11-19 11:51:35.570690 UTC] Computing gradient in Euclidean space
[2019-11-19 11:51:35.750921 UTC] Computing approximate natural gradient using conjugate gradient algorithm
[2019-11-19 11:51:37.840571 UTC] Performing line search
[2019-11-19 11:51:38.102228 UTC] Updating baseline
[2019-11-19 11:51:40.948607 UTC] Computing logging information
-------------------------------------
| Iteration            | 198        |
| ExpectedImprovement  | 0.011567   |
| ActualImprovement    | 0.010933   |
| ImprovementRatio     | 0.94522    |
| MeanKL               | 0.0076687  |
| Entropy              | 1.3027     |
| Perplexity           | 3.6793     |
| AveragePolicyStd     | 0.30335    |
| AveragePolicyStd[0]  | 0.34974    |
| AveragePolicyStd[1]  | 0.32826    |
| AveragePolicyStd[2]  | 0.27774    |
| AveragePolicyStd[3]  | 0.24156    |
| AveragePolicyStd[4]  | 0.27838    |
| AveragePolicyStd[5]  | 0.34442    |
| AverageReturn        | 537.76     |
| MinReturn            | 12.992     |
| MaxReturn            | 722.83     |
| StdReturn            | 229.69     |
| AverageEpisodeLength | 772.83     |
| MinEpisodeLength     | 34         |
| MaxEpisodeLength     | 1000       |
| StdEpisodeLength     | 319.46     |
| TotalNEpisodes       | 16095      |
| TotalNSamples        | 9.8879e+05 |
| ExplainedVariance    | 0.050694   |
-------------------------------------
[2019-11-19 11:51:42.392350 UTC] Saving snapshot
[2019-11-19 11:51:42.393570 UTC] Starting iteration 199
[2019-11-19 11:51:42.394444 UTC] Start collecting samples
[2019-11-19 11:51:47.575912 UTC] Computing input variables for policy optimization
[2019-11-19 11:51:47.833241 UTC] Performing policy update
[2019-11-19 11:51:47.841101 UTC] Computing gradient in Euclidean space
[2019-11-19 11:51:48.039300 UTC] Computing approximate natural gradient using conjugate gradient algorithm
[2019-11-19 11:51:50.081989 UTC] Performing line search
[2019-11-19 11:51:50.302486 UTC] Updating baseline
[2019-11-19 11:51:53.904969 UTC] Computing logging information
-------------------------------------
| Iteration            | 199        |
| ExpectedImprovement  | 0.015039   |
| ActualImprovement    | 0.014402   |
| ImprovementRatio     | 0.95762    |
| MeanKL               | 0.0070676  |
| Entropy              | 1.2879     |
| Perplexity           | 3.625      |
| AveragePolicyStd     | 0.30249    |
| AveragePolicyStd[0]  | 0.34982    |
| AveragePolicyStd[1]  | 0.32519    |
| AveragePolicyStd[2]  | 0.2769     |
| AveragePolicyStd[3]  | 0.24325    |
| AveragePolicyStd[4]  | 0.27717    |
| AveragePolicyStd[5]  | 0.3426     |
| AverageReturn        | 536.53     |
| MinReturn            | 12.992     |
| MaxReturn            | 722.83     |
| StdReturn            | 232.13     |
| AverageEpisodeLength | 769.02     |
| MinEpisodeLength     | 34         |
| MaxEpisodeLength     | 1000       |
| StdEpisodeLength     | 321.85     |
| TotalNEpisodes       | 16101      |
| TotalNSamples        | 9.9417e+05 |
| ExplainedVariance    | 0.28863    |
-------------------------------------
[2019-11-19 11:51:55.438115 UTC] Saving snapshot
[2019-11-19 11:51:55.439210 UTC] Starting iteration 200
[2019-11-19 11:51:55.440832 UTC] Start collecting samples
[2019-11-19 11:52:00.598506 UTC] Computing input variables for policy optimization
[2019-11-19 11:52:00.845757 UTC] Performing policy update
[2019-11-19 11:52:00.848460 UTC] Computing gradient in Euclidean space
[2019-11-19 11:52:01.041972 UTC] Computing approximate natural gradient using conjugate gradient algorithm
[2019-11-19 11:52:02.836594 UTC] Performing line search
[2019-11-19 11:52:03.079985 UTC] Updating baseline
[2019-11-19 11:52:05.440163 UTC] Computing logging information
------------------------------------
| Iteration            | 200       |
| ExpectedImprovement  | 0.013752  |
| ActualImprovement    | 0.012562  |
| ImprovementRatio     | 0.91347   |
| MeanKL               | 0.0067415 |
| Entropy              | 1.2862    |
| Perplexity           | 3.6192    |
| AveragePolicyStd     | 0.30228   |
| AveragePolicyStd[0]  | 0.35045   |
| AveragePolicyStd[1]  | 0.3235    |
| AveragePolicyStd[2]  | 0.2766    |
| AveragePolicyStd[3]  | 0.24521   |
| AveragePolicyStd[4]  | 0.27765   |
| AveragePolicyStd[5]  | 0.34026   |
| AverageReturn        | 559.93    |
| MinReturn            | 41.589    |
| MaxReturn            | 722.83    |
| StdReturn            | 217.63    |
| AverageEpisodeLength | 802.21    |
| MinEpisodeLength     | 61        |
| MaxEpisodeLength     | 1000      |
| StdEpisodeLength     | 300.36    |
| TotalNEpisodes       | 16107     |
| TotalNSamples        | 1e+06     |
| ExplainedVariance    | 0.14734   |
------------------------------------
[2019-11-19 11:52:06.827471 UTC] Saving snapshot
[2019-11-19 11:52:06.843935 UTC] Starting iteration 201
[2019-11-19 11:52:06.844783 UTC] Start collecting samples
[2019-11-19 11:52:11.798966 UTC] Computing input variables for policy optimization
[2019-11-19 11:52:12.055349 UTC] Performing policy update
[2019-11-19 11:52:12.057980 UTC] Computing gradient in Euclidean space
[2019-11-19 11:52:12.282916 UTC] Computing approximate natural gradient using conjugate gradient algorithm
[2019-11-19 11:52:14.329500 UTC] Performing line search
[2019-11-19 11:52:14.571337 UTC] Updating baseline
[2019-11-19 11:52:17.294079 UTC] Computing logging information
-------------------------------------
| Iteration            | 201        |
| ExpectedImprovement  | 0.015275   |
| ActualImprovement    | 0.015256   |
| ImprovementRatio     | 0.99875    |
| MeanKL               | 0.0072604  |
| Entropy              | 1.2888     |
| Perplexity           | 3.6284     |
| AveragePolicyStd     | 0.3023     |
| AveragePolicyStd[0]  | 0.35006    |
| AveragePolicyStd[1]  | 0.32128    |
| AveragePolicyStd[2]  | 0.27443    |
| AveragePolicyStd[3]  | 0.2467     |
| AveragePolicyStd[4]  | 0.28113    |
| AveragePolicyStd[5]  | 0.34022    |
| AverageReturn        | 544.48     |
| MinReturn            | 41.589     |
| MaxReturn            | 722.83     |
| StdReturn            | 225.36     |
| AverageEpisodeLength | 779.74     |
| MinEpisodeLength     | 61         |
| MaxEpisodeLength     | 1000       |
| StdEpisodeLength     | 312.58     |
| TotalNEpisodes       | 16112      |
| TotalNSamples        | 1.0028e+06 |
| ExplainedVariance    | 0.51803    |
-------------------------------------
[2019-11-19 11:52:18.844519 UTC] Saving snapshot
[2019-11-19 11:52:18.846429 UTC] Starting iteration 202
[2019-11-19 11:52:18.849188 UTC] Start collecting samples
[2019-11-19 11:52:24.392154 UTC] Computing input variables for policy optimization
[2019-11-19 11:52:24.653824 UTC] Performing policy update
[2019-11-19 11:52:24.655394 UTC] Computing gradient in Euclidean space
[2019-11-19 11:52:24.836945 UTC] Computing approximate natural gradient using conjugate gradient algorithm
[2019-11-19 11:52:27.007378 UTC] Performing line search
[2019-11-19 11:52:27.263068 UTC] Updating baseline
[2019-11-19 11:52:29.677387 UTC] Computing logging information
-------------------------------------
| Iteration            | 202        |
| ExpectedImprovement  | 0.015485   |
| ActualImprovement    | 0.012191   |
| ImprovementRatio     | 0.78732    |
| MeanKL               | 0.0069637  |
| Entropy              | 1.2592     |
| Perplexity           | 3.5226     |
| AveragePolicyStd     | 0.30082    |
| AveragePolicyStd[0]  | 0.34603    |
| AveragePolicyStd[1]  | 0.32013    |
| AveragePolicyStd[2]  | 0.27369    |
| AveragePolicyStd[3]  | 0.24461    |
| AveragePolicyStd[4]  | 0.28008    |
| AveragePolicyStd[5]  | 0.34038    |
| AverageReturn        | 544.96     |
| MinReturn            | 16.211     |
| MaxReturn            | 727.53     |
| StdReturn            | 226.09     |
| AverageEpisodeLength | 780        |
| MinEpisodeLength     | 31         |
| MaxEpisodeLength     | 1000       |
| StdEpisodeLength     | 312.69     |
| TotalNEpisodes       | 16122      |
| TotalNSamples        | 1.0101e+06 |
| ExplainedVariance    | 0.29225    |
-------------------------------------
[2019-11-19 11:52:31.252928 UTC] Saving snapshot
[2019-11-19 11:52:31.253933 UTC] Starting iteration 203
[2019-11-19 11:52:31.254765 UTC] Start collecting samples
[2019-11-19 11:52:36.438003 UTC] Computing input variables for policy optimization
[2019-11-19 11:52:36.669357 UTC] Performing policy update
[2019-11-19 11:52:36.673117 UTC] Computing gradient in Euclidean space
[2019-11-19 11:52:36.845976 UTC] Computing approximate natural gradient using conjugate gradient algorithm
[2019-11-19 11:52:38.971770 UTC] Performing line search
[2019-11-19 11:52:39.185223 UTC] Updating baseline
[2019-11-19 11:52:42.089887 UTC] Computing logging information
-------------------------------------
| Iteration            | 203        |
| ExpectedImprovement  | 0.01475    |
| ActualImprovement    | 0.013224   |
| ImprovementRatio     | 0.89658    |
| MeanKL               | 0.007599   |
| Entropy              | 1.2641     |
| Perplexity           | 3.5399     |
| AveragePolicyStd     | 0.30104    |
| AveragePolicyStd[0]  | 0.3451     |
| AveragePolicyStd[1]  | 0.32029    |
| AveragePolicyStd[2]  | 0.27335    |
| AveragePolicyStd[3]  | 0.24554    |
| AveragePolicyStd[4]  | 0.28049    |
| AveragePolicyStd[5]  | 0.34144    |
| AverageReturn        | 553.64     |
| MinReturn            | 16.211     |
| MaxReturn            | 727.53     |
| StdReturn            | 223.76     |
| AverageEpisodeLength | 791.45     |
| MinEpisodeLength     | 31         |
| MaxEpisodeLength     | 1000       |
| StdEpisodeLength     | 309.35     |
| TotalNEpisodes       | 16127      |
| TotalNSamples        | 1.0143e+06 |
| ExplainedVariance    | 0.35124    |
-------------------------------------
[2019-11-19 11:52:43.537834 UTC] Saving snapshot
[2019-11-19 11:52:43.538718 UTC] Starting iteration 204
[2019-11-19 11:52:43.539753 UTC] Start collecting samples
[2019-11-19 11:52:48.806438 UTC] Computing input variables for policy optimization
[2019-11-19 11:52:49.049913 UTC] Performing policy update
[2019-11-19 11:52:49.057765 UTC] Computing gradient in Euclidean space
[2019-11-19 11:52:49.207378 UTC] Computing approximate natural gradient using conjugate gradient algorithm
[2019-11-19 11:52:51.277449 UTC] Performing line search
[2019-11-19 11:52:51.568129 UTC] Updating baseline
[2019-11-19 11:52:54.636250 UTC] Computing logging information
------------------------------------
| Iteration            | 204       |
| ExpectedImprovement  | 0.013352  |
| ActualImprovement    | 0.01217   |
| ImprovementRatio     | 0.91146   |
| MeanKL               | 0.0075311 |
| Entropy              | 1.2521    |
| Perplexity           | 3.4976    |
| AveragePolicyStd     | 0.3005    |
| AveragePolicyStd[0]  | 0.34206   |
| AveragePolicyStd[1]  | 0.31876   |
| AveragePolicyStd[2]  | 0.2688    |
| AveragePolicyStd[3]  | 0.24683   |
| AveragePolicyStd[4]  | 0.2801    |
| AveragePolicyStd[5]  | 0.34645   |
| AverageReturn        | 548.67    |
| MinReturn            | 16.211    |
| MaxReturn            | 727.53    |
| StdReturn            | 221.48    |
| AverageEpisodeLength | 787.24    |
| MinEpisodeLength     | 31        |
| MaxEpisodeLength     | 1000      |
| StdEpisodeLength     | 303.99    |
| TotalNEpisodes       | 16132     |
| TotalNSamples        | 1.018e+06 |
| ExplainedVariance    | 0.58374   |
------------------------------------
[2019-11-19 11:52:56.169180 UTC] Saving snapshot
[2019-11-19 11:52:56.171134 UTC] Starting iteration 205
[2019-11-19 11:52:56.172611 UTC] Start collecting samples
[2019-11-19 11:53:01.366922 UTC] Computing input variables for policy optimization
[2019-11-19 11:53:01.665259 UTC] Performing policy update
[2019-11-19 11:53:01.672922 UTC] Computing gradient in Euclidean space
[2019-11-19 11:53:01.854498 UTC] Computing approximate natural gradient using conjugate gradient algorithm
[2019-11-19 11:53:03.796465 UTC] Performing line search
[2019-11-19 11:53:04.042196 UTC] Updating baseline
[2019-11-19 11:53:07.376196 UTC] Computing logging information
-------------------------------------
| Iteration            | 205        |
| ExpectedImprovement  | 0.014333   |
| ActualImprovement    | 0.013202   |
| ImprovementRatio     | 0.92109    |
| MeanKL               | 0.0071322  |
| Entropy              | 1.2368     |
| Perplexity           | 3.4446     |
| AveragePolicyStd     | 0.2997     |
| AveragePolicyStd[0]  | 0.33789    |
| AveragePolicyStd[1]  | 0.31928    |
| AveragePolicyStd[2]  | 0.26721    |
| AveragePolicyStd[3]  | 0.24685    |
| AveragePolicyStd[4]  | 0.28022    |
| AveragePolicyStd[5]  | 0.34673    |
| AverageReturn        | 546.33     |
| MinReturn            | 12.211     |
| MaxReturn            | 727.53     |
| StdReturn            | 230.68     |
| AverageEpisodeLength | 779.66     |
| MinEpisodeLength     | 31         |
| MaxEpisodeLength     | 1000       |
| StdEpisodeLength     | 319.3      |
| TotalNEpisodes       | 16143      |
| TotalNSamples        | 1.0257e+06 |
| ExplainedVariance    | 0.24764    |
-------------------------------------
[2019-11-19 11:53:08.876962 UTC] Saving snapshot
[2019-11-19 11:53:08.878035 UTC] Starting iteration 206
[2019-11-19 11:53:08.879231 UTC] Start collecting samples
[2019-11-19 11:53:13.293007 UTC] Computing input variables for policy optimization
[2019-11-19 11:53:13.529751 UTC] Performing policy update
[2019-11-19 11:53:13.537447 UTC] Computing gradient in Euclidean space
[2019-11-19 11:53:13.729606 UTC] Computing approximate natural gradient using conjugate gradient algorithm
[2019-11-19 11:53:15.603300 UTC] Performing line search
[2019-11-19 11:53:15.823096 UTC] Updating baseline
[2019-11-19 11:53:18.489694 UTC] Computing logging information
-------------------------------------
| Iteration            | 206        |
| ExpectedImprovement  | 0.019753   |
| ActualImprovement    | 0.016574   |
| ImprovementRatio     | 0.83907    |
| MeanKL               | 0.0067561  |
| Entropy              | 1.2356     |
| Perplexity           | 3.4403     |
| AveragePolicyStd     | 0.29966    |
| AveragePolicyStd[0]  | 0.33901    |
| AveragePolicyStd[1]  | 0.32005    |
| AveragePolicyStd[2]  | 0.26748    |
| AveragePolicyStd[3]  | 0.24627    |
| AveragePolicyStd[4]  | 0.27966    |
| AveragePolicyStd[5]  | 0.34549    |
| AverageReturn        | 537.5      |
| MinReturn            | 12.211     |
| MaxReturn            | 727.53     |
| StdReturn            | 235.56     |
| AverageEpisodeLength | 769.04     |
| MinEpisodeLength     | 21         |
| MaxEpisodeLength     | 1000       |
| StdEpisodeLength     | 326.83     |
| TotalNEpisodes       | 16147      |
| TotalNSamples        | 1.0287e+06 |
| ExplainedVariance    | 0.38372    |
-------------------------------------
[2019-11-19 11:53:19.795393 UTC] Saving snapshot
[2019-11-19 11:53:19.796899 UTC] Starting iteration 207
[2019-11-19 11:53:19.798658 UTC] Start collecting samples
[2019-11-19 11:53:25.095977 UTC] Computing input variables for policy optimization
[2019-11-19 11:53:25.348201 UTC] Performing policy update
[2019-11-19 11:53:25.351226 UTC] Computing gradient in Euclidean space
[2019-11-19 11:53:25.511500 UTC] Computing approximate natural gradient using conjugate gradient algorithm
[2019-11-19 11:53:27.600411 UTC] Performing line search
[2019-11-19 11:53:27.899809 UTC] Updating baseline
[2019-11-19 11:53:30.524578 UTC] Computing logging information
------------------------------------
| Iteration            | 207       |
| ExpectedImprovement  | 0.014363  |
| ActualImprovement    | 0.012878  |
| ImprovementRatio     | 0.89662   |
| MeanKL               | 0.0073172 |
| Entropy              | 1.2459    |
| Perplexity           | 3.476     |
| AveragePolicyStd     | 0.30029   |
| AveragePolicyStd[0]  | 0.34119   |
| AveragePolicyStd[1]  | 0.31822   |
| AveragePolicyStd[2]  | 0.27045   |
| AveragePolicyStd[3]  | 0.24456   |
| AveragePolicyStd[4]  | 0.2785    |
| AveragePolicyStd[5]  | 0.34883   |
| AverageReturn        | 535.36    |
| MinReturn            | 12.211    |
| MaxReturn            | 727.53    |
| StdReturn            | 240.56    |
| AverageEpisodeLength | 766.8     |
| MinEpisodeLength     | 21        |
| MaxEpisodeLength     | 1000      |
| StdEpisodeLength     | 336.26    |
| TotalNEpisodes       | 16153     |
| TotalNSamples        | 1.033e+06 |
| ExplainedVariance    | 0.32728   |
------------------------------------
[2019-11-19 11:53:32.043754 UTC] Saving snapshot
[2019-11-19 11:53:32.044432 UTC] Starting iteration 208
[2019-11-19 11:53:32.045117 UTC] Start collecting samples
[2019-11-19 11:53:37.196345 UTC] Computing input variables for policy optimization
[2019-11-19 11:53:37.456960 UTC] Performing policy update
[2019-11-19 11:53:37.466852 UTC] Computing gradient in Euclidean space
[2019-11-19 11:53:37.650376 UTC] Computing approximate natural gradient using conjugate gradient algorithm
[2019-11-19 11:53:39.527168 UTC] Performing line search
[2019-11-19 11:53:39.785634 UTC] Updating baseline
[2019-11-19 11:53:42.959118 UTC] Computing logging information
------------------------------------
| Iteration            | 208       |
| ExpectedImprovement  | 0.01303   |
| ActualImprovement    | 0.012617  |
| ImprovementRatio     | 0.96831   |
| MeanKL               | 0.0078511 |
| Entropy              | 1.2335    |
| Perplexity           | 3.4332    |
| AveragePolicyStd     | 0.29957   |
| AveragePolicyStd[0]  | 0.33765   |
| AveragePolicyStd[1]  | 0.31898   |
| AveragePolicyStd[2]  | 0.26891   |
| AveragePolicyStd[3]  | 0.24669   |
| AveragePolicyStd[4]  | 0.27691   |
| AveragePolicyStd[5]  | 0.34829   |
| AverageReturn        | 551.05    |
| MinReturn            | 12.211    |
| MaxReturn            | 727.53    |
| StdReturn            | 235.79    |
| AverageEpisodeLength | 788.33    |
| MinEpisodeLength     | 21        |
| MaxEpisodeLength     | 1000      |
| StdEpisodeLength     | 330.2     |
| TotalNEpisodes       | 16161     |
| TotalNSamples        | 1.041e+06 |
| ExplainedVariance    | 0.15695   |
------------------------------------
[2019-11-19 11:53:44.322527 UTC] Saving snapshot
[2019-11-19 11:53:44.323460 UTC] Starting iteration 209
[2019-11-19 11:53:44.324525 UTC] Start collecting samples
[2019-11-19 11:53:50.173830 UTC] Computing input variables for policy optimization
[2019-11-19 11:53:50.406886 UTC] Performing policy update
[2019-11-19 11:53:50.412968 UTC] Computing gradient in Euclidean space
[2019-11-19 11:53:50.607218 UTC] Computing approximate natural gradient using conjugate gradient algorithm
[2019-11-19 11:53:52.474725 UTC] Performing line search
[2019-11-19 11:53:52.738715 UTC] Updating baseline
[2019-11-19 11:53:55.563940 UTC] Computing logging information
-------------------------------------
| Iteration            | 209        |
| ExpectedImprovement  | 0.018659   |
| ActualImprovement    | 0.015564   |
| ImprovementRatio     | 0.83412    |
| MeanKL               | 0.0068099  |
| Entropy              | 1.2223     |
| Perplexity           | 3.3951     |
| AveragePolicyStd     | 0.29902    |
| AveragePolicyStd[0]  | 0.33332    |
| AveragePolicyStd[1]  | 0.31988    |
| AveragePolicyStd[2]  | 0.26785    |
| AveragePolicyStd[3]  | 0.24564    |
| AveragePolicyStd[4]  | 0.27805    |
| AveragePolicyStd[5]  | 0.34937    |
| AverageReturn        | 535.83     |
| MinReturn            | 12.211     |
| MaxReturn            | 727.53     |
| StdReturn            | 247.57     |
| AverageEpisodeLength | 766.52     |
| MinEpisodeLength     | 21         |
| MaxEpisodeLength     | 1000       |
| StdEpisodeLength     | 349.19     |
| TotalNEpisodes       | 16168      |
| TotalNSamples        | 1.0444e+06 |
| ExplainedVariance    | 0.19865    |
-------------------------------------
[2019-11-19 11:53:57.060300 UTC] Saving snapshot
[2019-11-19 11:53:57.062862 UTC] Starting iteration 210
[2019-11-19 11:53:57.063714 UTC] Start collecting samples
[2019-11-19 11:54:02.159205 UTC] Computing input variables for policy optimization
[2019-11-19 11:54:02.440374 UTC] Performing policy update
[2019-11-19 11:54:02.448720 UTC] Computing gradient in Euclidean space
[2019-11-19 11:54:02.628326 UTC] Computing approximate natural gradient using conjugate gradient algorithm
[2019-11-19 11:54:04.660544 UTC] Performing line search
[2019-11-19 11:54:04.886786 UTC] Updating baseline
[2019-11-19 11:54:08.233976 UTC] Computing logging information
-------------------------------------
| Iteration            | 210        |
| ExpectedImprovement  | 0.011587   |
| ActualImprovement    | 0.010757   |
| ImprovementRatio     | 0.92839    |
| MeanKL               | 0.0070095  |
| Entropy              | 1.2074     |
| Perplexity           | 3.3448     |
| AveragePolicyStd     | 0.29824    |
| AveragePolicyStd[0]  | 0.33154    |
| AveragePolicyStd[1]  | 0.31931    |
| AveragePolicyStd[2]  | 0.26861    |
| AveragePolicyStd[3]  | 0.24506    |
| AveragePolicyStd[4]  | 0.27664    |
| AveragePolicyStd[5]  | 0.34826    |
| AverageReturn        | 542.67     |
| MinReturn            | 12.211     |
| MaxReturn            | 727.53     |
| StdReturn            | 243.57     |
| AverageEpisodeLength | 775.74     |
| MinEpisodeLength     | 21         |
| MaxEpisodeLength     | 1000       |
| StdEpisodeLength     | 343.01     |
| TotalNEpisodes       | 16171      |
| TotalNSamples        | 1.0474e+06 |
| ExplainedVariance    | 0.17085    |
-------------------------------------
[2019-11-19 11:54:09.586215 UTC] Saving snapshot
[2019-11-19 11:54:09.604450 UTC] Starting iteration 211
[2019-11-19 11:54:09.605156 UTC] Start collecting samples
[2019-11-19 11:54:15.046957 UTC] Computing input variables for policy optimization
[2019-11-19 11:54:15.345179 UTC] Performing policy update
[2019-11-19 11:54:15.348663 UTC] Computing gradient in Euclidean space
[2019-11-19 11:54:15.580842 UTC] Computing approximate natural gradient using conjugate gradient algorithm
[2019-11-19 11:54:18.130853 UTC] Performing line search
[2019-11-19 11:54:18.436800 UTC] Updating baseline
[2019-11-19 11:54:21.892629 UTC] Computing logging information
-------------------------------------
| Iteration            | 211        |
| ExpectedImprovement  | 0.011499   |
| ActualImprovement    | 0.010774   |
| ImprovementRatio     | 0.9369     |
| MeanKL               | 0.0071017  |
| Entropy              | 1.2064     |
| Perplexity           | 3.3413     |
| AveragePolicyStd     | 0.29818    |
| AveragePolicyStd[0]  | 0.33298    |
| AveragePolicyStd[1]  | 0.31767    |
| AveragePolicyStd[2]  | 0.26752    |
| AveragePolicyStd[3]  | 0.24597    |
| AveragePolicyStd[4]  | 0.27652    |
| AveragePolicyStd[5]  | 0.34844    |
| AverageReturn        | 543.38     |
| MinReturn            | 12.211     |
| MaxReturn            | 727.53     |
| StdReturn            | 243.91     |
| AverageEpisodeLength | 776.11     |
| MinEpisodeLength     | 21         |
| MaxEpisodeLength     | 1000       |
| StdEpisodeLength     | 342.92     |
| TotalNEpisodes       | 16178      |
| TotalNSamples        | 1.0541e+06 |
| ExplainedVariance    | 0.14415    |
-------------------------------------
[2019-11-19 11:54:23.675040 UTC] Saving snapshot
[2019-11-19 11:54:23.675907 UTC] Starting iteration 212
[2019-11-19 11:54:23.677097 UTC] Start collecting samples
[2019-11-19 11:54:29.069722 UTC] Computing input variables for policy optimization
[2019-11-19 11:54:29.382032 UTC] Performing policy update
[2019-11-19 11:54:29.386779 UTC] Computing gradient in Euclidean space
[2019-11-19 11:54:29.609735 UTC] Computing approximate natural gradient using conjugate gradient algorithm
[2019-11-19 11:54:32.189945 UTC] Performing line search
[2019-11-19 11:54:32.526357 UTC] Updating baseline
[2019-11-19 11:54:36.369282 UTC] Computing logging information
-------------------------------------
| Iteration            | 212        |
| ExpectedImprovement  | 0.011785   |
| ActualImprovement    | 0.011541   |
| ImprovementRatio     | 0.97932    |
| MeanKL               | 0.0078569  |
| Entropy              | 1.2332     |
| Perplexity           | 3.4322     |
| AveragePolicyStd     | 0.29965    |
| AveragePolicyStd[0]  | 0.33611    |
| AveragePolicyStd[1]  | 0.3185     |
| AveragePolicyStd[2]  | 0.26772    |
| AveragePolicyStd[3]  | 0.24576    |
| AveragePolicyStd[4]  | 0.27807    |
| AveragePolicyStd[5]  | 0.35172    |
| AverageReturn        | 553.35     |
| MinReturn            | 12.211     |
| MaxReturn            | 727.53     |
| StdReturn            | 243.18     |
| AverageEpisodeLength | 789.71     |
| MinEpisodeLength     | 21         |
| MaxEpisodeLength     | 1000       |
| StdEpisodeLength     | 340.97     |
| TotalNEpisodes       | 16184      |
| TotalNSamples        | 1.0601e+06 |
| ExplainedVariance    | 0.12692    |
-------------------------------------
[2019-11-19 11:54:37.999082 UTC] Saving snapshot
[2019-11-19 11:54:38.000230 UTC] Starting iteration 213
[2019-11-19 11:54:38.001235 UTC] Start collecting samples
[2019-11-19 11:54:43.005103 UTC] Computing input variables for policy optimization
[2019-11-19 11:54:43.277046 UTC] Performing policy update
[2019-11-19 11:54:43.282553 UTC] Computing gradient in Euclidean space
[2019-11-19 11:54:43.463187 UTC] Computing approximate natural gradient using conjugate gradient algorithm
[2019-11-19 11:54:45.774863 UTC] Performing line search
[2019-11-19 11:54:46.055130 UTC] Updating baseline
[2019-11-19 11:54:49.001699 UTC] Computing logging information
-------------------------------------
| Iteration            | 213        |
| ExpectedImprovement  | 0.017401   |
| ActualImprovement    | 0.015055   |
| ImprovementRatio     | 0.86519    |
| MeanKL               | 0.0069469  |
| Entropy              | 1.2239     |
| Perplexity           | 3.4005     |
| AveragePolicyStd     | 0.29917    |
| AveragePolicyStd[0]  | 0.33683    |
| AveragePolicyStd[1]  | 0.31865    |
| AveragePolicyStd[2]  | 0.26512    |
| AveragePolicyStd[3]  | 0.24648    |
| AveragePolicyStd[4]  | 0.27846    |
| AveragePolicyStd[5]  | 0.34947    |
| AverageReturn        | 549.47     |
| MinReturn            | 12.211     |
| MaxReturn            | 727.53     |
| StdReturn            | 242.9      |
| AverageEpisodeLength | 788.54     |
| MinEpisodeLength     | 21         |
| MaxEpisodeLength     | 1000       |
| StdEpisodeLength     | 341.37     |
| TotalNEpisodes       | 16188      |
| TotalNSamples        | 1.0626e+06 |
| ExplainedVariance    | 0.65932    |
-------------------------------------
[2019-11-19 11:54:50.625346 UTC] Saving snapshot
[2019-11-19 11:54:50.626191 UTC] Starting iteration 214
[2019-11-19 11:54:50.626956 UTC] Start collecting samples
[2019-11-19 11:54:56.120434 UTC] Computing input variables for policy optimization
[2019-11-19 11:54:56.362674 UTC] Performing policy update
[2019-11-19 11:54:56.368626 UTC] Computing gradient in Euclidean space
[2019-11-19 11:54:56.556462 UTC] Computing approximate natural gradient using conjugate gradient algorithm
[2019-11-19 11:54:58.509276 UTC] Performing line search
[2019-11-19 11:54:58.736180 UTC] Updating baseline
[2019-11-19 11:55:01.226990 UTC] Computing logging information
-------------------------------------
| Iteration            | 214        |
| ExpectedImprovement  | 0.014778   |
| ActualImprovement    | 0.014152   |
| ImprovementRatio     | 0.95762    |
| MeanKL               | 0.0073813  |
| Entropy              | 1.2051     |
| Perplexity           | 3.337      |
| AveragePolicyStd     | 0.29822    |
| AveragePolicyStd[0]  | 0.33689    |
| AveragePolicyStd[1]  | 0.31793    |
| AveragePolicyStd[2]  | 0.26385    |
| AveragePolicyStd[3]  | 0.24598    |
| AveragePolicyStd[4]  | 0.2776     |
| AveragePolicyStd[5]  | 0.34709    |
| AverageReturn        | 534.93     |
| MinReturn            | 12.211     |
| MaxReturn            | 727.53     |
| StdReturn            | 250.88     |
| AverageEpisodeLength | 769.54     |
| MinEpisodeLength     | 21         |
| MaxEpisodeLength     | 1000       |
| StdEpisodeLength     | 353.67     |
| TotalNEpisodes       | 16200      |
| TotalNSamples        | 1.0707e+06 |
| ExplainedVariance    | 0.27636    |
-------------------------------------
[2019-11-19 11:55:02.630884 UTC] Saving snapshot
[2019-11-19 11:55:02.631626 UTC] Starting iteration 215
[2019-11-19 11:55:02.632275 UTC] Start collecting samples
[2019-11-19 11:55:07.519039 UTC] Computing input variables for policy optimization
[2019-11-19 11:55:07.808830 UTC] Performing policy update
[2019-11-19 11:55:07.812692 UTC] Computing gradient in Euclidean space
[2019-11-19 11:55:07.946577 UTC] Computing approximate natural gradient using conjugate gradient algorithm
[2019-11-19 11:55:09.788700 UTC] Performing line search
[2019-11-19 11:55:10.022544 UTC] Updating baseline
[2019-11-19 11:55:12.514545 UTC] Computing logging information
-------------------------------------
| Iteration            | 215        |
| ExpectedImprovement  | 0.015289   |
| ActualImprovement    | 0.013122   |
| ImprovementRatio     | 0.85825    |
| MeanKL               | 0.0068044  |
| Entropy              | 1.1985     |
| Perplexity           | 3.315      |
| AveragePolicyStd     | 0.29788    |
| AveragePolicyStd[0]  | 0.3361     |
| AveragePolicyStd[1]  | 0.31812    |
| AveragePolicyStd[2]  | 0.26383    |
| AveragePolicyStd[3]  | 0.24492    |
| AveragePolicyStd[4]  | 0.27834    |
| AveragePolicyStd[5]  | 0.34599    |
| AverageReturn        | 530.19     |
| MinReturn            | 12.211     |
| MaxReturn            | 727.53     |
| StdReturn            | 254.72     |
| AverageEpisodeLength | 763.68     |
| MinEpisodeLength     | 21         |
| MaxEpisodeLength     | 1000       |
| StdEpisodeLength     | 358.94     |
| TotalNEpisodes       | 16206      |
| TotalNSamples        | 1.0754e+06 |
| ExplainedVariance    | 0.33174    |
-------------------------------------
[2019-11-19 11:55:13.988507 UTC] Saving snapshot
[2019-11-19 11:55:13.989194 UTC] Starting iteration 216
[2019-11-19 11:55:13.989767 UTC] Start collecting samples
[2019-11-19 11:55:19.130798 UTC] Computing input variables for policy optimization
[2019-11-19 11:55:19.406149 UTC] Performing policy update
[2019-11-19 11:55:19.412450 UTC] Computing gradient in Euclidean space
[2019-11-19 11:55:19.594833 UTC] Computing approximate natural gradient using conjugate gradient algorithm
